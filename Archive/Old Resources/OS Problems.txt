1.1. Suppose the hypothetical processor of Figure 1.3 also has two I/O instructions: 0011   Load AC from I/O
0111   Store AC to I/O
In these cases, the 12-bit address identifies a particular external device. Show the program execution (using format of Figure 1.4) for the following program:
1. Load AC from device 5.
2. Add contents of memory location 940.
3. Store AC to device 6.
Assume that the next value retrieved from device 5 is 3 and that location 940 contains
a value of 2.
1.2. The program execution of Figure 1.4 is described in the text using six steps. Expand
this description to show the use of the MAR and MBR.
1.3. Consider a hypothetical 32-bit microprocessor having 32-bit instructions composed of
two fields. The first byte contains the opcode and the remainder an immediate operand or an operand address.
a. What is the maximum directly addressable memory capacity (in bytes)?
b. Discuss the impact on the system speed if the microprocessor bus has
1. a 32-bit local address bus and a 16-bit local data bus, or
2. a 16-bit local address bus and a 16-bit local data bus.
c. How many bits are needed for the program counter and the instruction register?
1.4. Consider a hypothetical microprocessor generating a 16-bit address (e.g., assume that the program counter and the address registers are 16 bits wide) and having a 16-bit data bus.
a. What is the maximum memory address space that the processor can access directly if it is connected to a “16-bit memory”?
b. What is the maximum memory address space that the processor can access directly if it is connected to an “8-bit memory”?
c. What architectural features will allow this microprocessor to access a separate “I/O space”?
d. If an input and an output instruction can specify an 8-bit I/O port number, how many 8-bit I/O ports can the microprocessor support? How many 16-bit I/O ports? Explain.
1.5. Consider a 32-bit microprocessor, with a 16-bit external data bus, driven by an 8-MHz input clock. Assume that this microprocessor has a bus cycle whose minimum duration equals four input clock cycles. What is the maximum data transfer rate across the bus that this microprocessor can sustain in bytes/s? To increase its performance, would it be better to make its external data bus 32 bits or to double the external clock frequency supplied to the microprocessor? State any other assumptions you make and explain. Hint: Determine the number of bytes that can be transferred per bus cycle.
1.6. Consider a computer system that contains an I/O module controlling a simple keyboard/printer Teletype. The following registers are contained in the CPU and connected directly to the system bus:
INPR: Input Register, 8 bits
OUTR: Output Register, 8 bits
FGI: Input Flag, 1 bit
FGO: Output Flag, 1 bit
IEN: Interrupt Enable, 1 bit
Keystroke input from the Teletype and output to the printer are controlled by the I/O module. The Teletype is able to encode an alphanumeric symbol to an 8-bit word and decode an 8-bit word into an alphanumeric symbol. The Input flag is set when an 8-bit word enters the input register from the Teletype. The Output flag is set when a word is printed.
a. Describe how the CPU, using the first four registers listed in this problem, can achieve I/O with the Teletype.
b. Describe how the function can be performed more efficiently by also employing IEN.
1.7. In virtually all systems that include DMA modules, DMA access to main memory is
given higher priority than processor access to main memory. Why?
1.8. A DMA module is transferring characters to main memory from an external device transmitting at 9600 bits per second (bps). The processor can fetch instructions at the rate of 1 million instructions per second. By how much will the processor be slowed
down due to the DMA activity?
1.9. A computer consists of a CPU and an I/O device D connected to main memory M via
a shared bus with a data bus width of one word. The CPU can execute a maximum of 106 instructions per second. An average instruction requires five processor cycles, three of which use the memory bus. A memory read or write operation uses one processor cycle. Suppose that the CPU is continuously executing “background” programs that require 95% of its instruction execution rate but not any I/O instructions.
Assume that one processor cycle equals one bus cycle. Now suppose that very large blocks of data are to be transferred between M and D.
a. If programmed I/O is used and each one-word I/O transfer requires the CPU to
execute two instructions, estimate the maximum I/O data transfer rate, in words
per second, possible through D.
b. Estimate the same rate if DMA transfer is used.
1.10. Consider the following code:
for (i   0; i   20; i++)
for (j   0; j   10; j++)
a[i]   a[i] * j
a. Give one example of the spatial locality in the code.
b. Give one example of the temporal locality in the code.
1.11. Generalize Equations (1.1) and (1.2) in Appendix 1A to n-level memory hierarchies.
1.12. Consider a memory system with the following parameters:
Tc   100 ns Cc   0.01 cents/bit Tm   1,200 ns Cm   0.001 cents/bit
a. What is the cost of 1 MByte of main memory?
b. What is the cost of 1 MByte of main memory using cache memory technology?
c. If the effective access time is 10% greater than the cache access time, what is the
hit ratio H?
1.13. A computer has a cache, main memory, and a disk used for virtual memory. If a referenced word is in the cache, 20 ns are required to access it. If it is in main memory but not in the cache, 60 ns are needed to load it into the cache (this includes the time to originally check the cache), and then the reference is started again. If the word is not in main memory, 12 ms are required to fetch the word from disk, followed by 60 ns to copy it to the cache, and then the reference is started again. The cache hit ratio is 0.9 and the main-memory hit ratio is 0.6. What is the average time in ns required to access a referenced word on this system?
1.14. Suppose a stack is to be used by the processor to manage procedure calls and returns. Can the program counter be eliminated by using the top of the stack as a program counter?
2.1 Suppose that we have a multiprogrammed computer in which each job has identical characteristics. In one computation period, T, for a job, half the time is spent in I/O and the other half in processor activity. Each job runs for a total of N periods. Assume that a simple round-robin scheduling is used, and that I/O operations can overlap with processor operation. Define the following quantities:
• Turnaround time = actual time to complete a job
• Throughput = average number of jobs completed per time period T
• Processor utilization = percentage of time that the processor is active (not waiting) Compute these quantities for one, two, and four simultaneous jobs, assuming that the period T is distributed in each of the following ways:
a. I/O first half, processor second half
b. I/O first and fourth quarters, processor second and third quarter
2.2 An I/O-bound program is one that, if run alone, would spend more time waiting for I/O than using the processor. A processor-bound program is the opposite. Suppose a short-term scheduling algorithm favors those programs that have used little processor time in the recent past. Explain why this algorithm favors I/O-bound programs and yet does not permanently deny processor time to processor-bound programs.
2.3 Contrast the scheduling policies you might use when trying to optimize a time-sharing system with those you would use to optimize a multiprogrammed batch system.
2.4 What is the purpose of system calls, and how do system calls relate to the OS and to
the concept of dual-mode (kernel-mode and user-mode) operation?
2.5 In IBM’s mainframe OS, OS/390, one of the major modules in the kernel is the System Resource Manager. This module is responsible for the allocation of resources among address spaces (processes). The SRM gives OS/390 a degree of sophistication unique among operating systems. No other mainframe OS, and certainly no other type of OS, can match the functions performed by SRM. The concept of resource includes processor, real memory, and I/O channels. SRM accumulates statistics pertaining to utilization of processor, channel, and various key data structures. Its purpose is to provide optimum performance based on performance monitoring and analysis. The installation sets forth various performance objectives, and these serve as guidance to the SRM, which dynamically modifies installation and job performance characteristics based on system utilization. In turn, the SRM provides reports that enable the trained operator to refine
the configuration and parameter settings to improve user service.
This problem concerns one example of SRM activity. Real memory is divided
into equal-sized blocks called frames, of which there may be many thousands. Each frame can hold a block of virtual memory referred to as a page. SRM receives control approximately 20 times per second and inspects each and every page frame. If the page has not been referenced or changed, a counter is incremented by 1. Over time, SRM averages these numbers to determine the average number of seconds that a page frame in the system goes untouched. What might be the purpose of this and what action might SRM take?
2.6 A multiprocessor with eight processors has 20 attached tape drives. There is a large number of jobs submitted to the system that each require a maximum of four tape
drives to complete execution. Assume that each job starts running with only three tape drives for a long period before requiring the fourth tape drive for a short period toward the end of its operation. Also assume an endless supply of such jobs.
a. Assume the scheduler in the OS will not start a job unless there are four tape
drives available. When a job is started, four drives are assigned immediately and are not released until the job finishes. What is the maximum number of jobs that can be in progress at once? What are the maximum and minimum number of tape drives that may be left idle as a result of this policy?
b. Suggest an alternative policy to improve tape drive utilization and at the same time avoid system deadlock. What is the maximum number of jobs that can be in progress at once? What are the bounds on the number of idling tape drives?
3.1 The following state transition table is a simplified model of process management, with the labels representing transitions between states of READY, RUN, BLOCKED, and NONRESIDENT.
Give an example of an event that can cause each of the above transitions. Draw a
diagram if that helps.
3.2 Assume that at time 5 no system resources are being used except for the processor
and memory. Now consider the following events:
At time 5: P1 executes a command to read from disk unit 3.
At time 15: P5’s time slice expires.
At time 18: P7 executes a command to write to disk unit 3.
At time 20: P3 executes a command to read from disk unit 2.
At time 24: P5 executes a command to write to disk unit 3.
At time 28: P5 is swapped out.
At time 33: An interrupt occurs from disk unit 2: P3’s read is complete. At time 36: An interrupt occurs from disk unit 3: P1’s read is complete. At time 38: P8 terminates.
At time 40: An interrupt occurs from disk unit 3: P5’s write is complete. At time 44: P5 is swapped back in.
At time 48: An interrupt occurs from disk unit 3: P7’s write is complete.
For each time 22, 37, and 47, identify which state each process is in. If a process is blocked, further identify the event on which is it blocked.
3.3 Figure 3.9b contains seven states. In principle, one could draw a transition between any two states, for a total of 42 different transitions.
a. List all of the possible transitions and give an example of what could cause each
transition.
b. List all of the impossible transitions and explain why.
3.4 For the seven-state process model of Figure 3.9b, draw a queueing diagram similar to that of Figure 3.8b.
3.5 Consider the state transition diagram of Figure 3.9b. Suppose that it is time for the OS to dispatch a process and that there are processes in both the Ready state and the Ready/Suspend state, and that at least one process in the Ready/Suspend state has higher scheduling priority than any of the processes in the Ready state. Two extreme policies are as follows: (1) Always dispatch from a process in the Ready state, to minimize swapping, and (2) always give preference to the highest-priority process, even though that may mean swapping when swapping is not necessary. Suggest an intermediate policy that tries to balance the concerns of priority and performance.
3.6 Table 3.13 shows the process states for the VAX/VMS operating system.
a. Can you provide a justification for the existence of so many distinct wait states?
b. Why do the following states not have resident and swapped-out versions: Page
Fault Wait, Collided Page Wait, Common Event Wait, Free Page Wait, and Resource Wait?
c. Draw the state transition diagram and indicate the action or occurrence that
causes each transition.
3.7 The VAX/VMS operating system makes use of four processor access modes to facilitate the protection and sharing of system resources among processes. The access mode determines
• Instruction execution privileges: What instructions the processor may execute
• Memory access privileges: Which locations in virtual memory the current instruction may access
The four modes are as follows:
• Kernel: Executes the kernel of the VMS operating system, which includes memory
management, interrupt handling, and I/O operations
• Executive: Executes many of the OS service calls, including file and record (disk
and tape) management routines
• Supervisor: Executes other OS services, such as responses to user commands
• User: Executes user programs, plus utilities such as compilers, editors, linkers, and
debuggers
A process executing in a less-privileged mode often needs to call a procedure that executes in a more-privileged mode; for example, a user program requires an operating system service. This call is achieved by using a change-mode (CHM) instruction, which causes an interrupt that transfers control to a routine at the new access mode. A return is made by executing the REI (return from exception or interrupt) instruction.
a. A number of operating systems have two modes, kernel and user. What are the
advantages and disadvantages of providing four modes instead of two?
b. Can you make a case for even more than four modes?
3.8 The VMS scheme discussed in the preceding problem is often referred to as a ring protection structure, as illustrated in Figure 3.18. Indeed, the simple kernel/user scheme, as described in Section 3.3, is a two-ring structure. [SILB04] points out a problem with this approach:
The main disadvantage of the ring (hierarchical) structure is that it does not allow us to enforce the need-to-know principle. In particular, if an object must
be accessible in domain Dj but not accessible in domain Di, then we must have
j 6 i. But this means that every segment accessible in Di is also accessible in Dj.
Explain clearly what the problem is that is referred to in the preceding quote.
3.9 Figure 3.8b suggests that a process can only be in one event queue at a time.
a. Is it possible that you would want to allow a process to wait on more than one event at the same time? Provide an example.
b. In that case, how would you modify the queueing structure of the figure to support this new feature?
3.10 In a number of early computers, an interrupt caused the register values to be stored in fixed locations associated with the given interrupt signal. Under what circumstances is this a practical technique? Explain why it is inconvenient in general.
3.11 In Section 3.4, it was stated that UNIX is unsuitable for real-time applications because a process executing in kernel mode may not be preempted. Elaborate.
3.12 You have executed the following C program:
main ()
{ int pid;
pid = fork ();
printf (“%d \n”, pid); }
What are the possible outputs, assuming the fork succeeded?
4.1 It was pointed out that two advantages of using multiple threads within a process are that (1) less work is involved in creating a new thread within an existing process than in creating a new process, and (2) communication among threads within the same process is simplified. Is it also the case that a mode switch between two threads within the same process involves less work than a mode switch between two threads in different processes?
4.2 In the discussion of ULTs versus KLTs, it was pointed out that a disadvantage of ULTs is that when a ULT executes a system call, not only is that thread blocked, but also all of the threads within the process are blocked. Why is that so?
4.3 OS/2 is an obsolete OS for PCs from IBM. In OS/2, what is commonly embodied in the concept of process in other operating systems is split into three separate types of entities: session, processes, and threads. A session is a collection of one or more processes associated with a user interface (keyboard, display, and mouse). The session represents an interactive user application, such as a word processing program or a spreadsheet. This concept allows the personal-computer user to open more than one application, giving each one or more windows on the screen. The OS must keep track of which window, and therefore which session, is active, so that keyboard and mouse input are routed to the appropriate session. At any time, one session is in foreground mode, with other sessions in background mode. All keyboard and mouse input is directed to one of the processes of the foreground session, as dictated by the applications. When a session is in foreground mode, a process performing video output sends it directly to the hardware video buffer and thence to the user’s screen. When the session is moved to the background, the hardware video buffer is saved to a logical video buffer for that session. While a session is in background, if any of the threads of any of the processes of that session executes and produces screen output, that output is directed to the logical video buffer. When the session returns to foreground, the screen is updated to reflect the current contents of the logical video buffer for the new foreground session.
There is a way to reduce the number of process-related concepts in OS/2 from three to two. Eliminate sessions, and associate the user interface (keyboard, mouse, and screen) with processes. Thus, one process at a time is in foreground mode. For further structuring, processes can be broken up into threads.
a. What benefits are lost with this approach?
b. If you go ahead with this modification, where do you assign resources (memory,
files, etc.): at the process or thread level?
4.4 Consider an environment in which there is a one-to-one mapping between user-level
threads and kernel-level threads that allows one or more threads within a process to issue blocking system calls while other threads continue to run. Explain why this model can make multithreaded programs run faster than their single-threaded counterparts on a uniprocessor computer.
4.5 If a process exits and there are still threads of that process running, will they continue to run?
4.6 The OS/390 mainframe operating system is structured around the concepts of address space and task. Roughly speaking, a single address space corresponds to a single application and corresponds more or less to a process in other operating systems. Within an address space, a number of tasks may be generated and execute concurrently; this corresponds roughly to the concept of multithreading. Two data structures are key to managing this task structure. An address space control block (ASCB) contains information about an address space needed by OS/390 whether or not that address space is executing. Information in the ASCB includes dispatching priority, real and virtual memory allocated to this address space, the number of ready tasks in this address space, and whether each is swapped out. A task control block (TCB) represents a user program in execution. It contains information needed for managing a task within an address space, including processor status information, pointers to programs that are part of this task, and task execution state. ASCBs are global structures maintained in system memory, while TCBs are local structures maintained within their address space. What is the advantage of splitting the control information into global and local portions?
4.7 Many current language specifications, such as for C and C++, are inadequate for multithreaded programs. This can have an impact on compilers and the correctness of code, as this problem illustrates. Consider the following declarations and function definition:
       int global_positives = 0;
       typedef struct list {
           struct list *next;
           double val;
       } * list;
       void count_positives(list l)
       {
           list p;
           for (p = l; p; p = p -> next)
              if (p -> val > 0.0)
                 ++global_positives;
}
Now consider the case in which thread A performs
count_positives(<list containing only negative values>);
while thread B performs
       ++global_positives;
a. What does the function do?
b. The C language only addresses single-threaded execution. Does the use of two
parallel threads create any problems or potential problems?
4.8 But some existing optimizing compilers (including gcc, which tends to be relatively
conservative) will “optimize” count_positives to something similar to
       void count_positives(list l)
       {
list p;
           register int r;
       r = global_positives;
           for (p = l; p; p = p -> next)
              if (p -> val > 0.0) ++r;
           global_positives = r;
       }
What problem or potential problem occurs with this compiled version of the program if threads A and B are executed concurrently?
4.9 Consider the following code using the POSIX Pthreads API:
thread2.c
       #include <pthread.h>
       #include <stdlib.h>
       #include <unistd.h>
       #include <stdio.h>
       int myglobal;
           void *thread_function(void *arg) {
              int i,j;
              for ( i=0; i<20; i++ ) {
                 j=myglobal;
                 j=j+1;
                 printf(“.”);
                 fflush(stdout);
                 sleep(1);
                 myglobal=j;
}
return NULL;
                }
                int main(void) {
                   pthread_t mythread;
int i;
if ( pthread_create( &mythread, NULL, thread_function, NULL) ) {
                      printf(ldquo;error creating thread.”);
abort(); }
                for ( i=0; i<20; i++) {
                   myglobal=myglobal+1;
                   printf(“o”);
                   fflush(stdout);
                   sleep(1);
                }
                if ( pthread_join ( mythread, NULL ) ) {
                   printf(“error joining thread.”);
abort(); }
                printf(“\nmyglobal equals %d\n”,myglobal);
                exit(0);
                }
In main() we first declare a variable called mythread, which has a type of pthread_t. This is essentially an ID for a thread. Next, the if statement creates a thread associated with mythread. The call pthread_create() returns zero on success and a nonzero value on failure. The third argument of pthread_ create() is the name of a function that the new thread will execute when it starts. When this thread_function() returns, the thread terminates. Meanwhile, the main program itself defines a thread, so that there are two threads executing. The pthread_join function enables the main thread to wait until the new thread completes.
a. What does this program accomplish?
b. Here is the output from the executed program:
                $ ./thread2
                ..o.o.o.o.oo.o.o.o.o.o.o.o.o.o..o.o.o.o.o
                myglobal equals 21
Is this the output you would expect? If not, what has gone wrong?
4.10 The Solaris documentation states that a ULT may yield to another thread of the same priority. Isn’t it possible that there will be a runnable thread of higher priority and that therefore the yield function should result in yielding to a thread of the same or higher
priority?
4.11 In Solaris 9 and Solaris 10, there is a one-to-one mapping between ULTs and LWPs. In
Solaris 8, a single LWP supports one or more ULTs.
a. What is the possible benefit of allowing a many-to-one mapping of ULTs to
LWPs?
b. In Solaris 8, the thread execution state of a ULT is distinct from that of its LWP. Explain why.
c. Figure 4.17 shows the state transition diagrams for a ULT and its associated LWP in Solaris 8 and 9. Explain the operation of the two diagrams and their relationships.
4.12. Explain the rationale for the Uninterruptible state in Linux.
5.1 At the beginning of Section 5.1, it is stated that multiprogramming and multiprocessing present the same problems, with respect to concurrency. This is true as far as it goes. However, cite two differences in terms of concurrency between multiprogramming and multiprocessing.
5.2 Processes and threads provide a powerful structuring tool for implementing programs that would be much more complex as simple sequential programs. An earlier construct that is instructive to examine is the coroutine. The purpose of this problem is to introduce coroutines and compare them to processes. Consider this simple problem from [CONW63]:
Read 80-column cards and print them on 125-character lines, with the following changes. After every card image an extra blank is inserted, and every adjacent pair of asterisks (**) on a card is replaced by the character.
a. Develop a solution to this problem as an ordinary sequential program. You will find that the program is tricky to write. The interactions among the various elements of the program are uneven because of the conversion from a length of 80 to 125; furthermore, the length of the card image, after conversion, will vary depending on the number of double asterisk occurrences. One way to improve clarity, and to minimize the potential for bugs, is to write the application as three separate procedures. The first procedure reads in card images, pads each image with a blank, and writes a stream of characters to a temporary file. After all of the cards have been read, the second procedure reads the temporary file, does the character substitution, and writes out a second temporary file. The third procedure reads the stream of characters from the second temporary file and prints lines of 125 characters each.
b. The sequential solution is unattractive because of the overhead of I/O and temporary files. Conway proposed a new form of program structure, the coroutine, that allows the application to be written as three programs connected by one-character buffers (Figure 5.25). In a traditional procedure, there is a master/slave relationship between the called and calling procedure. The calling procedure may execute a call from any point in the procedure; the called procedure is begun at its entry point and returns to the calling procedure at the point of call. The coroutine exhibits a more symmetric relationship. As each call is made, execution takes up from the last active point in the called procedure. Because there is no sense in which a calling procedure is “higher” than the called, there is no return. Rather, any coroutine can pass control to any other coroutine with a resume command. The first time a coroutine is invoked, it is “resumed” at its entry point. Subsequently, the coroutine is reactivated at the point of its own last resume command. Note that only one coroutine in a program can be in execution at one time and that the transition points are explicitly defined in the code, so this is not an example of concurrent processing. Explain the operation of the program in Figure 5.25.
c. The program does not address the termination condition. Assume that the I/O routine READCARD returns the value true if it has placed an 80-character image in inbuf; otherwise it returns false. Modify the program to include this contingency. Note that the last printed line may therefore contain less than 125 characters.
d. Rewrite the solution as a set of three processes using semaphores.
An Application of Coroutines
5.3 Consider the following program:
           P1: {
        shared int x;
        x = 10;
        while (1) {
            x = x - 1;
            x = x + 1;
            if (x != 10)
printf(“x is %d”,x) }}
}} }}
printf(“x is %d”,x)
Note that the scheduler in a uniprocessor system would implement pseudo-parallel execution of these two concurrent processes by interleaving their instructions, without restriction on the order of the interleaving.
a. Show a sequence (i.e., trace the sequence of interleavings of statements) such that the statement “x is 10” is printed.
b. Show a sequence such that the statement “x is 8” is printed. You should remember that the increment/decrements at the source language level are not done atomically, that is, the assembly language code:
    LD    R0,X  /* load R0 from memory location x */
    INCR  R0    /* increment R0 */
    STO   R0,X  /* store the incremented value back in X */
implements the single C increment instruction (x = x + 1).
5.4 Consider the following program:
const int n = 50; int tally;
void total()
{
int count;
for (count = 1; count<= n; count++){
tally++; }
}
void main() {
tally = 0;
parbegin (total (), total ()); write (tally);
}
a. Determine the proper lower bound and upper bound on the final value of the shared variable tally output by this concurrent program. Assume processes can execute at any relative speed and that a value can only be incremented after it has been loaded into a register by a separate machine instruction.
b. Suppose that an arbitrary number of these processes are permitted to execute in parallel under the assumptions of part (a). What effect will this modification have on the range of final values of tally?
5.5 Is busy waiting always less efficient (in terms of using processor time) than a blocking wait? Explain.
5.6 Consider the following program:
boolean blocked [2]; int turn;
void P (int id)
{
while (true) { blocked[id] = true; while (turn != id) {
while (blocked[1-id]) /* do nothing */;
turn = id; }
                        /* critical section */
                        blocked[id] = false;
                        /* remainder */
} }
void main() {
blocked[0] = false; blocked[1] = false; turn = 0;
parbegin (P(0), P(1));
}
This software solution to the mutual exclusion problem for two processes is proposed in [HYMA66]. Find a counterexample that demonstrates that this solution is incorrect. It is interesting to note that even the Communications of the ACM was fooled on this one.
5.7 A software approach to mutual exclusion is Lamport’s bakery algorithm [LAMP74], so called because it is based on the practice in bakeries and other shops in which every customer receives a numbered ticket on arrival, allowing each to be served in turn. The algorithm is as follows:
boolean choosing[n]; int number[n]; while (true) {
choosing[i] = true;
number[i] = 1 + getmax(number[], n); choosing[i] = false;
for (int j = 0; j < n; j++){
while (choosing[j]) { };
while ((number[j] != 0) && (number[j],j) < (number[i],i)) { }; }
       /* critical section */;
       number [i] = 0;
       /* remainder */;
}
The arrays choosing and number are initialized to false and 0, respectively. The ith element of each array may be read and written by process i but only read by other processes. The notation (a, b) < (c, d) is defined as:
( a < c ) or ( a = c and b < d )
a. Describe the algorithm in words.
b. Show that this algorithm avoids deadlock.
c. Show that it enforces mutual exclusion.
5.8 Now consider a version of the bakery algorithm without the variable choosing. Then we have
1 int number[n]; 2 while (true) {
3
4
5 6}
7    /* critical section */;
8    number [i] = 0;
number[i] = 1 + getmax(number[], n); for (int j = 0; j < n; j++){
while ((number[j] != 0) && (number[j],j) < (number[i],i)) { };
    9    /* remainder */;
    10 }
Does this version violate mutual exclusion? Explain why or why not.
5.9 Consider the following program which provides a software approach to mutual
exclusion:
integer array control [1 :N]; integer k
where 1 ≤ k ≤ N, and each element of “control” is either 0, 1,
or 2. All elements of “control” are initially zero; the initial value of k is immaterial.
The program of the ith process (1 ≤ i ≤ N) is
begin integer j;
L0: control [i] := l;
LI: for j:=k step l until N, l step l until k do
begin
if j = i then goto L2;
if control [j] ≠ 0 then goto L1 end;
L2: control [i] := 2;
for j := 1 step 1 until N do
if j ≠ i and control [j] = L3: if control [k] ≠ 0 and k ≠ i L4: k := i;
2 then goto L0; then goto L0;
critical section;
L5: for j := k step 1 until N, 1 step 1 until k do
if j ≠ k and control [j] ≠ 0 then begin
k := j; goto L6
end;
L6: control [i] := 0;
L7: remainder of cycle; goto L0;
end
This is referred to as the Eisenberg-McGuire algorithm. Explain its operation and its key features.
5.10 Consider the first instance of the statement bolt = 0 in Figure 5.2b.
a. Achieve the same result using the exchange instruction.
b. Which method is preferable?
5.11 When a special machine instruction is used to provide mutual exclusion in the fashion of Figure 5.2, there is no control over how long a process must wait before being granted access to its critical section. Devise an algorithm that uses the compare&swap instruction but that guarantees that any process waiting to enter its critical section will do so within n – 1 turns, where n is the number of processes that may require access to the critical section and a “turn” is an event consisting of one process leaving the critical section and another process being granted access.
5.12 Consider the following definition of semaphores:
             void semWait(s)
             {
if (s.count > 0) { s.count--;
} else {
                   place this process in s.queue;
block; }
}
void semSignal (s) {
if (there is at least one process blocked on semaphore s) {
                     remove a process P from s.queue;
                     place process P on ready list;
                 }
else
}
Compare this set of definitions with that of Figure 5.3. Note one difference: With the preceding definition, a semaphore can never take on a negative value. Is there any difference in the effect of the two sets of definitions when used in programs? That is, could you substitute one set for the other without altering the meaning of the program?
5.13 Consider a sharable resource with the following characteristics: (1) As long as there are fewer than three processes using the resource, new processes can start using it right away. (2) Once there are three process using the resource, all three must leave before any new processes can begin using it. We realize that counters are needed to keep track of how many processes are waiting and active, and that these counters are themselves shared resources that must be protected with mutual exclusion. So we might create the following solution:
<CODE>
The solution appears to do everything right: All accesses to the shared variables are protected by mutual exclusion, processes do not block themselves while in the mutual exclusion, new processes are prevented from using the resource if there are (or were) three active users, and the last process to depart unblocks up to three waiting processes.
a. The program is nevertheless incorrect. Explain why.
b. Suppose we change the if in line 6 to a while. Does this solve any problem in the
program? Do any difficulties remain?
5.14 Now consider this correct solution to the preceding problem:
<CODE>
a. Explain how this program works and why it is correct.
b. This solution does not completely prevent newly arriving processes from cutting
in line but it does make it less likely. Give an example of cutting in line.
c. This program is an example of a general design pattern that is a uniform way to implement solutions to many concurrency problems using semaphores. It has been
referred to as the I’ll Do It For You pattern. Describe the pattern.
5.15 Now consider another correct solution to the preceding problem:
a. Explain how this program works and why it is correct.
Does this solution differ from the preceding one in terms of the number of processes that can be unblocked at a time? Explain.
This program is an example of a general design pattern that is a uniform way to implement solutions to many concurrency problems using semaphores. It has been referred to as the Pass The Baton pattern. Describe the pattern.
5.16 It should be possible to implement general semaphores using binary semaphores. We can use the operations semWaitB and semSignalB and two binary semaphores, delay and mutex. Consider the following:
<CODE>

Initially, s is set to the desired semaphore value. Each semWait operation decrements s, and each semSignal operation increments s. The binary semaphore mutex, which is initialized to 1, assures that there is mutual exclusion for the updating of s. The binary semaphore delay, which is initialized to 0, is used to block processes.
There is a flaw in the preceding program. Demonstrate the flaw and propose a change that will fix it. Hint: Suppose two processes each call semWait(s) when s is initially 0, and after the first has just performed semSignalB(mutex) but not performed semWaitB(delay), the second call to semWait(s) proceeds to the same point. All that you need to do is move a single line of the program.
5.17 In 1978, Dijkstra put forward the conjecture that there was no solution to the mutual exclusion problem avoiding starvation, applicable to an unknown but finite number of processes, using a finite number of weak semaphores. In 1979, J. M. Morris refuted this conjecture by publishing an algorithm using three weak semaphores. The behavior of the algorithm can be described as follows: If one or several process are waiting in a semWait(S) operation and another process is executing semSignal(S), the value of the semaphore S is not modified and one of the waiting processes is unblocked independently of semWait(S). Apart from the three semaphores, the algorithm uses two nonnegative integer variables as counters of the number of processes in certain sections of the algorithm. Thus, semaphores A and B are initialized to 1, while semaphore M and counters NA and NM are initialized to 0. The mutual exclusion semaphore B protects access to the shared variable NA. A process attempting to enter its critical section must cross two barriers represented by semaphores A and M. Counters NA and NM, respectively, contain the number of processes ready to cross barrier A and those having already crossed barrier A but not yet barrier M. In the second part of the protocol, the NM processes blocked at M will enter their critical sections one by one, using a cascade technique similar to that used in the first part. Define an algorithm that conforms to this description.
5.18 The following problem was once used on an exam:
Jurassic Park consists of a dinosaur museum and a park for safari riding. There are m passengers and n single-passenger cars. Passengers wander around the museum for a while, then line up to take a ride in a safari car. When a car is available, it loads the one passenger it can hold and rides around the park for a random amount of time. If the n cars are all out riding passengers around, then a passenger who wants to ride waits; if a car is ready to load but there are no waiting passengers, then the car waits. Use semaphores to synchronize the m passenger processes and the n car processes.
The following skeleton code was found on a scrap of paper on the floor of the exam room. Grade it for correctness. Ignore syntax and missing variable declarations. Remember that P and V correspond to semWait and semSignal.
<CODE>
5.19 In the commentary on Figure 5.9 and Table 5.4, it was stated that “it would not do simply to move the conditional statement inside the critical section (controlled by s) of the consumer because this could lead to deadlock.” Demonstrate this with a table similar to Table 5.4.
5.20 Consider the solution to the infinite-buffer producer/consumer problem defined in Figure 5.10. Suppose we have the (common) case in which the producer and consumer are running at roughly the same speed. The scenario could be:
Producer: append; semSignal; produce; ... ; append; semSignal; produce; ... Consumer: consume; ... ; take; semWait; consume; ... ; take; semWait; ...
The producer always manages to append a new element to the buffer and signal during the consumption of the previous element by the consumer. The producer is always appending to an empty buffer and the consumer is always taking the sole item in the buffer. Although the consumer never blocks on the semaphore, a large number of calls to the semaphore mechanism is made, creating considerable overhead.
Construct a new program that will be more efficient under these circumstances. Hints: Allow n to have the value –1, which is to mean that not only is the buffer empty but that the consumer has detected this fact and is going to block until the producer supplies fresh data. The solution does not require the use of the local variable m found in Figure 5.10.
5.21 Consider Figure 5.13. Would the meaning of the program change if the following were interchanged?
a. semWait(e);semWait(s)
b. semSignal(s);semSignal(n) c. semWait(n);semWait(s)
d. semSignal(s);semSignal(e)
5.22 The following pseudocode is a correct implementation of the producer/consumer problem with a bounded buffer:
Labels p1, p2, p3 and c1, c2, c3 refer to the lines of code shown above (p2 and c2 each cover three lines of code). Semaphores empty and full are linear semaphores that can take unbounded negative and positive values. There are multiple producer processes, referred to as Pa, Pb, Pc, etc., and multiple consumer processes, referred to as Ca, Cb, Cc, etc. Each semaphore maintains a FIFO (first-in-first-out) queue of blocked processes. In the scheduling chart below, each line represents the state of the buffer and semaphores after the scheduled execution has occurred. To simplify, we assume that scheduling is such that processes are never interrupted while executing a given portion of code p1, or p2, ..., or c3. Your task is to complete the following chart.
5.23 This problem demonstrates the use of semaphores to coordinate three types of processes.6 Santa Claus sleeps in his shop at the North Pole and can only be wakened by either (1) all nine reindeer being back from their vacation in the South Pacific, or (2) some of the elves having difficulties making toys; to allow Santa to get some sleep, the elves can only wake him when three of them have problems. When three elves are having their problems solved, any other elves wishing to visit Santa must wait for those elves to return. If Santa wakes up to find three elves waiting at his shop’s door, along with the last reindeer having come back from the tropics, Santa has decided that the elves can wait until after Christmas, because it is more important to get his sleigh ready. (It is assumed that the reindeer do not want to leave the tropics, and therefore they stay there until the last possible moment.) The last reindeer to arrive must get Santa while the others wait in a warming hut before being harnessed to the sleigh. Solve this problem using semaphores.
5.24 Show that message passing and semaphores have equivalent functionality by
a. Implementing message passing using semaphores. Hint: Make use of a shared
buffer area to hold mailboxes, each one consisting of an array of message slots.
b. Implementing a semaphore using message passing. Hint: Introduce a separate
synchronization process.
5.25 Explain what is the problem with this implementation of the one-writer many-readers
problem?
<CODE>
6.1 Show that the four conditions of deadlock apply to Figure 6.1a.
6.2 Show how each of the techniques of prevention, avoidance, and detection can be
applied to Figure 6.1.
6.3 For Figure 6.3, provide a narrative description of each of the six depicted paths, similar to the description of the paths of Figure 6.2 provided in Section 6.1.
6.4 It was stated that deadlock cannot occur for the situation reflected in Figure 6.3. Justify that statement.
6.5 Given the following state for the Banker’s Algorithm. 6 processes P0 through P5
4 resource types: A (15 instances); B (6 instances)
C (9 instances); D (10 instances)
Snapshot at time T0:
a. Verify that the Available array has been calculated correctly.
b. Calculate the Need matrix.
c. Show that the current state is safe, that is, show a safe sequence of processes. In
addition, to the sequence show how the Available (working array) changes as each
process terminates.
d. Given the request (3,2,3,3) from Process P5. Should this request be granted? Why
or why not?
6.6 In the code below, three processes are competing for six resources labeled A to F.
a. Using a resource allocation graph (Figures 6.5 and 6.6), show the possibility of a deadlock in this implementation.
b. Modify the order of some of the get requests to prevent the possibility of any deadlock. You cannot move requests across procedures, only change the order inside each procedure. Use a resource allocation graph to justify your answer.
6.7 A spooling system (Figure 6.16) consists of an input process I, a user process P, and an output process O connected by two buffers. The processes exchange data in blocks of equal size. These blocks are buffered on a disk using a floating boundary between the input and the output buffers, depending on the speed of the processes. The communication primitives used ensure that the following resource constraint is satisfied:
           where
i + o ... max
max = maximum number of blocks on disk i = number of input blocks on disk
Input buffer
o = number of output blocks on disk The following is known about the processes:
1. As long as the environment supplies data, process I will eventually input it to the disk (provided disk space becomes available).
2. As long as input is available on the disk, process P will eventually consume it and output a finite amount of data on the disk for each block input (provided disk space becomes available).
3. As long as output is available on the disk, process O will eventually consume it.
Show that this system can become deadlocked.
6.8 Suggest an additional resource constraint that will prevent the deadlock in Problem
6.7 but still permit the boundary between input and output buffers to vary in accordance with the present needs of the processes.
6.9 In the THE multiprogramming system [DIJK68], a drum (precursor to the disk for
secondary storage) is divided into input buffers, processing areas, and output buffers, with floating boundaries, depending on the speed of the processes involved. The current state of the drum can be characterized by the following parameters:
max = maximum number of pages on drum i = number of input pages on drum
p = number of processing pages on drum
o = number of output pages on drum
reso = minimum number of pages reserved for output resp = minimum number of pages reserved for processing
Formulate the necessary resource constraints that guarantee that the drum capacity is not exceeded and that a minimum number of pages is reserved permanently for output and processing.
6.10 In the THE multiprogramming system, a page can make the following state transitions:
1. empty : input buffer
2. input buffer : processing area
(input production) (input consumption) (output production)
(output consumption) (procedure call) (procedure return)
3. processing area : output
4. output buffer : empty
5. empty : processing area
6. processing area : empty
a. Define the effect of these
b. Can any of them lead to a
buffer
transitions in terms of the quantities i, o, and p.
deadlock if the assumptions made in Problem 6.6 about input processes, user processes, and output processes hold?
6.11 Consider a system with a total of 150 units of memory, allocated to three processes as
shown:
Apply the banker’s algorithm to determine whether it would be safe to grant each of the following requests. If yes, indicate a sequence of terminations that could be guaranteed possible. If no, show the reduction of the resulting allocation table.
a. A fourth process arrives, with a maximum memory need of 60 and an initial need
of 25 units.
b. A fourth process arrives, with a maximum memory need of 60 and an initial need
of 35 units.
6.12 Evaluate the banker’s algorithm for its usefulness in an OS.
6.13 A pipeline algorithm is implemented so that a stream of data elements of type T produced by a process P0 passes through a sequence of processes P1, P2, ..., Pn – 1, which operates on the elements in that order.
a. Define a generalized message buffer that contains all the partially consumed data
elements and write an algorithm for process Pi (0   i   n – 1), of the form
repeat
receive from predecessor; consume element;
send to successor:
forever
Assume P0 receives input elements sent by Pn – 1. The algorithm should enable the processes to operate directly on messages stored in the buffer so that copying is unnecessary.
b. Show that the processes cannot be deadlocked with respect to the common buffer.
6.14 Suppose the following two processes, foo and bar are executed concurrently and share the semaphore variables S and R (each initialized to 1) and the integer variable
x (initialized to 0).
a. Can the concurrent execution of these two processes result in one or both being blocked forever? If yes, give an execution sequence in which one or both are blocked forever.
b. Can the concurrent execution of these two processes result in the indefinite postponement of one of them? If yes, give an execution sequence in which one is indefinitely postponed.
6.15 Consider a system consisting of four processes and a single resource. The current state of the claim and allocation matrices are:
What is the minimum number of units of the resource needed to be available for this
state to be safe?
6.16 Consider the following ways of handling deadlock: (1) banker’s algorithm, (2) detect
deadlock and kill thread, releasing all resources, (3) reserve all resources in advance, (4) restart thread and release all resources if thread needs to wait, (5) resource ordering, and (6) detect deadlock and roll back thread’s actions.
a. One criterion to use in evaluating different approaches to deadlock is which
approach permits the greatest concurrency. In other words, which approach allows the most threads to make progress without waiting when there is no deadlock? Give a rank order from 1 to 6 for each of the ways of handling deadlock just listed, where 1 allows the greatest degree of concurrency. Comment on your ordering.
b. Another criterion is efficiency; in other words, which requires the least processor overhead. Rank order the approaches from 1 to 6, with 1 being the most efficient, assuming that deadlock is a very rare event. Comment on your ordering. Does your ordering change if deadlocks occur frequently?
6.17 Comment on the following solution to the dining philosophers problem. A hungry philosopher first picks up his left fork; if his right fork is also available, he picks up his right fork and starts eating; otherwise he puts down his left fork again and repeats the cycle.
6.18 Suppose that there are two types of philosophers. One type always picks up his left fork first (a “lefty”), and the other type always picks up his right fork first (a “righty”). The behavior of a lefty is defined in Figure 6.12. The behavior of a righty is as follows:
<CODE>
Prove the following:
a. Any seating arrangement of lefties and righties with at least one of each avoids deadlock.
b. Any seating arrangement of lefties and righties with at least one of each prevents starvation.
6.19 Figure 6.17 shows another solution to the dining philosophers problem using monitors. Compare to Figure 6.14 and report your conclusions.
6.20 In Table 6.3, some of the Linux atomic operations do not involve two accesses to a variable, such as atomic_read(atomic_t *v). A simple read operation is obviously atomic in any architecture. Therefore, why is this operation added to the repertoire of atomic operations?
6.21 Consider the following fragment of code on a Linux system. read_lock(&mr_rwlock);
write_lock(&mr_rwlock);
Where mr_rwlock is a reader–writer lock. What is the effect of this code?
6.22 The two variables a and b have initial values of 1 and 2, respectively. The following
code is for a Linux system:
What possible errors are avoided by the use of the memory barriers?
7.1 In Section 2.3, we listed five objectives of memory management, and in Section 7.1, we listed five requirements. Argue that each list encompasses all of the concerns addressed in the other.
7.2 Consider a fixed partitioning scheme with equal-size partitions of 216 bytes and a total main memory size of 224 bytes. A process table is maintained that includes a pointer to a partition for each resident process. How many bits are required for the pointer?
7.3 Consider a dynamic partitioning scheme. Show that, on average, the memory contains half as many holes as segments.
7.4 To implement the various placement algorithms discussed for dynamic partitioning (Section 7.2), a list of the free blocks of memory must be kept. For each of the three methods discussed (best-fit, first-fit, next-fit), what is the average length of the search?
7.5 Another placement algorithm for dynamic partitioning is referred to as worst-fit. In this case, the largest free block of memory is used for bringing in a process.
a. Discuss the pros and cons of this method compared to first-, next-, and best-fit.
b. What is the average length of the search for worst-fit?
7.6 This diagram shows an example of memory configuration under dynamic partitioning, after a number of placement and swapping-out operations have been carried out. Addresses go from left to right; gray areas indicate blocks occupied by processes; white areas indicate free memory blocks. The last process placed is 2-Mbyte and is marked with an X. Only one process was swapped out after that.
1 M
a. What was the maximum size of the swapped out process?
b. What was the size of the free block just before it was partitioned by X?
c. A new 3-Mbyte allocation request must be satisfied next. Indicate the intervals of
memory where a partition will be created for the new process under the following four placement algorithms: best-fit, first-fit, next-fit, worst-fit. For each algorithm, draw a horizontal segment under the memory strip and label it clearly.
7.7 A 1-Mbyte block of memory is allocated using the buddy system.
a. Show the results of the following sequence in a figure similar to Figure 7.6: Request 70;
Request 35; Request 80; Return A; Request 60; Return B; Return D; Return C.
b. Show the binary tree representation following Return B.
7.8 Consider a buddy system in which a particular block under the current allocation has an address of 011011110000.
a. If the block is of size 4, what is the binary address of its buddy?
b. If the block is of size 16, what is the binary address of its buddy?
7.9 Let buddyk(x)   address of the buddy of the block of size 2k whose address is x. Write a general expression for buddyk(x).
7.10 The Fibonacci sequence is defined as follows:
F0   0, F1   1, Fn+2   Fn+1 + Fn, n   0
a. Could this sequence be used to establish a buddy system?
b. What would be the advantage of this system over the binary buddy system
described in this chapter?
7.11 During the course of execution of a program, the processor will increment the contents
of the instruction register (program counter) by one word after each instruction fetch, but will alter the contents of that register if it encounters a branch or call instruction that causes execution to continue elsewhere in the program. Now consider Figure 7.8. There are two alternatives with respect to instruction addresses:
• Maintain a relative address in the instruction register and do the dynamic address translation using the instruction register as input. When a successful branch or call is encountered, the relative address generated by that branch or call is loaded into the instruction register.
• Maintain an absolute address in the instruction register. When a successful branch or call is encountered, dynamic address translation is employed, with the results stored in the instruction register.
Which approach is preferable?
7.12 Consider a simple paging system with the following parameters: 232 bytes of physical memory; page size of 210 bytes; 216 pages of logical address space.
a. How many bits are in a logical address?
b. How many bytes in a frame?
c. How many bits in the physical address specify the frame?
d. How many entries in the page table?
e. How many bits in each page table entry? Assume each page table entry contains a
valid/invalid bit.
7.13 Write the binary translation of the logical address 0001010010111010 under the
following hypothetical memory management schemes, and explain your answer:
a. a paging system with a 256-address page size, using a page table in which the frame
number happens to be four times smaller than the page number
b. a segmentation system with a 1K-address maximum segment size, using a segment table in which bases happen to be regularly placed at real addresses: 22   4,096
segment #
7.14 Consider a simple segmentation system that has the following segment table:
For each of the following logical addresses, determine the physical address or indicate if a segment fault occurs:
a. 0, 198
b. 2, 156
c. 1, 530
d. 3, 444
e. 0, 222
7.15 Consider a memory in which contiguous segments S1, S2,...,Sn are placed in their order of creation from one end of the store to the other, as suggested by the following figure:
When segment Sn+1 is being created, it is placed immediately after segment Sn even though some of the segments S1, S2,...,Sn may already have been deleted. When the boundary between segments (in use or deleted) and the hole reaches the other end of the memory, the segments in use are compacted.
a. Show that the fraction of time F spent on compacting obeys the following inequality:
FÚ1-f wherek=t-1 1 + kf 2s
where
s   average length of a segment, in words
t   average lifetime of a segment, in memory references
f   fraction of the memory that is unused under equilibrium conditions
Hint: Find the average speed at which the boundary crosses the memory and
assume that the copying of a single word requires at least two memory references.
b. FindFforf 0.2,t 1,000,ands 50.

8.1 Suppose the page table for the process currently executing on the processor looks like the following. All numbers are decimal, everything is numbered starting from zero, and all addresses are memory byte addresses. The page size is 1,024 bytes.
a. Describe exactly how, in general, a virtual address generated by the CPU is translated into a physical main memory address.
b. What physical address, if any, would each of the following virtual addresses correspond to? (Do not try to handle any page faults, if any.)
(i) 1,052
(ii) 2,221
(iii) 5,499
8.2 Consider the following program.
#define Size 64
int A[Size; Size], B[Size; Size], C[Size; Size]; int register i, j;
for (j = 0; j< Size; j ++) for (i = 0; i< Size; i++)
        C[i; j] = A[i; j] + B[i; j];
Assume that the program is running on a system using demand paging and the page size is 1 Kilobyte. Each integer is 4 bytes long. It is clear that each array requires a 16-page space. As an example, A[0, 0]-A[0, 63], A[1, 0]-A[1, 63], A[2, 0]-A[2, 63], and A[3, 0]-A[3, 63] will be stored in the first data page. A similar storage pattern can be derived for the rest of array A and for arrays B and C. Assume that the system allocates a 4-page working set for this process. One of the pages will be used by the program and three pages can be used for the data. Also, two index registers are assigned for i and j (so, no memory accesses are needed for references to these two variables).
a. Discuss how frequently the page fault would occur (in terms of number of times C[i, j]   A[i, j]   B[i, j] are executed).
b. Can you modify the program to minimize the page fault frequency?
c. What will be the frequency of page faults after your modification?
8.3 a.
b. Assume you want to implement a hashed inverted page table for the same
How much memory space is needed for the user page table of Figure 8.4?
addressing scheme as depicted in Figure 8.4, using a hash function that maps the 20-bit page number into a 6-bit hash value. The table entry contains the page number, the frame number, and a chain pointer. If the page table allocates space for up to 3 overflow entries per hashed entry, how much memory space does the hashed inverted page table take?
8.4 Consider the following string of page references 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2. Complete a figure similar to Figure 8.15, showing the frame allocation for:
a. FIFO (first-in-first-out)
b. LRU (least recently used)
c. Clock
d. Optimal (assume the page reference string continues with 1, 2, 0, 1, 7, 0, 1)
e. List the total number of page faults and the miss rate for each policy. Count page
faults only after all frames have been initialized.
8.5 A process references five pages, A, B, C, D, and E, in the following order:
A; B; C; D; A; B; E; A; B; C; D; E
Assume that the replacement algorithm is first-in-first-out and find the number of page transfers during this sequence of references starting with an empty main memory with three page frames. Repeat for four page frames.
8.6 A process contains eight virtual pages on disk and is assigned a fixed allocation of four page frames in main memory. The following page trace occurs:
1, 0, 2, 2, 1, 7, 6, 7, 0, 1, 2, 0, 3, 0, 4, 5, 1, 5, 2, 4, 5, 6, 7, 6, 7, 2, 4, 2, 7, 3, 3, 2, 3
a. Show the successive pages residing in the four frames using the LRU replacement policy. Compute the hit ratio in main memory. Assume that the frames are initially empty.
b. Repeat part (a) for the FIFO replacement policy.
c. Compare the two hit ratios and comment on the effectiveness of using FIFO to
approximate LRU with respect to this particular trace.
8.7 In the VAX, user page tables are located at virtual addresses in the system space. What
is the advantage of having user page tables in virtual rather than main memory? What
is the disadvantage?
8.8 Suppose the program statement
for(i = 1;i 6= n;i ++) a[i] = b[i] + c[i];
is executed in a memory with page size of 1,000 words. Let n   1,000. Using a machine that has a full range of register-to-register instructions and employs index registers, write a hypothetical program to implement the foregoing statement. Then show the sequence of page references during execution.
8.9 The IBM System/370 architecture uses a two-level memory structure and refers to the two levels as segments and pages, although the segmentation approach lacks many of the features described earlier in this chapter. For the basic 370 architecture, the page size may be either 2 Kbytes or 4 Kbytes, and the segment size is fixed at either 64 Kbytes or 1 Mbyte. For the 370/XA and 370/ESA architectures, the page size is 4 Kbytes and the segment size is 1 Mbyte. Which advantages of segmentation does this scheme lack? What is the benefit of segmentation for the 370?
8.10 Assuming a page size of 4 Kbytes and that a page table entry takes 4 bytes, how many levels of page tables would be required to map a 64-bit address space, if the top level page table fits into a single page?
8.11 Consider a system with memory mapping done on a page basis and using a singlelevel page table. Assume that the necessary page table is always in memory.
a. If a memory reference takes 200 ns, how long does a paged memory reference take?
b. Now we add an MMU that imposes an overhead of 20 ns on a hit or a miss. If
we assume that 85% of all memory references hit in the MMU TLB, what is the
Effective Memory Access Time (EMAT)?
c. Explain how the TLB hit rate affects the EMAT.
8.12 Consider a page reference string for a process with a working set of M frames, initially all empty. The page reference string is of length P with N distinct page numbers in it. For any page replacement algorithm,
a. What is a lower bound on the number of page faults?
b. What is an upper bound on the number of page faults?
8.13 In discussing a page replacement algorithm, one author makes an analogy with a
snowplow moving around a circular track. Snow is falling uniformly on the track and a lone snowplow continually circles the track at constant speed. The snow that is plowed w the track disappears from the system.
a. For which of the page replacement algorithms discussed in Section 8.2 is this a
useful analogy?
b. What does this analogy suggest about the behavior of the page replacement algorithm in question?
8.14 In the S/370 architecture, a storage key is a control field associated with each page-sized frame of real memory. Two bits of that key that are relevant for page replacement are the reference bit and the change bit. The reference bit is set to 1 when any address within the frame is accessed for read or write, and is set to 0 when a new page is loaded into the frame. The change bit is set to 1 when a write operation is performed on any location within the frame. Suggest an approach for determining which page frames are least-recently-used, making use of only the reference bit.
8.15 Consider the following sequence of page references (each element in the sequence
represents a page number): 12345213323454511325
1k
Define the mean working set size after the kth reference as sk( ) = k a 0 W(t, ) 0
t=1 1k
and define the missing page probability after the kth reference as mk( ) = k a F(t, ) t=1
where F(t,  )   1 if a page fault occurs at virtual time t and 0 otherwise.
a. Draw a diagram similar to that of Figure 8.19 for the reference sequence just
defined for the values     1, 2, 3, 4, 5, 6. b. Plot s20( ) as a function of  .
c. Plot m20( ) as a function of  .
8.16 A key to the performance of the VSWS resident set management policy is the value of Q. Experience has shown that, with a fixed value of Q for a process, there are considerable differences in page fault frequencies at various stages of execution. Furthermore, if a single value of Q is used for different processes, dramatically different frequencies of page faults occur. These differences strongly indicate that a mechanism that would dynamically adjust the value of Q during the lifetime of a process would improve the behavior of the algorithm. Suggest a simple mechanism for this purpose.
8.17 Assume that a task is divided into four equal-sized segments and that the system builds an eight-entry page descriptor table for each segment. Thus, the system has a combination of segmentation and paging. Assume also that the page size is 2 Kbytes.
a. What is the maximum size of each segment?
b. What is the maximum logical address space for the task?
c. Assume that an element in physical location 00021ABC is accessed by this task.
What is the format of the logical address that the task generates for it? What is the
maximum physical address space for the system?
8.18 Consider a paged logical address space (composed of 32 pages of 2 Kbytes each)
mapped into a 1-Mbyte physical memory space.
a. What is the format of the processor’s logical address?
b. What is the length and width of the page table (disregarding the “access rights”
bits)?
c. What is the effect on the page table if the physical memory space is reduced by
half?
8.19 The UNIX kernel will dynamically grow a process’s stack in virtual memory as needed, but it will never try to shrink it. Consider the case in which a program calls a C subroutine that allocates a local array on the stack that consumes 10 K. The kernel will expand the stack segment to accommodate it. When the subroutine returns, the stack pointer is adjusted and this space could be released by the kernel, but it is not released. Explain why it would be possible to shrink the stack at this point and why the UNIX kernel does not shrink it.

9.1 Consider the following workload:
a. Show the schedule using shortest remaining time, nonpreemptive priority (a smaller priority number implies higher priority) and round robin with quantum 30 ms. Use time scale diagram as shown below for the FCFS example to show the schedule for each requested scheduling policy.
b. What is the average waiting time of the above scheduling policies?
9.2 Consider the following set of processes:
9.3
9.4 9.5
9.6
9.7
9.8
9.9
Perform the same analysis as depicted in Table 9.5 and Figure 9.5 for this set.
Prove that, among nonpreemptive scheduling algorithms, SPN provides the minimum average waiting time for a batch of jobs that arrive at the same time. Assume that the scheduler must always execute a task if one is available.
Assume the following burst-time pattern for a process: 6, 4, 6, 4, 13, 13, 13, and assume that the initial guess is 10. Produce a plot similar to those of Figure 9.9.
Consider the following pair of equations as an alternative to Equation (9.3):
Sn+1 =aTn +(1-a)Sn
Xn+1 = min[Ubound,max[Lbound,(bSn+1)]]
where Ubound and Lbound are prechosen upper and lower bounds on the estimated value of T. The value of Xn + 1 is used in the shortest-process-next algorithm, instead of the value of Sn + 1. What functions do a and b perform, and what is the effect of higher and lower values on each?
In the bottom example in Figure 9.5, process A runs for two time units before control is passed to process B. Another plausible scenario would be that A runs for three time units before control is passed to process B. What policy differences in the feedback scheduling algorithm would account for the two different scenarios?
In a nonpreemptive uniprocessor system, the ready queue contains three jobs at time t immediately after the completion of a job. These jobs arrived at times t1, t2, and t3 with estimated execution times of r1, r2, and r3, respectively. Figure 9.18 shows the linear increase of their response ratios over time. Use this example to find a variant of response ratio scheduling, known as minimax response ratio scheduling, that minimizes the maximum response ratio for a given batch of jobs ignoring further arrivals. (Hint: Decide, first, which job to schedule as the last one.)
Prove that the minimax response ratio algorithm of the preceding problem minimizes the maximum response ratio for a given batch of jobs. (Hint: Focus attention on the job that will achieve the highest response ratio and all jobs executed before it. Consider the same subset of jobs scheduled in any other order and observe the response ratio of the job that is executed as the last one among them. Notice that this subset may now be mixed with other jobs from the total set.)
Define residence time Tr as the average total time a process spends waiting and being served. Show that for FIFO, with mean service time Ts, we have Tr = Ts/(1 – r), where r is utilization.
ready process for the next cycle by dividing a maximum response time by the number
of processes requiring service. Is this a reasonable policy?
9.14 Which type of process is generally favored by a multilevel feedback queueing
scheduler—a processor-bound process or an I/O-bound process? Briefly explain why.
9.15 In priority-based process scheduling, the scheduler only gives control to a particular process if no other process of higher priority is currently in the Ready state. Assume that no other information is used in making the process scheduling decision. Also assume that process priorities are established at process creation time and do not change. In a system operating with such assumptions, why would using Dekker’s solution (see Section A.1) to the mutual exclusion problem be “dangerous”? Explain this
by telling what undesired event could occur and how it could occur.
9.16 Five batch jobs, A through E, arrive at a computer center at essentially the same time. They have an estimated running time of 15, 9, 3, 6, and 12 minutes, respectively. Their (externally defined) priorities are 6, 3, 7, 9, and 4, respectively, with a lower value corresponding to a higher priority. For each of the following scheduling algorithms, determine the turnaround time for each process and the average turnaround for all jobs. Ignore process switching overhead. Explain how you arrived at your answers. In the last three cases, assume that only one job at a time runs until it finishes and that all jobs are completely processor bound.
a. round robin with a time quantum of 1 minute
b. priority scheduling
c. FCFS (run in order 15, 9, 3, 6, and 12)
d. shortest job first

10.1 Consider a set of three periodic tasks with the execution profiles of Table 10.6. Develop scheduling diagrams similar to those of Figure 10.5 for this set of tasks.
10.2 Consider a set of five aperiodic tasks with the execution profiles of Table 10.7. Develop scheduling diagrams similar to those of Figure 10.6 for this set of tasks.
10.3 Least laxity first (LLF) is a real-time scheduling algorithm for periodic tasks. Slack time, or laxity, is the amount of time between when a task would complete if it started now and its next deadline. This is the size of the available scheduling window. Laxity can be expressed as
Laxity = (deadline time) - (current time) - (processor time needed)
LLF selects the task with the minimum laxity to execute next. If two or more tasks have the same minimum laxity value, they are serviced on a FCFS basis.
a. Suppose a task currently has a laxity of t. By how long may the scheduler delay
starting this task and still meet its deadline?
b. Suppose a task currently has a laxity of 0. What does this mean?
c. What does it mean if a task has negative laxity?
d. Consider a set of three periodic tasks with the execution profiles of Table 10.8a.
Develop scheduling diagrams similar to those of Figure 10.4 for this set of tasks that compare rate monotonic, earliest deadline first, and LLF. Assume preemption may occur at 5-ms intervals. Comment on the results.
10.4 Repeat Problem 10.3d for the execution profiles of Table 10.8b. Comment on the results.
10.5 Maximum urgency first (MUF) is a real-time scheduling algorithm for periodic tasks. Each task is assigned an urgency that is defined as a combination of two fixed priorities and one dynamic priority. One of the fixed priorities, the criticality, has precedence over the dynamic priority. Meanwhile, the dynamic priority has precedence over the other fixed priority, called the user priority. The dynamic priority is inversely
proportional to the laxity of a task. MUF can be explained as follows. First, tasks are ordered from shortest to longest period. Define the critical task set as the first N tasks such that worst-case processor utilization does not exceed 100%. Among critical set tasks that are ready, the scheduler selects the task with the least laxity. If no critical set tasks are ready, the schedule chooses among the noncritical tasks the one with the least laxity. Ties are broken through an optional user priority and then by FCFS. Repeat Problem 10.3d, adding MUF to the diagrams. Assume that user-defined priorities are A highest, B next, C lowest. Comment on the results.
10.6 Repeat Problem 10.4, adding MUF to the diagrams. Comment on the results.
10.7 This problem demonstrates that although Equation (10.2) for rate monotonic scheduling is a sufficient condition for successful scheduling, it is not a necessary condition (i.e., sometimes successful scheduling is possible even if Equation (10.2) is
not satisfied).
a. Consider a task set with the following independent periodic tasks:
• Task P1: C1 = 20; T1 = 100
• Task P2: C2 = 30; T2 = 145
Can these tasks be successfully scheduled using rate monotonic scheduling?
b. Now add the following task to the set:
• Task P3: C3 = 68; T3 = 150 Is Equation (10.2) satisfied?
c. Suppose that the first instance of the preceding three tasks arrives at time t = 0. Assume that the first deadline for each task is the following:
D1 =100; D2 =145; D3 =150
Using rate monotonic scheduling, will all three deadlines be met? What about deadlines for future repetitions of each task?
10.8 Draw a diagram similar to that of Figure 10.9b that shows the sequence events for this same example using priority ceiling.
11.1 Consider a program that accesses a single I/O device and compare unbuffered I/O to the use of a buffer. Show that the use of the buffer can reduce the running time by at most a factor of two.
11.2 Generalize the result of Problem 11.1 to the case in which a program refers to n devices.
11.3 a.
b.
Perform the same type of analysis as that of Table 11.2 for the following sequence of disk track requests: 27, 129, 110, 186, 147, 41, 10, 64, 120. Assume that the disk head is initially positioned over track 100 and is moving in the direction of decreasing track number.
Do the same analysis, but now assume that the disk head is moving in the direction
of increasing track number.
11.4 Consider a disk with N tracks numbered from 0 to (N - 1) and assume that requested
sectors are distributed randomly and evenly over the disk. We want to calculate the average number of tracks traversed by a seek.
a. Calculate the probability of a seek of length j when the head is currently positioned over track t. (Hint: This is a matter of determining the total number of combinations, recognizing that all track positions for the destination of the seek are equally likely.)
b. Calculate the probability of a seek of length K, for an arbitrary current position of the head. (Hint: This involves the summing over all possible combinations of movements of K tracks.)
c. Calculate the average number of tracks traversed by a seek, using the formula for expected value
N-1
E[x]= ai* Pr[x=i]
n Hint: Use the equalities a =
i=0 n(n + 1)
;
n n(n + 1)(2n + 1) ai2 = 6 . i=1
  2
d. Show that for large values of N, the average number of tracks traversed by a seek
i=1
approaches N/3.
11.5 The following equation was suggested both for cache memory and disk cache memory:
TS =TC +M*TD
Generalize this equation to a memory hierarchy with N levels instead of just 2.
11.6 For the frequency-based replacement algorithm (Figure 11.9), define Fnew, Fmiddle, and Fold as the fraction of the cache that comprises the new, middle, and old sections,
respectively. Clearly, Fnew + Fmiddle + Fold = 1. Characterize the policy when a. Fold =1-Fnew
b. Fold = 1/(cache size)
11.7 Calculate how much disk space (in sectors, tracks, and surfaces) will be required to store 300,000 120-byte logical records if the disk is fixed sector with 512 bytes/ sector, with 96 sectors/track, 110 tracks per surface, and 8 usable surfaces. Ignore any file header record(s) and track indexes, and assume that records cannot span two sectors.
11.8 Consider the disk system described in Problem 11.7, and assume that the disk rotates at 360 rpm. A processor reads one sector from the disk using interrupt-driven I/O, with one interrupt per byte. If it takes 2.5 μs to process each interrupt, what percentage of the time will the processor spend handling I/O (disregard seek time)?
11.9 Repeat the preceding problem using DMA, and assume one interrupt per sector.
11.10 A 32-bit computer has two selector channels and one multiplexor channel. Each selector channel supports two magnetic disk and two magnetic tape units. The multiplexor
channel has two line printers, two card readers, and ten VDT terminals connected to
it. Assume the following transfer rates:
Disk drive Magnetic tape drive Line printer
Card reader
VDT
800 Kbytes/s 200 Kbytes/s 6.6 Kbytes/s 1.2 Kbytes/s 1 Kbyte/s
Estimate the maximum aggregate I/O transfer rate in this system.
11.11 It should be clear that disk striping can improve the data transfer rate when the strip size is small compared to the I/O request size. It should also be clear that RAID 0 provides improved performance relative to a single large disk, because multiple I/O requests can be handled in parallel. However, in this latter case, is disk striping necessary? That is, does disk striping improve I/O request rate performance compared to a
comparable disk array without striping?
11.12 Consider a 4-drive, 200 GB-per-drive RAID array. What is the available data storage capacity for each of the RAID levels, 0, 1, 3, 4, 5, and 6?
12.1 Define:
B   block size
R   record size
P   size of block pointer
F   blocking factor; expected number of records within a block
Give a formula for F for the three blocking methods depicted in Figure 12.8.
12.2 One scheme to avoid the problem of preallocation versus waste or lack of contiguity is to allocate portions of increasing size as the file grows. For example, begin with a portion size of one block, and double the portion size for each allocation. Consider a file of n records with a blocking factor of F, and suppose that a simple one-level index is used as a file allocation table.
a. Give an upper limit on the number of entries in the file allocation table as a function of F and n.
b. What is the maximum amount of the allocated file space that is unused at any time?
12.3 What file organization would you choose to maximize efficiency in terms of speed of access, use of storage space, and ease of updating (adding/deleting/modifying) when the data are
a. updated infrequently and accessed frequently in random order?
b. updated frequently and accessed in its entirety relatively frequently?
c. updated frequently and accessed frequently in random order?
12.4 For the B-tree in Figure 12.4c, show the result of inserting the key 97.
12.5 An alternative algorithm for insertion into a B-tree is the following: As the insertion
algorithm travels down the tree, each full node that is encountered is immediately split, even though it may turn out that the split was unnecessary.
a. What is the advantage of this technique?
b. What are the disadvantages?
12.6 Both the search and the insertion time for a B-tree are a function of the height of the tree. We would like to develop a measure of the worst-case search or insertion time. Consider a B-tree of degree d that contains a total of n keys. Develop an inequality that shows an upper bound on the height h of the tree as a function of d and n.
12.7 Ignoring overhead for directories and file descriptors, consider a file system in which files are stored in blocks of 16K bytes. For each of the following file sizes, calculate the percentage of wasted file space due to incomplete filling of the last block: 41,600 bytes; 640,000 bytes; 4.064,000 bytes.
12.8 What are the advantages of using directories?
12.9 Directories can be implemented either as “special files” that can only be accessed in
limited ways or as ordinary data files. What are the advantages and disadvantages of
each approach?
12.10 Some operating systems have a tree–structured file system but limit the depth of the
tree to some small number of levels. What effect does this limit have on users? How
does this simplify file system design (if it does)?
12.11 Consider a hierarchical file system in which free disk space is kept in a free space list.
a. Suppose the pointer to free space is lost. Can the system reconstruct the free space list?
b. Suggest a scheme to ensure that the pointer is never lost as a result of a single memory failure.
12.12 In UNIX System V, the length of a block is 1 Kbyte, and each block can hold a total of 256 block addresses. Using the inode scheme, what is the maximum size of a file?
12.13 Consider the organization of a UNIX file as represented by the inode (Figure 12.16). Assume that there are 12 direct block pointers, and a singly, doubly, and triply indirect pointer in each inode. Further, assume that the system block size and the disk sector size are both 8K. If the disk block pointer is 32 bits, with 8 bits to identify the physical disk and 24 bits to identify the physical block, then
a. What is the maximum file size supported by this system?
b. What is the maximum file system partition supported by this system?
c. Assuming no information other than that the file inode is already in main memory,
how many disk accesses are required to access the byte in position 13,423,956?
13.1 With reference to the device driver interface to the eCos kernel (Table 13.2), it is recommended that device drivers should use the _intsave() variants to claim and release spinlocks rather than the non-_intsave() variants. Explain why.
13.2 Also in Table 13.2, it is recommended that cyg_drv_spinlock_spin should be used sparingly, and in situations where deadlocks/livelocks cannot occur. Explain why.
13.3 In Table 13.2, what should be the limitations on the use of cyg_drv_spinlock_ destroy? Explain.
13.4 In Table 13.2, what limitations should be placed in the use of cyg_drv_mutex_ destroy?
13.5 Why does the eCos bitmap scheduler not support time slicing?
13.6 The implementation of mutexes within the eCos kernel does not support recursive locks. If a thread has locked a mutex and then attempts to lock the mutex again, typically as a result of some recursive call in a complicated call graph, then either an assertion failure will be reported or the thread will deadlock. Suggest a reason for
this policy.
13.7 Figure 13.14 is a listing of code intended for use on the eCos kernel.
a. Explain the operation of the code. Assume thread B begins execution first and thread A begins to execute after some event occurs.
b. What would happen if the mutex unlock and wait code execution in the call to cyg_cond_wait, on line 30, were not atomic?
c. Why is the while loop on line 26 needed?
13.8 The discussion of eCos spinlocks included an example showing why spinlocks should
not be used on a uniprocessor system if two threads of different priorities can compete for the same spinlock. Explain why the problem still exists even if only threads of the same priority can claim the same spinlock.
13.9 TinyOS’s scheduler serves tasks in FIFO order. Many other schedulers for TinyOS have been proposed, but none have caught on. What characteristics of the sensornet domain might cause a lack of need for more complex scheduling?
13.10 a. The TinyOS Resource interface does not allow a component that already has a request in the queue for a resource to make a second request. Suggest a reason.
b. However, the TinyOS Resource interface allows a component holding the resource lock to re-request the lock. This request is enqueued for a later grant. Suggest a reason for this policy. Hint: What might cause there to be latency between one component releasing a lock and the next requester being granted it?

14.1 Consider an automated teller machine (ATM) in which users provide a personal identification number (PIN) and a card for account access. Give examples of confidentiality, integrity, and availability requirements associated with the system and, in each case, indicate the degree of importance of the requirement.
14.2 Repeat the preceding problem for a telephone switching system that routes calls through a switching network based on the telephone number requested by the caller.
14.3 Consider a desktop publishing system used to produce documents for various
organizations.
a. Give an example of a type of publication for which confidentiality of the stored
data is the most important requirement.
b. Give an example of a type of publication in which data integrity is the most important requirement.
c. Give an example in which system availability is the most important requirement.

14.4 For each of the following assets, assign a low, moderate, or high impact level for the
loss of confidentiality, availability, and integrity, respectively. Justify your answers.
a. An organization managing public information on its Web server.
b. A law enforcement organization managing extremely sensitive investigative
information.
c. A financial organization managing routine administrative information (not privacy related information).
d. An information system used for large acquisitions in a contracting organization
contains both sensitive, pre-solicitation phase contract information and routine administrative information. Assess the impact for the two data sets separately and the information system as a whole.
e. A power plant contains a SCADA (supervisory control and data acquisition) system controlling the distribution of electric power for a large military installation. The SCADA system contains both real-time sensor data and routine administrative information. Assess the impact for the two data sets separately and the information system as a whole.
14.5 Assume that passwords are selected from four-character combinations of 26 alphabetic characters. Assume that an adversary is able to attempt passwords at a rate of one per second.
a. Assuming no feedback to the adversary until each attempt has been completed, what is the expected time to discover the correct password?
b. Assuming feedback to the adversary flagging an error as each incorrect character is entered, what is the expected time to discover the correct password?
14.6 There is a flaw in the virus program of Figure 14.1. What is it?
14.7 The question arises as to whether it is possible to develop a program that can analyze
a piece of software to determine if it is a virus. Consider that we have a program D that is supposed to be able to do that. That is, for any program P, if we run D(P), the result returned is TRUE (P is a virus) or FALSE (P is not a virus). Now consider the following program:
             Program CV :=
              { ...
              main-program :=
                       {if D(CV) then goto next:
next: }
}
else infect-executable;
In the preceding program, infect-executable is a module that scans memory for executable programs and replicates itself in those programs. Determine if D can correctly decide whether CV is a virus.
14.8 The point of this problem is to demonstrate the type of puzzles that must be solved in the design of malicious code and therefore, the type of mind-set that one wishing to counter such attacks must adopt.
a. Consider the following C program:
             begin
                  print (*begin print (); end.*);
end
What do you think the program was intended to do? Does it work?
b. Answer the same questions for the following program:
char [] = {’0’, ’ ’, ’}’, ’;’, ’m’, ’a’, ’i’, ’n’, ’(’, ’)’, ’{’, and so on... ’t’, ’)’, ’0’};
main () {
                        int I;
                        printf(*char t[] = (*);
                        for (i=0; t[i]!=0; i=i+1)
                             printf(“%d, “, t[i]);
                        printf(“%s”, t);
}
c. What is the specific relevance of this problem to this chapter?
14.9 Consider the following fragment:
                    legitimate code
if data is Friday the 13th; crash_computer();
legitimate code
What type of malicious software is this?
14.10 Consider the following fragment in an authentication program:
username = read_username(); password = read_password(); if username is “133t h4ck0r”
return ALLOW_LOGIN;
if username and password are valid
return ALLOW_LOGIN else return DENY_LOGIN
What type of malicious software is this?
14.11 The following code fragments show a sequence of virus instructions and a polymorphic version of the virus. Describe the effect produced by the metamorphic code.
15.1 Explain the suitability or unsuitability of the following passwords:
a. YK 334
b. mfmitm (for “my favorite
movie is tender mercies”) c. Natalie1
d. Washington
e. Aristotle f. tv9stove g. 12345678 h. dribgib
15.2 An early attempt to force users to use less predictable passwords involved computer supplied passwords. The passwords were eight characters long and were taken from the character set consisting of lowercase letters and digits. They were generated by a pseudorandom number generator with 215 possible starting values. Using the technology of the time, the time required to search through all character strings of length 8 from a 36-character alphabet was 112 years. Unfortunately, this is not a true reflection of the actual security of the system. Explain the problem.
15.3 Assume that passwords are selected from four-character combinations of 26 alphabetic characters. Assume that an adversary is able to attempt passwords at a rate of one per second.
a. Assuming no feedback to the adversary until each attempt has been completed,
what is the expected time to discover the correct password?
b. Assuming feedback to the adversary flagging an error as each incorrect character
is entered, what is the expected time to discover the correct password?
15.4 Assume that source elements of length k are mapped in some uniform fashion into a target elements of length p. If each digit can take on one of r values, then the number of source elements is rk and the number of target elements is the smaller number rp.
A particular source element xi is mapped to a particular target element yj.
a. What is the probability that the correct source element can be selected by an adversary on one try?
b. What is the probability that a different source element xk (xi ≠ xk) that results in
the same target element, yj, could be produced by an adversary?
c. What is the probability that the correct target element can be produced by an
adversary on one try?
15.5 Assume that passwords are limited to the use of the 95 printable ASCII characters
and that all passwords are 10 characters in length. Assume a password cracker with an encryption rate of 6.4 million encryptions per second. How long will it take to test exhaustively all possible passwords on a UNIX system?
15.6 Because of the known risks of the UNIX password system, the SunOS-4.0 documentation recommends that the password file be removed and replaced with a publicly readable file called /etc/publickey. An entry in the file for user A consists of a user’s identifier IDA, the user’s public key, PUa, and the corresponding private key, PRa. This private key is encrypted using DES with a key derived from the user’s login password Pa. When A logs in, the system decrypts E(Pa, PRa) to obtain PRa.
a. The system then verifies that Pa was correctly supplied. How?
b. How can an opponent attack this system?
15.7 It was stated that the inclusion of the salt in the UNIX password scheme increases the difficulty of guessing by a factor of 4096. But the salt is stored in plaintext in the same entry as the corresponding ciphertext password. Therefore, those two characters are known to the attacker and need not be guessed. Why is it asserted that the salt increases security?
15.8 Assuming that you have successfully answered the preceding problem and understand the significance of the salt, here is another question. Wouldn’t it be possible to thwart completely all password crackers by dramatically increasing the salt size to, say, 24 or 48 bits?
15.9 For the DAC model discussed in Section 15.2, an alternative representation of the protection state is a directed graph. Each subject and each object in the protection state is represented by a node (a single node is used for an entity that is both subject and object). A directed line from a subject to an object indicates an access right, and the label on the link defines the access right.
a. Draw a directed graph that corresponds to the access matrix of Figure 12.15a.
b. Draw a directed graph that corresponds to the access matrix of Figure 15.4.
c. Is there a one-to-one correspondence between the directed graph representation
and the access matrix representation? Explain.
15.10 UNIX treats file directories in the same fashion as files; that is, both are defined by
the same type of data structure, called an inode. As with files, directories include a 9-bit protection string. If care is not taken, this can create access control problems. For example, consider a file with protection mode 644 (octal) contained in a directory with protection mode 730. How might the file be compromised in this case?
15.11 In the traditional UNIX file access model, UNIX systems provide a default setting for newly created files and directories, which the owner may later change. The default is typically full access for the owner combined with one of the following: no access for group and other, read/execute access for group and none for other, or read/execute access for both group and other. Briefly discuss the advantages and disadvantages of each of these cases, including an example of a type of organization where each would be appropriate.
15.12 Consider user accounts on a system with a Web server configured to provide access to user Web areas. In general, this scheme uses a standard directory name, such as public_ html, in a user’s home directory. This acts as the user’s Web area if it exists. However, to allow the Web server to access the pages in this directory, it must have at least search (execute) access to the user’s home directory, read/execute access to the Web directory, and read access to any Web pages in it. Consider the interaction of this requirement with the cases you discussed for the preceding problem. What consequences does this requirement have? Note that a Web server typically executes as a special user, and in a group that is not shared with most users on the system. Are there some circumstances when running such a Web service is simply not appropriate? Explain.
15.13 Assume a system with N job positions. For job position i, the number of individual users in that position is Ui and the number of permissions required for the job position is Pi.
a. For a traditional DAC scheme, how many relationships between users and permissions must be defined?
b. For a RBAC scheme, how many relationships between users and permissions must
be defined?
15.14 In the context of an IDS, we define a false positive to be an alarm generated by an IDS
in which the IDS alerts to a condition that is actually benign. A false negative occurs when an IDS fails to generate an alarm when an alert-worthy condition is in effect. Using the following diagram, depict two curves that roughly indicate false positives and false negatives, respectively.
16.1 Let   be the percentage of program code that can be executed simultaneously by n computers in a cluster, each computer using a different set of parameters or initial conditions. Assume that the remaining code must be executed sequentially by a single processor. Each processor has an execution rate of x MIPS.
a. Derive an expression for the effective MIPS rate when using the system for exclusive execution of this program, in terms of n,   , and x.
b. If n   16 and x   4 MIPS, determine the value of that will yield a system performance of 40 MIPS.
16.2 An application program is executed on a nine-computer cluster. A benchmark program takes time T on this cluster. Further, 25% of T is time in which the application is running simultaneously on all nine computers. The remaining time, the application has to run on a single computer.
a. Calculate the effective speedup under the aforementioned condition as compared to executing the program on a single computer. Also calculate, the percentage of code that has been parallelized (programmed or compiled so as to use the cluster mode) in the preceding program.
b. Suppose that we are able to effectively use 18 computers rather than 9 computers on the parallelized portion of the code. Calculate the effective speedup that is achieved.
16.3 The following FORTRAN program is to be executed on a computer, and a parallel version is to be executed on a 32-computer cluster.
<CODE>
Suppose lines 2 and 4 each take two machine cycle times, including all processor and memory-access activities. Ignore the overhead caused by the software loop control statements (lines 1, 3, 5) and all other system overhead and resource conflicts.
a. What is the total execution time (in machine cycle times) of the program on a single computer?
b. Divide the I-loop iterations among the 32 computers as follows: Computer 1 executes the first 32 iterations (I   1 to 32), processor 2 executes the next 32 iterations, and so on. What are the execution time and speedup factor compared with part (a)? (Note that the computational workload, dictated by the J-loop, is unbalanced among the computers.)
c. Explain how to modify the parallelizing to facilitate a balanced parallel execution of all the computational workload over 32 computers. A balanced load means an equal number of additions assigned to each computer with respect to both loops.
d. What is the minimum execution time resulting from the parallel execution on 32 computers? What is the resulting speedup over a single computer?
