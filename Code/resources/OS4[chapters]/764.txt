Recovery and Fault Tolerance


                                                          Chapte                        r  19
Recovery and Fault
Tolerance
A fault may damage the state of some data or processes. Several things could
      go wrong if a fault occurs during operation of a system--data consistency
      could be lost, a server could malfunction, resources and services could
become unavailable, or the system could cease operation. To provide reliable
operation, an OS avoids such consequences of faults using three approaches
called recovery, fault tolerance, and resiliency.
Recovery in a distributed system uses the notion of rollbacks, discussed earlier
in Chapter 13. When a fault occurs, some data or processes would be rolled back
to states that were recorded before the fault. However, a rollback of one of the
processes of a distributed computation may force rollbacks of a few of its other
processes to ensure mutual consistency of process states. This requirement is
called the domino effect. Normal operation of a computation would be resumed
after recovery is completed; however, the computation may have to reexecute
some actions it had performed before the fault occurred.
Fault tolerance provides uninterrupted operation of a system by repair-
ing the states of data or processes affected by a fault, rather than by rolling
them back to recorded states. The resiliency approach tries to minimize the cost
of reexecution when faults occur. Resiliency is achieved through special tech-
niques for (1) remembering useful results computed in a subcomputation and
using them directly, i.e., without reexecution, after a fault and (2) reexecuting a
subcomputation, rather than a complete computation, when a fault occurs.
We begin this chapter with an overview of different classes of faults and
various ways of dealing with them. Subsequent sections discuss recovery, fault
tolerance and resiliency.
19.1  FAULTS, FAILURES, AND RECOVERY                                                 ·
A fault like a power outage or a memory read error may damage the state of
a system. For reliable operation, the system should be restored to a consistent
state, and its operation should be resumed. Recovery is the generic name for all
approaches used for this purpose.
                                                                                           743



744  Part 5  Distributed Operating Systems
                                                                 System         Behavior
                                                                 State
                                 Before                                         Expected
                                 fault                                          behavior
                                                                         Fault
                                            error
                                                                 State
                                 After                                          Unexpected
                                 fault                                          behavior;
                                                                                i.e., failure
                   Figure  19.1  Fault, error, and  failure  in  a system.
                      A fault like a power outage is noticed readily, whereas a fault like a damaged
                   disk block becomes noticeable only when the resulting loss of data causes an
                   unexpected behavior of the system or an unusual situation in it. Such unexpected
                   behavior or situation is called a failure. Figure 19.1 illustrates how a failure arises.
                   A fault causes an error, which is a part of the system state that is erroneous. An
                   error causes unexpected behavior of the system, which is a failure. Example 19.1
                   discusses a fault, an error and a failure in a banking system.
·
     Example 19.1  Fault, Error, and Failure
                   Bank accounts A and B contain $1000 and $250, respectively. A banking
                   application transfers $100 from account A to account B. A power outage
                   occurs after it deducts $100 from the balance in account A, but before it adds
                   $100 to the balance in account B. The power outage is a fault. The error is that
                   $100 has been deducted from account A but has not been added to account B.
                   The failure is that $100 has vanished!
                   ·
                      A recovery is performed when a failure is noticed. Figure 19.2 illustrates the
                   state of a system during normal operation, after a fault, and after recovery. The
                   system is initiated in state S0 at time 0. A fault occurs at time t1. The consequent
                   failure is detected at ti. The system would have been in state Si at time ti if the fault
                   had not occurred; however, it is actually in state Si . A recovery procedure applies
                   a correction  S to the state and makes the system ready to resume its operation.
                   The resulting state would depend on the recovery procedure employed. Let the
                   resulting state be called Snew. It would be ideal if Snew = Si; however, the nature
                   of a fault, the failure caused by it, and the recovery approach would determine
                   whether it could be so.



                                                                Chapter 19  Recovery and Fault Tolerance  745
                                          A failure
                  A fault                 is noticed  Si
                  occurs                                           Recovery
                                                          S        actions change
                                                          Snew     the state
              S0  S1                                  Si
              0   t1                                  ti     Time
Figure  19.2     Recovery after a fault.
19.1.1 Classes of Faults
A fault may affect a computer system, affect only a process in the system, or
affect hardware components such as memory and the communication hardware.
Accordingly, faults are classified into system, process, storage, and communica-
tion faults. Within a class of faults, a fault model describes those properties of
a fault that determine the kinds of errors and failures that might result from a
fault.
A system fault is a system crash caused by a power outage or by compo-
nent faults. System faults are classified into amnesia and partial amnesia faults,
depending on how much state information is lost when a fault occurs. In an
amnesia fault, the system completely "forgets" the state it was in when the fault
occurred. In a partial amnesia fault, the system "forgets" some components of its
state when the fault occured. File servers typically suffer partial amnesia faults
because they lose the data or metadata that was stored in memory or on a disk
that failed. A fail-stop system fault is one that brings a system to a halt. This
characteristic is convenient in practice because it permits an external observer,
whether a person or a computer system, to know when a fault has occurred. It
also provides an opportunity to recover or repair the system state before putting
the system back into operation.
A process that suffers a Byzantine fault may perform malicious or arbi-
trary actions. It is not possible to undo such actions when a failure is noticed.
Hence Byzantine faults are handled by using redundant processes and agreement
protocols. In this approach, several processes are created to perform the same
computation. If their results do not match, the system uses an agreement proto-
col to decide which of them is the correct result. Processes producing incorrect
results are identified and aborted before they perform any data updates; others
are permitted to perform updates and continue their operation.
A typical storage fault occurs because of a bad block on a storage medium.
It makes some data unreadable. The occurrence of a storage fault may be detected
by error checking techniques (see Section 14.3), or it may be noticed when data is
accessed. Storage faults are basically partial amnesia faults, however they could
be made nonamnesia faults by using software techniques such as disk mirroring.



746  Part 5  Distributed Operating Systems
             Communication faults are caused by link or transmission faults. These faults are
             nonamnesia faults because the networking software includes sufficient buffering
             and error handling capability to ensure that messages are not lost.
             In Section 19.2, we discuss how Byzantine faults are handled in practice.
             The rest of this chapter assumes faults to be non-Byzantine.
             19.1.2 Overview of Recovery Techniques
             For non-Byzantine faults, recovery involves restoring a system or an application
             to a consistent state. It involves reexecuting some actions that were performed
             before the fault occurred. Recovery techniques can be classified into data recovery,
             process recovery, fault tolerance, and resiliency. These techniques have differ-
             ent implications for reliability, response times to computations, and the cost of
             recovery. Table 19.1 summarizes their features.
             Data recovery techniques guard against loss of data in a file through backups.
             Backups are created periodically during normal operation. When a fault occurs,
             a file is restored to the state found in its latest backup (see Section 13.11). Data
             recovery techniques incur substantial reexecution overhead if backups are created
             at large intervals and high overhead during normal operation if they are created
             frequently. So deciding the frequency of backups involves a trade-off.
             Process recovery techniques employ checkpoints to record the state of a pro-
             cess and its file processing activities. This operation is called checkpointing. When
             a fault occurs, the recovery procedure sets the state of a process to that found in
             a checkpoint. This operation is called a rollback of the process. It incurs the cost
             of reexecuting the actions that were performed after the checkpoint was taken.
             The tradeoff between the cost of a rollback and the overhead of checkpointing
             during normal operation is analogous to that in data recovery techniques.
             Table 19.1        Recovery Techniques
             Technique                      Description
             Data recovery                  A backup is a recording of the state of a file. When a fault
                                            occurs, the state of the file is set to that found in its latest
                                            backup (see Section 13.11).
             Process recovery               A checkpoint is a recording of the state of a process and its file
                                            processing activities. A process is recovered by setting its state to
                                            that found in a checkpoint that was taken before a fault
                                            occurred. This action is called a rollback.
             Fault tolerance                The error in state caused by a fault is corrected without
                                            interrupting the system's operation.
             Resiliency                     Special techniques are employed to reduce the cost of fault
                                            tolerance--fewer results that were produced in a computation
                                            before a fault occurred are recomputed after the fault.



                                    Chapter 19                   Recovery and Fault      Tolerance  747
Fault tolerance techniques enable a system or an application to continue its
operation despite the occurrence of a fault. A fault tolerance technique recovers
the system or the application to a consistent state that differs only marginally, if
at all, from the state the system would have been in if the fault had not occurred.
Results of some computations that were in progress at the time when a fault
occurred may be lost. These computations have to be reexecuted.
Resiliency techniques ensure that some of the results that were produced
by a computation that was in progress when a fault occurred would be used in
the computation after the fault. It reduces reexecution costs and degradation of
response times due to a fault.
Backward and Forward Recovery       Recovery approaches are classified into two
broad classes. Backward recovery implies resetting the state of an entity or an
application affected by a fault to some prior state and resuming its operation from
that state. It involves reexecution of some actions that were performed before a
fault. Forward recovery is based on repairing the erroneous state of a system so
that the system can continue its operation. The repair cost depends on the nature
of the computation and may involve a certain amount of reexecution.
Backward recovery is simpler to implement than forward recovery. However,
it requires a practical method of producing a consistent state recording of a
system. This aspect poses obvious difficulties in a distributed system. Another
weakness of the backward recovery technique is that an application may not make
any progress if faults occur frequently. A major advantage of forward recovery
is that the operation of a system or an application continues from the repaired
state rather than from some previous state as in backward recovery. This feature
guarantees forward progress of a computation with time for certain classes of
faults.
19.2     BYZANTINE FAULTS AND AGREEMENT PROTOCOLS                                                   ·
Because of the difficulty in undoing wrong actions, recovery from Byzantine faults
has been studied only in the restricted context of agreement between processes.
The agreement problem is motivated by the Byzantine generals problem where a
group of generals have to decide whether to attack the enemy. The generals and
their armies are located in different geographical locations, hence generals have
to depend on exchange of messages to arrive at a decision. Possible faults are
that messages may get lost, or some generals may be traitors who deliberately
send out confusing messages. An agreement protocol is designed to arrive at an
agreement in spite of such faults.
Three agreement problems have been defined in literature. In the Byzantine
agreement problem one process starts the agreement protocol by broadcasting a
single value to all other processes. A process that receives the value broadcasts it to
other processes. A nonfaulty process broadcasts the same value that it receives.
A faulty process may broadcast an arbitrary value; it may even send different
values to different processes. Processes may have to perform many rounds of



748  Part 5  Distributed Operating Systems
             broadcasts before an agreement is reached. The problem requires all nonfaulty
             processes to agree on the same value. This value should be the same as the value
             broadcast by the initiator if the initiator is a nonfaulty process; otherwise, it could
             be any value. In the consensus problem, each process has its own initial value and
             all nonfaulty processes have to agree on a common value. In the interactive con-
             sistency problem, nonfaulty processes have to agree on a set of values. We discuss
             only the Byzantine agreement problem.
                     Lamport et al. (1982) developed an agreement protocol for use when pro-
             cesses may fail but messages are delivered without fail. It involves m + 1 rounds
             of information exchange, where the number of faulty processes is  m. However,
             there are some restrictions on the value of m. Agreement is possible only if the
             total number of processes exceeds 3 times the number of faulty processes. An
             impossibility result states that a group of three processes containing one faulty
             process cannot reach agreement.
                     The impossibility result is easy to prove if the initiator is a faulty process.
             Let process P1, the initiator, send values 0 and 1 to processes P2 and P3. Process
             P2 will send 0 to process P3. Now, process P3 has received two different values
             from two processes. It cannot decide which of the two is the correct value. A similar
             situation arises if P1 is a nonfaulty initiator and sends 1 to P2 and P3, but process
             P2 is faulty and sends 0 to process P3. Agreement would have been possible
             if  the system contained       n  processes,   n    4,  and  the  following  algorithm    was
             used:
                 1.  The initiator sends its value to every other process.
                 2.  A process receiving the value from the initiator sends it to all processes other
                     than itself and the initiator.
                 3.  Each process forms a collection of n - 1 values containing one value received
                     from the initiator in Step 1 and n - 2 values received from other processes
                     in Step 2. If it did not receive a value from the initiator or from some other
                     process, it would assume an arbitrary value 0. It uses the value appearing the
                     majority of times in this collection.
             This is  the  algorithm followed        for   a single Byzantine  fault,  i.e., for m   =  1.
             The algorithm for m > 1 is quite complex, hence we do not discuss it here.
             19.3     RECOVERY                                                                          ·
             A recovery scheme consists of two components. The checkpointing algorithm
             decides when a process should take a checkpoint. We will use the notation Cij to
             denote the jth checkpoint taken by process Pi. The recovery algorithm rolls back
             some processes to their states recorded in checkpoints such that the new process
             states are mutually consistent. Example 19.2 illustrates the fundamental issue in
             the design of checkpointing and recovery algorithms.



                                                                   Chapter  19  Recovery and Fault Tolerance        749
                          C11    C12            C13
             P1
                                 C21m1     C22            C23
             P2
                               C31 C32     m2             m3
             P3
                                                                   tf
Figure 19.3  Checkpoints  of processes in  a distributed  system.
                                                                                                                    ·
Checkpointing and Recovery                                                                        Example     19.2
Figure 19.3 shows the timing diagram of a distributed computation whose
processes P1 - P3 operate in nodes N1 - N3, respectively. C11, C12 and C13
are the checkpoints taken by process P1. Similarly C21, C22, C23, and C31, C32
are the checkpoints taken by processes P2 and P3, respectively. We denote the
state recorded in <checkpoint> as state(<checkpoint>). Let processes P1, P2
and P3 be in the states s1, s2 and s3, respectively, at time instant tf . Hence the
distributed computation is in the state S  {s1, s2, s3}. Let a failure occur in
node N3 at time instant tf . A naive recovery algorithm simply rolls back process
P3 to its latest checkpoint, i.e., C32. However, the new state of the computation,
{s1, s2, state(C32)}, is not a consistent state because P2 has received message
m3 in state s2 but P3 has not sent m3 in state(C32), which is its new state (see
Definition 17.1).
                                                                                               ·
From Example 19.2 it is clear that the state of a process cannot be recovered
in isolation. A recovery algorithm should restore the state of the computation to a
state S in which states of all pairs of processes are mutually consistent according
to Definition 17.1. Hence the goal of a recovery algorithm is to make the following
decisions for each process Pi in a distributed computation:
1. Decide whether process Pi should be rolled back.
2. If so, identify a checkpoint Cij to which Pi should be rolled back.
In Example 19.2, the distributed computation could be recovered to the state
{s1, state(C22), state(C32)}. We discuss a basis for such recovery in the following.
Definition 19.1 Orphan Message             A message mk sent by process Pi to process
Pj is an orphan message in the state S  {s1, . . . , si, . . . , sj , . . . , sn} of a system
if sj , the state of process Pj , records mk as received but si, the state of process
Pi, does not record it as sent.
An orphan message is a message that has been received by its destination
process, but it is disowned by its sender because of recovery. Hence the states of its
sender and destination processes are inconsistent. This inconsistency is removed



750  Part 5  Distributed Operating Systems
             by rolling back its destination process to some state in which it had not received
             the orphan message. This effect is called the domino effect. In Example 19.2, m3
             becomes an orphan message when P3 is rolled back to the state in C32. Hence
             P2 should be rolled back to some checkpoint that was taken before P2 received
             message m3, for example, to checkpoint C22. If process P2 had sent a message m4
             to P1 after C22 and process P1 had received this message in state s1, the domino
             effect would force a rollback of process P1 as well.
                Using these ideas, checkpointing and recovery can be performed in one of
             two ways. The checkpointing algorithm would permit individual processes to
             take checkpoints at will. This method is called asynchronous checkpointing. At a
             fault, the recovery algorithm would roll back processes one by one in accordance
             with the domino effect. Alternatively, the checkpointing algorithm would coor-
             dinate the checkpointing actions of processes to ensure that the process states
             in the checkpoints are mutually consistent. This method is called synchronous
             checkpointing, and the collection of process checkpoints produced by it is called a
             synchronous checkpoint. When applied to the system of Figure 19.3, a synchronous
             checkpointing  algorithm       would  produce  either  the  synchronous  checkpoint
             {C11, C21, C31} or the synchronous checkpoint {C12, C22, C32}. The recovery algo-
             rithm would simply roll back each process to its individual checkpoint in the latest
             synchronous checkpoint.
             19.4  FAULT TOLERANCE TECHNIQUES                                                        ·
             The basic principle in fault tolerance is to ensure that a fault either does not cause
             an error, or the error can be removed easily. In some earlier chapters and sections,
             we saw how fault tolerance techniques ensure that no error in state would arise due
             to process, storage, and communication faults: Section 19.2 described how pro-
             cess faults of a Byzantine nature can be tolerated, Section 13.11.2.2 discussed how
             the stable storage technique tolerates storage faults, and Section 16.4 discussed
             an arrangement involving acknowledgment and retransmission of messages to
             tolerate communication faults.
                In this section, we discuss two facets of the tolerance of system faults that
             follow the fail-stop model.
             ·  Fault tolerance for replicated data: Despite a fault, data should be avail-
                able and applications should see values resulting from the latest update
                operation.
             ·  Fault tolerance for distributed data: Despite a fault, mutual consistency of
                different parts of the data should not be affected.
             19.4.1 Logs, Forward Recovery, and Backward Recovery
             A log is a record of actions or activities in a process. Two kinds of logs are used
             in practice:
             · Do logs: A do log records those actions that should be performed to ensure
                correctness of state of an entity or a system. A do log is also called a redo log



                                                            Chapter 19  Recovery and Fault  Tolerance  751
   because actions recorded in it may be performed more than once if a fault
   occurs. Do logs are used to implement forward recovery.
·  Undo logs: An undo log contains a record of those actions that should be
   undone to remove an error in state caused by occurrence of a fault. Undo
   logs are used to implement backward recovery.
   A write-ahead logging principle is used to construct a log--a process writes
information concerning an action it intends to take into a log before performing
the action. This way, the log would contain all information necessary to achieve
the correct state should a fault occur before the action is completed. A log could
be an operation log, which contains a list of actions to be performed so that entities
in the system would achieve correct states, or a value log, which contains a list of
values or data images that should be assigned to entities.
   The  implementation  scheme    for   an  atomic         action  discussed  in  Sec-
tion 13.11.2.2 used an intentions list. The intentions list is a value log that is
used as a redo log. Being a value log, recovery actions that use it are idempotent;
this property is needed because entries in the log would be processed more than
once if faults occur during commit processing. Recovery using the intentions
list constitutes forward recovery. If the subactions in an atomic action directly
updated data, an undo log would have to be maintained so that the actions could
be undone if a fault occurred before the atomic action could commit. The undo
log would contain data images taken before updates were performed. Its use to
undo data updates constitutes backward recovery.
   The idea of atomic execution of a sequence of operations on a file can be
extended to operations involving several files. A language construct called the
atomic transaction is provided in a programming language or a database query
language for this purpose. It has the following syntax:
        begin transaction <transaction id>
                        {Access and modify files}
                        if <condition>
                                  then abort transaction;
                        {Access and modify files}
        end transaction <transaction id>
   An atomic transaction has an all-or-nothing property like an atomic action.
Its execution commences when a process executes the begin transaction statement.
The atomic transaction is said to commit if the process executes the end trans-
action statement. All files modified by the atomic transaction would be updated
consistently at this time. If the process executes the abort transaction statement,
or if a fault occurs before the transaction commits, execution of the transaction
would be aborted and no file updates would be made. In this case, all files would
remain in their original states.
19.4.2 Handling Replicated Data
Availability of data D can be provided through replication. We can make n copies
of D, n > 1 and locate them strategically in the system such that at least one copy
of D would be accessible from any node despite anticipated faults in the system.



752  Part 5  Distributed Operating Systems
             If data D may be modified, it is essential to use rules that would ensure correctness
             of data access and updates. We use the following rules:
             1. Many processes can concurrently read D.
             2. Only one process can write a new value into D at any time.
             3. Reading and writing cannot be performed concurrently.
             4. A process reading D must see the latest value of D.
             Rules  1­3  are  analogous     to  rules  of  the  readers  and  writers  problem           of
             Section 6.7.2. Rule 4 addresses a special issue in data replication.
             Quorum Algorithms              A quorum is the number of copies of D that must be accessed
             to perform a specific operation on D. Quorum algorithms ensure adherence to
             Rules 1­4 by specifying a read quorum Qr and a write quorum Qw. Two kinds of
             locks are used on D. A read lock is a shared lock, and a write lock is an exclusive
             lock. A process requesting a read lock is granted the lock if D is presently unlocked
             or if it is already under a read lock. Request for a write lock is granted only if D is
             presently unlocked. Processes use read and write quorums while accessing D, so
             a process can read D after putting a read lock on Qr copies of D, and can write
             D after putting a write lock on Qw copies of D.
             Since a read lock is a shared lock, any value of Qr would satisfy Rule 1. For
             implementing Rules 2 and 3, we choose Qr and Qw such that
                                                      2 × Qw > n                       (19.1)
                                                Qr + Qw > n                            (19.2)
             Equation (19.2) also ensures that a reader will always lock at least one copy that
             participated in the latest write operation. This copy contains the latest value of
             D, so Eq. (19.2) also satisfies Rule 4.
             A choice of values that satisfies Eqs. (19.1) and (19.2) is Qr = 1 and Qw = n.
             With these quorums, a read operation is much faster than a write operation.
             It would be appropriate if read operations are more frequent than write opera-
             tions. Many other quorum values are also possible. If write operations are more
             frequent, we could choose values of Qr and Qw such that Eqs. (19.1) and (19.2)
             are satisfied and Qw is as small as possible. If Qw = n, a writer would not update
             all copies of D, so a reader would access some copies of D that contain its latest
             value, and some copies that contain its old values. To be able to identify the latest
             value, we could associate a timestamp with each copy of D to indicate when it was
             last modified.
             The choice of Qr = 1 and Qw = n is not fault tolerant. Qw = n implies that a
             process would have to put locks on all n copies of D in order to perform a write
             operation. Hence a writer would be unable to write if even one node containing
             a copy of D failed or became inaccessible to it. If a system is required to tolerate
             faults in up to k nodes, we could choose
                                                Qr = k + 1
                                                Qw = n - k
                                                n>2×k



                                                     Chapter 19  Recovery and Fault Tolerance  753
These quorum sizes are large, however it is unavoidable because Eq. (19.1) is
essential to ensure consistency of data and Eq. (19.2) is essential to ensure that
reading and writing are not performed concurrently.
19.4.3 Handling Distributed Data
A distributed transaction (also called a multisite transaction) is a facility for manip-
ulating files located in different nodes of a distributed system in a mutually
consistent manner. Each node participating in a distributed transaction Ti con-
tains a transaction manager. It maintains information about data updates to be
made on behalf of the transaction, which could be similar to the intentions list
of atomic actions (see Section 13.11.2.2). In addition, it also maintains a log
that is local to it. The node where the transaction was initiated contains a trans-
action coordinator. The coordinator implements the all-or-nothing property of
transactions through the two-phase commit protocol, also called the 2PC pro-
tocol. It initiates this protocol when the application executes the statement end
transaction Ti. In the first phase the protocol checks whether each participating
node can commit the updates of the transaction. Depending on responses from
participating nodes, it decides whether to commit or abort the transaction. In the
second phase, it informs its decision to each participating node, so that it could
commit or abort accordingly. The 2PC protocol is presented as Algorithm 19.1.
Algorithm 19.1    Two-Phase Commit Protocol
Phase 1:
1.  Actions of the transaction coordinator: Write the record prepare Ti in the log.
    Set a time-out interval  and send a prepare Ti message to each participat-
    ing node. Wait until either each participating node replies, or a time-out
    occurs.
2.  Actions of a participating node: On receiving a prepare Ti message, the partici-
    pating node decides whether it is ready to commit. If so, it writes information
    about data updates to be made, followed by the record prepared Ti in its
    log and sends a prepared Ti reply to the coordinator. Otherwise, it writes
    the record abandoned Ti in its log and sends an abandoned Ti reply to the
    coordinator.
Phase 2:
1.  Actions of the transaction coordinator: If each participating node sent a pre-
    pared Ti reply, write the record commit Ti in its log and send a commit Ti
    message to each participating node. If a participating node sent an abandoned
    Ti message, or a time-out occurred, write the record abort Ti in its log and
    send an abort Ti message to each participating node. In either case, wait until
    an acknowledgment is received from each participating node, and write a
    complete Ti record in its log.



754  Part 5  Distributed Operating Systems
             2. Actions of a participating node: Write the record commit Ti or abort Ti in
             the log in accordance with the coordinator's message and send an acknowl-
             edgment to the coordinator. Perform either commit processing or abort
             processing accordingly, and release locks on the data.
             The 2PC protocol handles failure of a participating node as follows: If a
             participating node fails before the 2PC protocol was initiated by the coordinator,
             on recovery it would not find a prepared or abandoned record for the transaction
             in its log. It would assume that the first phase of the 2PC protocol would have
             timed out and the coordinator would have aborted the transaction. Hence it
             would abandon the transaction. This action is safe because a participating node
             can unilaterally withdraw from a transaction any time before sending a prepared
             reply in the first phase. The coordinator would abort the transaction because the
             failed node would not send a prepared Ti message even if it has recovered by the
             time the coordinator starts the 2PC protocol.
             If the participating node fails after sending a prepared or abandoned reply
             to the coordinator, it would find a prepared or abandoned record in its log when
             it recovers. This record may be followed by a commit or abort record, in which
             case the node would perform commit or abort processing. Otherwise, the node
             would have to query the coordinator to find whether the transaction had been
             committed or aborted, and accordingly perform commit or abort processing.
             If the node fails while it was performing commit processing, it would find a
             commit record in its log when it recovered. So it would repeat commit processing.
             Recall from Section 13.11.2.2 that repeated commit processing would not cause
             data consistency problems because the data update operations performed during
             commit processing are idempotent.
             If the coordinator fails after writing the commit record in its log, but before
             writing the complete record in the log, it would see the commit record in its log
             when it recovers. It would now resend commit Ti messages to all participating
             nodes, because it would not know whether it had sent such messages before it
             crashed. However, this requirement constitutes a weakness in the 2PC protocol:
             If the coordinator had failed before sending commit Ti messages, participating
             nodes would not know whether the coordinator decided to commit or abort the
             transaction. Any participating node that had sent an abandoned Ti reply in the
             first phase would know that the decision could not be to commit the transaction;
             however, a node that had sent a prepared Ti reply would be blocked until the
             coordinator recovered and sent it a commit Ti or abort Ti message. A three-phase
             commit protocol has been designed to avoid this blocking situation; however, it is
             not discussed here.
             19.5  RESILIENCY                                                                       ·
             Resiliency techniques focus on minimizing the cost of reexecution when faults
             occur. The basis for resiliency is the property that failures in a distributed system
             are partial, rather than total, so some parts of a distributed computation, or



                       Chapter 19  Recovery and Fault Tolerance                           755
the results computed by them, may survive a failure. Use of such results after
recovery would reduce reexecution, and may even avoid it. Consider a distributed
transaction that is initiated in node Ni and involves computations in nodes Nj and
Nk. It has a transaction manager in each of these nodes. The transaction would
be aborted if the transaction manager in node Nj does not respond to the prepare
message from the coordinator in node Ni because of the failure of node Nj or link
(Ni, Nj). The aborted transaction would have to be reexecuted at some other time.
Much of the reexecution would be wasteful if node Nj had already completed the
computation, but was simply unable to participate in commit processing because
of a link fault.
A nested transaction Tik is an atomic transaction that is a part of another
transaction Ti. Transactions Ti and Tik have a parent­child relationship; the
transaction controller of Ti initiates Tik and assigns it a unique id. The nested
transaction can commit or abort just like an atomic transaction, except for one
difference--when it reaches the commit point, a tentative commit is performed
for it. A tentative commit is an intermediate stage between not committed and
committed. The log of the nested transaction is written in stable storage; however,
it is not processed at this time. The actual commit of the nested transaction, which
involves processing of the log, is held in abeyance until the parent transaction com-
mits. When a parent transaction reaches its commit point, it is committed by using
a two-phase commit protocol to ensure that all its child transactions can commit.
Resiliency using nested transactions is implemented as follows: Consider a
transaction Ti that executes in node Ni and initiates a nested transaction Tik
in node Nj . Let node Nj crash and recover sometime after Tik has performed a
tentative commit. The transaction coordinator, which is in node Ni, may find that
the nested transaction Tik is taking too long to complete, or that the transaction
manager in node Nj is not responding to its prepare message, so it may decide to
initiate Tik once again--either in node Nj itself, or in another node. If it reinitiates
Tik in node Nj , the transaction manager in node Nj would check whether Tik was
initiated there in the past and had performed a tentative commit. If so, it would
not reinitiate Tik because it already has Tik's results in the log; it would simply
use Tik's results when the parent transaction Ti commits. Thus, reexecution of
Tik would be avoided.
If the transaction coordinator of Ti decided to reinitiate the nested transac-
tion in another node, it would assign another id to the new nested transaction,
say, Til . Now, transaction Tik of node Nj has become an orphan because its parent
transaction is no longer interested in it. If it has not performed a tentative commit,
it should be prevented from performing it in future. If it has performed a tentative
commit, care should be taken not to include it in the 2PC when the results of Ti
are committed so that data consistency is not harmed through duplicate actions.
To implement this aspect, the transaction coordinator for Ti maintains a list of
ids of nested transactions in which it is currently interested. When it initiates
nested transaction Tik, it would add Tik's id to the list, and when it reinitiates
the nested transaction with the id Til , it would delete Tik from this list and add
Til to it. When Tik wishes to perform a tentative commit, its transaction man-
ager would check with the transaction coordinator whether Tik's id is present



756         Part 5   Distributed Operating Systems
                         in the list of nested transactions. Since it is not the case, the transaction manager
                         would disallow a tentative commit of Tik to take place. When Ti commits, Tik
                         would not participate in the 2PC because its id is not present in the list of nested
                         transactions.
19.6      SUMMARY                                                                                               ·
Recovery and fault tolerance are two approaches to       its  operation,  whereas    in  forward  recovery      the
reliability of a computer system. These approaches       error is removed from the system's state and its
are generically called recovery. The cost of a recov-    operation is resumed. Backward recovery is imple-
ery approach is determined by its overhead during        mented as follows: The states of processes are
normal operation and the amount of reprocessing          recorded periodically. When a node fails, a process
which becomes necessary when a fault occurs. In          that was executing in it, say process Pi, is rolled
a distributed system, a fault typically affects the      back to a previous state. If Pi had sent a message
operation of a single link or node, hence special        m that was received by another process Pj, Pi's
techniques are employed to minimize the cost of a        rollback makes message m an orphan message and
recovery. It gives rise to a third recovery approach     causes an inconsistency in the states of Pi and Pj.
called  resiliency.  In  this  chapter  we  studied      To remove this inconsistency, Pj has to be rolled
the recovery techniques of distributed operating         back to some previous state in which it had not
systems.                                                 received message m. This effect is called the domino
     A fault like an I/O device malfunction or a         effect. Recovery is performed by rolling back pro-
power outage causes an error in the state of the         cesses in accordance with the domino effect until
system. It leads to an unexpected behavior of the        all processes assume mutually consistent states.
system, which is called a failure. Recovery is initi-         A system implements fault tolerance by main-
ated when a failure is noticed. It puts the system       taining a log in which it writes information for
into a new state from which its operation can be         recovery. An undo log contains information useful
resumed. The nature of a fault determines what           for backward recovery, while a do log, which is also
kind of recovery is possible. A fail-stop fault brings   called a redo log, contains information for forward
the system to a halt, a partial amnesia fault makes it   recovery. Fault tolerance is implemented through
lose a part of its state, while a Byzantine fault makes  an atomic transaction, which ensures that if a fault
it behave in an unpredictable manner and perform         occurs, either all actions in a specified sequence of
wrong actions. It may not be possible to undo            actions would be performed or none of them would
the effect of wrong actions performed because of         be performed. This way, the system will never be in
a Byzantine fault in a process, hence recovery is        a state in which only some of the actions have been
implemented as follows: Several processes are cre-       performed. An atomic transaction can be imple-
ated to perform the same computation in parallel.        mented by using a do log and forward recovery
When a failure results from a Byzantine fault, the       if a fault occurs while implementing its actions; it
state in which majority of the processes exist is        can also be implemented by using an undo log and
considered to be the correct state. Processes in the     backward recovery. The two-phase commit proto-
wrong state are aborted and others resume their          col (2PC protocol) is used to implement atomic
operation.                                               transactions that involve data existing in differ-
     Recovery from non-Byzantine faults can be           ent nodes of the system. It ensures that actions of
performed by using two approaches. In backward           the transaction are implemented only if all nodes
recovery, recovery is performed by rolling back the      containing  its  data  can  carry  out   the  required
system to a previous consistent state and resuming       updates.



                                                            Chapter 19    Recovery and Fault Tolerance               757
An atomic transaction that involves data in                 reduces  the  cost         of  reprocessing     as  follows:    A
many nodes of the system can be implemented                 nested transaction of the failed transaction may
by using nested transactions, which are its parts           have completed its operation in some other node.
that execute in different nodes. If an atomic trans-        Hence it is not reinitiated even if its parent trans-
action is unable to complete because of a node              action is reinitiated; instead, its results are simply
fault, it may be reinitiated. The resiliency technique      reused in the reinitiated parent transaction.
TEST  YOUR CONCEPTS                                                                                                         ·
19.1  Classify each of the following statements as true              a.  A fault occurs when a system is in state S, and
      or false:                                                          a process Pi is in state si. Process Pi is rolled
      a. A power outage is a partial amnesia fault if                    back to a state si contained in a checkpoint
      no recovery techniques are used.                                   that was taken at time t. A domino effect
      b. Use of a recovery technique incurs overhead                     arises if
      even during normal operation of a system,                          i. Pi had received a message m         some time
      i.e., even when no faults occur.                                    after time t.
      c. Backward recovery is performed by using                         ii. Pi had sent a message m to a process Pk
      backups and checkpoints.                                            some time after time t, and in state S the
      d. An orphan message is a message that has                          message is still in transit.
      been sent but has not been received by its                         iii. Pi had sent a message m to a process
      destination process.                                                Pk some time after time t, and in state
      e. The domino effect may be observed while                          S process Pk has received the message.
      recovering a system by using asynchronous                      b.  An atomic transaction can be implemented
      checkpoints.                                                       by using
      f. Quorum algorithms are used for fault toler-                     i. A do log and backward recovery
      ance while updating distributed data.                              ii. A do log and forward recovery
19.2  Select the appropriate alternative(s) in each of                   iii. An undo log and backward recovery
      the following questions:                                           iv. An undo log and forward recovery
EXERCISES                                                                                                                   ·
19.1  A checkpoint is said to be strongly consistent if     19.3  Can orphan messages arise if a process takes a
      (i) states of all pairs of processes are mutually           checkpoint before receiving each message?
      consistent, and (ii) every message recorded as        19.4  When asynchronous checkpointing is used, sev-
      sent by a sender process is recorded as received            eral checkpoints for each process need to be
      by a receiver process. Discuss whether a syn-               preserved to support rollbacks in the presence
      chronous   checkpoint      is  both  consistent  and        of orphan messages. To preserve disk space, it
      strongly consistent.                                        is useful to know when (if ever) a specific check-
19.2  Processes in a distributed computation perform              point can be deleted without affecting recovery.
      asynchronous checkpointing as follows: Each                 Comment on the following proposals:
      process takes a checkpoint immediately after                   a. Delete a checkpoint Cij when another check-
      sending a message. Prove that recovery using                       point is taken for process Pi.
      such  checkpoints     can  be  performed  without              b. Delete      a  checkpoint  Cij  if  another  check-
      encountering the domino effect.                                    point Cij+1 is taken for process Pi and no



758       Part 5     Distributed Operating Systems
          messages were      sent  by  Pi  between  the  two    19.7  Can use of read and write quorums determined
          checkpoints.                                                by Eq.(19.2) lead to deadlocks? If so, design a
          c. Delete a checkpoint Cij if another checkpoint            scheme to avoid deadlocks.
          Cij+1 is taken for process Pi and no mes-             19.8  Because of large quorum sizes in handling repli-
          sages were received by Pi between the two                   cated data, it is proposed to use an approach
          checkpoints.                                                based on the notion of request sets of Maekawa
          d. Delete all checkpoints for process Pi taken              (see Section 18.3.1). Comment on whether all
          prior to checkpoint Cij if for every message                four rules of Section 19.4.2 would be satisfied by
          mk recorded as received in Cij , the process                this approach.
          that sent message mk has taken a checkpoint           19.9  Comment          on  correctness  of  the      following
          after sending it.                                           scheme      for  mutual  exclusion    of  readers  and
19.5  The node in a distributed system in which a pro-                writers over replicated data:
      cess Pi operates fails. What are the processes that             a. Set Qr = 1 and Qw = n, where n is the number
      need to be rolled back due to recovery of Pi?                   of copies of data.
      Give an algorithm to recover from Pi's failure.                 b. When a writer wishes to update the data, it
      While recovery from Pi's failure is in progress,                tries to set a write lock on each copy.
      the node in which another process Pj operates                   i.    If    the  copy    is  already  locked,  it  waits
      fails. State the conditions under which recovery                      for the copy's lock to be released by the
      from these two failures would be independent of                       process which had set it.
      one another. How should recovery from these                     ii.   If it cannot access the copy,        it assumes
      failures be performed if these conditions are not                     that the node containing the copy has
      satisfied?                                                            failed, and reduces Qw by 1.
19.6  Give a scheme to implement an atomic trans-                     iii.  It proceeds to update the data when it
      action using an undo log. In what order should                        finds that it has set a write lock on as
      entries in the undo log be processed if a transac-                    many copies as the current value of Qw.
      tion is aborted?
BIBLIOGRAPHY                                                                                                              ·
Lamport et al. (1982) discusses the Byzantine generals          discusses fault tolerance in distributed systems. Garg
problem. Barborak et al. (1993) surveys approaches that         (2002) discusses recovery based on checkpointing and
can be used to obtain agreement on a system status by the       message logging.
fault-free segment of the processor population. Lynch
(1996), Tel (2000), and Garg (2002) discuss consensus in        1.  Barborak, M., M. Malek, and A. Dahbura
synchronous and asynchronous systems.                               (1993): "The consensus problem in fault tolerant
     The  two-phase  commit  protocol      is  discussed    in      computing," Computing Surveys, 25, 2, 171­220.
Gray (1981). The three-phase commit protocol avoids             2.  Garg, V. K. (2002): Elements of Distributed
the blocking problem of the two­phase commit proto-                 Computing, Wiley-IEEE, New York.
col when the coordinator fails. It permits participating        3.  Gray, J. N. (1981): "The transaction concept:
nodes to roll forward such a transaction to completion,             virtues and limitations," Proceedings of the
or to roll it back to an abort. The three-phase commit              International Conference on Very Large Data
protocol is discussed in Skeen (1983). Svobodova (1984)             Bases, 144­154.
discusses resiliency in distributed computing.                  4.  Lamport, L., R. Shostak, and M. Pease (1982):
     Venkatesh et al. (1987) discusses optimal check-               "The Byzantine generals problem," ACM
pointing  and  domino-free   recovery.     This  topic   con-       Transactions on Programming Languages and
tinues to be much researched even today. Tel (2000)                 Systems, 4 (3), 382­401.



                                                  Chapter 19    Recovery and Fault Tolerance         759
5.  Lynch, N. (1996): Distributed Algorithms,     8.  Tel, G. (2000): Introduction to Distributed
    Morgan Kaufmann.                                  Algorithms, 2nd ed., Cambridge University Press,
6.  Skeen, D. (1983): "A formal model of crash        Cambridge.
    recovery in a distributed system," IEEE       9.  Venkatesh, K., T. Radhakrishnan, and H. F. Li
    Transactions on Software Engineering, 9 (3),      (1987): "Optimal checkpointing and local
    219­228.                                          recording for domino-free rollback recovery,"
7.  Svobodova, L. (1984): "Resilient Distributed      Information Processing Letters, 25 (5),
    computing," IEEE Transactions on Software         295­304.
    Engineering, 10 (3), 257­267.
