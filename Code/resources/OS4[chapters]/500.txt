File Systems


                                                    Chapte                                  r  13
File Systems
C omputer users store programs and data in files so that they can be used
      conveniently and preserved across computing sessions. A user has many
      expectations when working with files, namely
·  Convenient and fast access to files
·  Reliable storage of files
·  Sharing of files with collaborators
   The resources used for storing and accessing files are I/O devices. As it must,
the OS ensures both efficient performance of file processing activities in processes
and efficient use of I/O devices.
   Operating systems organize file management into two components called the
file system and the input-output control system (IOCS) to separate the file-level
concerns from concerns related to efficient storage and access of data. Accord-
ingly, a file system provides facilities for creating and manipulating files, for
ensuring reliability of files when faults such as power outages or I/O device mal-
functions occur, and for specifying how files are to be shared among users. The
IOCS provides access to data stored on I/O devices and good performance of
I/O devices.
   This chapter deals with the design of the file system. After discussing the
basics of file organizations, directory structures and disk space management, we
describe the file sharing semantics that govern concurrent sharing of files and
file system reliability. Implementation of file operations by means of the IOCS is
discussed in Chapter 14.
13.1  OVERVIEW OF FILE PROCESSING                                                        ·
We use the term file processing to describe the general sequence of operations
of opening a file, reading data from the file or writing data into it, and closing
the file. Figure 13.1 shows the arrangement through which an OS implements file
processing activities of processes. Each directory contains entries describing some
files. The directory entry of a file indicates the name of its owner, its location on a
disk, the way its data is organized, and which users may access it in what manner.
   The code of a process Pi is shown in the left part of Figure 13.1. When it
opens a file for processing, the file system locates the file through the directory
                                                                                               479



480  Part 4  File  Systems and I/O Management
                                                            Directory structure
                                                                                            Directory
                                                                                                       File
                                                                                                       system
                           Process                                                          File
                           Pi                  beta         beta                 phi
                   open         beta
                                                            Logical
                   read         beta,                       view of
                           ...                              file data
                   close         beta
                                                                                 File data
                                                                                 in memory
                                                                                                       IOCS
                                                                                 File data
                                                                                 on disk
                   Figure  13.1  File system and the IOCS.
                   structure, which is an arrangement of many directories. In Figure 13.1, there are
                   two files named beta located in different directories. When process Pi opens
                   beta, the manner in which it names beta, the directory structure, and identities
                   of the user who initiated process Pi will together determine which of the two files
                   will be accessed.
                   A file system provides several file types (see Section 13.2). Each file type pro-
                   vides its own abstract view of data in a file--we call it a logical view of data.
                   Figure 13.1 shows that file beta opened by process Pi has a record-oriented log-
                   ical view, while file phi has a byte stream­oriented logical view in which distinct
                   records do not exist.
                   The IOCS organizes a file's data on an I/O device in accordance with its file
                   type. It is the physical view of the file's data. The mapping between the logical
                   view of the file's data and its physical view is performed by the IOCS. The IOCS
                   also provides an arrangement that speeds up a file processing activity--it holds
                   some data from a file in memory areas organized as buffers, a file cache, or a disk
                   cache. When a process performs a read operation to get some data from a file,
                   the IOCS takes the data from a buffer or a cache if it is present there. This way,
                   the process does not have to wait until the data is read off the I/O device that
                   holds the file. Analogously, when a process performs a write operation on a file,
                   the IOCS copies the data to be written in a buffer or in a cache. The actual I/O



                                                                Chapter 13               File  Systems  481
operations to read data from an I/O device into a buffer or a cache, or to write it
from there onto an I/O device, are performed by the IOCS in the background.
13.1.1 File System and the IOCS
A file system views a file as a collection of data that is owned by a user, can be
shared by a set of authorized users, and has to be reliably stored over an extended
period of time. A file system gives users freedom in naming their files, as an aspect
of ownership, so that a user can give a desired name to a file without worrying
whether it conflicts with names of other users' files; and it provides privacy by
protecting against interference by other users. The IOCS, on the other hand, views
a file as a repository of data that need to be accessed speedily and are stored on
an I/O device that needs to be used efficiently.
   Table 13.1 summarizes the facilities provided by the file system and the IOCS.
The file system provides directory structures that enable users to organize their
data into logical groups of files, e.g., one group of files for each professional
activity. The file system provides protection against illegal file accesses and ensures
correct operation when processes access and update a file concurrently. It also
ensures that data is reliably stored, i.e., data is not lost when system crashes occur.
Facilities of the IOCS are as described earlier.
   The file system and the IOCS form a hierarchy. Each of them has policies and
provides mechanisms to implement the policies. In the language of Section 1.1, the
IOCS and the file system provide different abstractions that lead to the following
division of functions:
·  The file system provides an interface through which a process can perform
   open, read/write, and close operations on files. Its policy modules handle
   protection and sharing of files during open and read/write operations. Its
   mechanism modules assist in the implementation of open and close opera-
   tions by accessing directories. They also pass on read/write requests for file
   data to the IOCS.
·  The IOCS policy modules ensure efficient operation of I/O devices and effi-
   cient file processing in each process through the IOCS mechanism modules.
   The mechanism modules in the IOCS, in turn, invoke the kernel through
   system calls to initiate I/O operations.
   Table 13.1           Facilities Provided by the File System
   and the Input-Output Control System
   File System
   · Directory structures for convenient grouping of files
   · Protection of files against illegal accesses
   · File sharing semantics for concurrent accesses to a file
   · Reliable storage of files
   Input-Output Control System (IOCS)
   · Efficient operation of I/O devices
   · Efficient access to data in a file



482  Part 4  File Systems and I/O Management
             Data and Metadata     A file system houses two kinds of data--data contained
             within files, and data used to access files. We call the data within files file data, or
             simply data. The data used to access files is called control data, or metadata. In
             the logical view shown in Figure 13.1, data contained in the directory structure
             is metadata. As discussed later in this chapter and in Chapter 14, other metadata
             play a role in implementing file operations.
             13.1.2 File Processing in a Program
             At the programming language level, a file is an object that possesses attributes
             describing the organization of its data and the method of accessing the data.
             A program contains a declaration statement for a file, which specifies values of
             its attributes, and statements that open it, perform read/write operations on it,
             and close it (we call them file processing statements). During execution of the
             program, file processing is actually implemented by library modules of the file
             system and the IOCS.
                  Figure 13.2 illustrates how file processing is actually implemented. The pro-
             gram of Figure 13.2(a) declares alpha as a sequential-access file that contains
             records with a size of 60 bytes (see Section 13.2 for a discussion of records in a
             file). It also contains statements to open alpha and read a record from it. The
             compiler of the programming language processes the file declaration statement in
             the program and determines attributes of the file. It now replaces open, close,
             read, and write statements with calls on file system library modules open,
             close, read, and write, and passes the file attributes as parameters to the
             open call [see Figure 13.2(b)]. The file system modules invoke modules of the
             IOCS to actually perform I/O operations. The linker links the file system library
             (a)                              (b)                 (c)
                  file  alpha
                  sequential
                  record=60
                  open  alpha,                call  open(alpha,`       call...
                     `read'                         read',..)
                                                                       call...
                  read  alpha,                call  read(alpha,
                        xyz                         xyz)
                                                                       File system
                                                                       modules open
                                                                       & close
                                                                       IOCS module
                                                                       seq_read
             Figure  13.2    Implementing a file processing activity: (a) program containing file declaration
             statements; (b) compiled program showing calls on file system modules; (c) process invoking
             file system and IOCS modules during operation.



                                                                           Chapter 13         File Systems        483
modules and the IOCS modules invoked by them to produce the program shown
in Figure 13.2(c) (see Section 11.3.2 for a description of the linking function).
When a process is created for execution of this program, it invokes the file system
library modules during its operation to perform the open and read operations
on the file, and these modules implement them with the help of appropriate IOCS
library modules.
13.2  FILES AND FILE OPERATIONS                                                                                   ·
File Types    A file system houses and organizes different types of files, e.g.,
data files, executable programs, object modules, textual information, documents,
spreadsheets, photos, and video clips. Each of these file types has its own format
for recording the data. These file types can be grouped into two classes:
· Structured files
· Byte stream files
A structured file is a collection of records, where a record is a meaningful unit
for processing of data. A record is a collection of fields, and a field contains a single
data item. Each record in a file is assumed to contain a key field. The value in the
key field of a record is unique in a file; i.e., no two records contain an identical key.
Many file types mentioned earlier are structured files. File types used by standard
system software like compilers and linkers have a structure determined by the OS
designer, while file types of user files depend on the applications or programs that
create them.
A byte stream file is "flat." There are no records and fields in it; it is looked
upon as a sequence of bytes by the processes that use it. The next example
illustrates structured and byte stream files.
                                                                                                                  ·
Structured and Byte Stream Files                                                              Example       13.1
Figure 13.3(a) shows a structured file named employee_info. Each record
in the file contains information about one employee. A record contains four
fields: employee id, name, designation, and age. The field containing the
employee id is the key field. Figure 13.3(b) shows a byte stream file report.
                                                                                           ·
File Attributes   A file attribute is a characteristic of a file that is important either
to its users or to the file system, or both. Commonly used attributes of a file are:
type, organization, size, location on disk, access control information, which indi-
cates the manner in which different users can access the file; owner name, time of
creation, and time of last use. The file system stores the attributes of a file in its
directory entry. During a file processing activity, the file system uses the attributes
of a file to locate it, and to ensure that each operation being performed on it is con-
sistent with its attributes. At the end of the file processing activity, the file system
stores changed values of the file's attributes, if any, in the file's directory entry.



484  Part 4  File  Systems and I/O Management
                                       employee_info                          report
                                                                        abscd18735 . . .
                                                      employee id
                                               51
                                               Anita Ingle
                                               Manager
                                (a)            33 Years            (b)
                   Figure 13.3  Logical views of (a) a structured file employee_info; (b) a byte stream file
                   report.
                   Table 13.2        Operations on Files
                   Operation                   Description
                   Opening a file              The file system finds the directory entry of the file and
                                               checks whether the user whose process is trying to open
                                               the file has the necessary access privileges for the file.
                                               It then performs some housekeeping actions to initiate
                                               processing of the file.
                   Reading or writing          The file system considers the organization of the file
                   a record                    (see Section 13.3) and implements the read/write
                                               operation in an appropriate manner.
                   Closing a file              The file size information in the file's directory entry is
                                               updated.
                   Making a copy of a file     A copy of the file is made, a new directory entry is
                                               created for the copy and its name, size, location, and
                                               protection information is recorded in the entry.
                   File deletion               The directory entry of the file is deleted and the disk
                                               area occupied by it is freed.
                   File renaming               The new name is recorded in the directory entry
                                               of the file.
                   Specifying access           The protection information in the file's directory entry
                   privileges                  is updated.
                   File Operations    Table 13.2 describes operations performed on files. As men-
                   tioned earlier, operations such as open, close, rename, and delete are performed
                   by file system modules. Actual access of files, i.e., reading or writing of records,
                   is implemented by the IOCS modules.
                   13.3     FUNDAMENTAL FILE ORGANIZATIONS AND
                            ACCESS METHODS                                                                    ·
                   We use the term "record access pattern" to describe the order in which records
                   in a file are accessed by a process. The two fundamental record access patterns
                   are sequential access, in which records are accessed in the order in which they



                                                  Chapter 13                              File  Systems  485
fall in a file (or in the reverse of that order), and random access, in which records
may be accessed in any order. The file processing actions of a process will execute
efficiently only if the process's record access pattern can be implemented efficiently
in the file system. The characteristics of an I/O device make it suitable for a specific
record access pattern. For example, a tape drive can access only the record that
is placed immediately before or after the current position of its read/write head.
Hence it is suitable for sequential access to records. A disk drive can directly
access any record given its address. Hence it can efficiently implement both the
sequential and random record access patterns.
A file organization is a combination of two features--a method of arranging
records in a file and a procedure for accessing them. A file organization is designed
to exploit the characteristics of an I/O device for providing efficient record access
for a specific record access pattern. A file system supports several file organi-
zations so that a process can employ the one that best suits its file processing
requirements and the I/O device in use. This section describes three fundamen-
tal file organizations--sequential file organization, direct file organization and
index sequential file organization. Other file organizations used in practice are
either variants of these fundamental ones or are special-purpose organizations
that exploit less commonly used I/O devices.
Accesses to files governed by a specific file organization are implemented by
an IOCS module called an access method. An access method is a policy module
of the IOCS. While compiling a program, the compiler infers the file organiza-
tion governing a file from the file's declaration statement (or from the rules for
default, if the program does not contain a file declaration statement), and identi-
fies the correct access method to invoke for operations on the file. We describe the
functions of access methods after discussing the fundamental file organizations.
13.3.1 Sequential File Organization
In sequential file organization, records are stored in an ascending or descending
sequence according to the key field; the record access pattern of an application
is expected to follow suit. Hence sequential file organization supports two kinds
of operations: read the next (or previous) record, and skip the next (or previous)
record. A sequential-access file is used in an application if its data can be con-
veniently presorted into an ascending or descending order. The sequential file
organization is also used for byte stream files.
13.3.2 Direct File Organization
The direct file organization provides convenience and efficiency of file processing
when records are accessed in a random order. To access a record, a read/write
command needs to mention the value in its key field. We refer to such files as
direct-access files. A direct-access file is implemented as follows: When a process
provides the key value of a record to be accessed, the access method module for
the direct file organization applies a transformation to the key value that generates
the address of the record in the storage medium. If the file is organized on a disk,



486  Part 4  File Systems and I/O Management
                   the transformation generates a (track_no, record_no) address. The disk heads are
                   now positioned on the track track_no before a read or write command is issued
                   on the record record_no.
                         Consider a file of employee information organized as a direct-access file. Let
                   p records be written on one track of the disk. Assuming the employee numbers
                   and the track and record numbers of the file to start from 1, the address of the
                   record for employee number n is (track number (tn), record number (rn)) where
                                              tn =  n                                               (13.1)
                                                    p
                                              rn = n - (tn - 1) × p                                 (13.2)
                   and   ...     indicates a rounded-up integer value.
                         Direct file organization provides access efficiency when records are pro-
                   cessed randomly. However, it has three drawbacks compared to sequential file
                   organization:
                      ·  Record address calculation consumes CPU time.
                      ·  Disks can store much more data along the outermost track than along the
                         innermost track. However, the direct file organization stores an equal amount
                         of data along each track. Hence some recording capacity is wasted.
                      ·  The address calculation formulas (13.1) and (13.2) work correctly only if a
                         record exists for every possible value of the key, so dummy records have to
                         exist for keys that are not in use. This requirement leads to poor utilization
                         of the I/O medium.
                   Hence sequential processing of records in a direct-access file is less efficient than
                   processing of records in a sequential-access file. Another practical problem is that
                   characteristics of an I/O device are explicitly assumed and used by the address
                   calculation formulas (13.1) and (13.2), which makes the file organization device-
                   dependent. Rewriting the file on another device with different characteristics, e.g.,
                   different track capacity, will imply modifying the address calculation formulas.
                   This requirement affects the portability of programs.
·
     Example 13.2  Sequential and Direct-Access Files
                   Figure 13.4 shows the arrangement of employee records in sequential and
                   direct file organizations. Employees with the employee numbers 3, 5­9 and 11
                   have left the organization. However, the direct-access file needs to contain a
                   record for each of these employees to satisfy the address calculation formulas
                   (13.1) and (13.2). This fact leads to the need for dummy records in the direct-
                   access file.
                   ·
                   13.3.3 Index Sequential File Organization
                   An index helps to determine the location of a record from its key value. In a
                   pure indexed file organization, the index of a file contains an index entry with



                                                                                           Chapter 13     File Systems        487
employee #                                                         dummy records
             1     2  4  10  12  ...                     1  2      3      4  5    .  .  .  10
(a)                                                 (b)
Figure 13.4  Records  in (a) sequential file;  (b)  direct-access  file.
the format (key value, disk address) for each key value existing in the file. To
access a record with key k, the index entry containing k is found by search-
ing the index, and the disk address mentioned in the entry is used to access
the record. If an index is smaller than a file, this arrangement provides high
access efficiency because a search in the index is more efficient than a search in
the file.
The index sequential file organization is a hybrid organization that combines
elements of the indexed and the sequential file organizations. To locate a desired
record, the access method module for this organization searches an index to
identify a section of the disk that may contain the record, and searches the records
in this section of the disk sequentially to find the record. The search succeeds if
the record is present in the file; otherwise, it results in a failure. This arrangement
requires a much smaller index than does a pure indexed file because the index
contains entries for only some of the key values. It also provides better access
efficiency than the sequential file organization while ensuring comparably efficient
use of I/O media.
For a large file the index would still contain a large number of entries, and
so the time required to search through the index would be large. A higher-level
index can be used to reduce the search time. An entry in the higher-level index
points to a section of the index. This section of the index is searched to find the
section of the disk that may contain a desired record, and this section of the
disk is searched sequentially for the desired record. The next example illustrates
this arrangement.
                                                                                                                              ·
Index Sequential File Organization                                                                        Example       13.3
Figure 13.5 illustrates a file of employee information organized as an index
sequential file. Records are stored in ascending order by the key field. Two
indexes are built to facilitate speedy search. The track index indicates the
smallest and largest key value located on each track (see the fields named low
and high in Figure 13.5). The higher-level index contains entries for groups
of tracks containing 3 tracks each. To locate the record with a key k, first the
higher-level index is searched to locate the group of tracks that may contain
the desired record. The track index for the tracks of the group is now searched
to locate the track that may contain the desired record, and the selected track is
searched sequentially for the record with key k. The search ends unsuccessfully
if it fails to find the record on the track.
                                                                                                       ·



488  Part 4  File Systems and I/O Management
             Track                                                        Track
             group  Low    High               Track  Low  High            #
             1      1      43                 1      1        13          1      1   2   4   10    12  13
             2      45     96                 2      16       31          2      16  17  18  21    24  31  Records
                   Higher-level               3      32       43          3      32  33  36  37    40  43
                    index                     ...
                                                 Track index
             Figure 13.5 Track index  and     higher-level index  in  an  index  sequential file.
             13.3.4 Access Methods
             An access method is a module of the IOCS that implements accesses to a class
             of files using a specific file organization. The procedure to be used for accessing
             records in a file, whether by a sequential search or by address calculation, is deter-
             mined by the file organization. The access method module uses this procedure to
             access records. It may also use some advanced techniques in I/O programming
             to make file processing more efficient. Two such techniques are buffering and
             blocking of records.
             Buffering of Records     The access method reads records of an input file ahead
             of the time when they are needed by a process and holds them temporarily in
             memory areas called buffers until they are actually used by the process. The
             purpose of buffering is to reduce or eliminate the wait for an I/O operation to
             complete; the process faces a wait only when the required record does not already
             exist in a buffer. The converse actions are performed for an output file. When the
             process performs a write operation, the data to be written into the file is copied
             into a buffer and the process is allowed to continue its operation. The data is
             written on the I/O device sometime later and the buffer is released for reuse. The
             process faces a wait only if a buffer is not available when it performs a write
             operation.
             Blocking of Records      The access method always reads or writes a large block
             of data, which contains several file records, from or to the I/O medium. This
             feature reduces the total number of I/O operations required for processing a
             file, thereby improving the file processing efficiency of a process. Blocking also
             improves utilization of an I/O medium and throughput of a device.
             We discuss the techniques of buffering and blocking of records in Chapter 14.
             13.4   DIRECTORIES                                                                                     ·
             A directory contains information about a group of files. Each entry in a directory
             contains the attributes of one file, such as its type, organization, size, location, and
             the manner in which it may be accessed by various users in the system. Figure 13.6



                                                                             Chapter 13              File  Systems  489
   File       Type and    Location     Protection   Open                                       Misc
   name        size       info         info         count             Lock   Flags             info
   Field                  Description
   File name              Name of the file. If this field has a fixed size, long file names
                          beyond a certain length will be truncated.
   Type and size          The file's type and size. In many file systems, the type of file is
                          implicit in its extension; e.g., a file with extension .c is a byte
                          stream file containing a C program, and a file with extension
                          .obj is an object program file, which is often a structured file.
   Location info          Information about the file's location on a disk. This information
                          is typically in the form of a table or a linked list containing
                          addresses of disk blocks allocated to a file.
   Protection info        Information about which users are permitted to access this file,
                          and in what manner.
   Open count             Number of processes currently accessing the file.
   Lock                   Indicates whether a process is currently accessing the file in an
                          exclusive manner.
   Flags                  Information about the nature of the file--whether the file is a
                          directory, a link, or a mounted file system.
   Misc info              Miscellaneous information like id of owner, date and time of
                          creation, last use, and last modification.
Figure 13.6 Fields in  a  typical directory entry.
shows the fields of a typical directory entry. The open count and lock fields are
used when several processes open a file concurrently. The open count indicates
the number of such processes. As long as this count is nonzero, the file system
keeps some of the metadata concerning the file in memory to speed up accesses
to the data in the file. The lock field is used when a process desires exclusive
access to a file. The flags field is used to differentiate between different kinds of
directory entries. We put the value "D" in this field to indicate that a file is a
directory, "L" to indicate that it is a link, and "M" to indicate that it is a mounted
file system. Later sections in this chapter will describe these uses. The misc info
field contains information such as the file's owner, its time of creation, and last
modification.
   A file system houses files owned by several users. Therefore it needs to grant
users two important prerogatives:
·  File naming freedom: A user's ability to give any desired name to a file, without
   being constrained by file names chosen by other users.
·  File sharing: A user's ability to access files created by other users, and ability
   to permit other users to access his files.



490  Part 4  File Systems and I/O Management
                           Master
                           Directory
                           User
                           Directories              A             B                        C
                           (UDs)
                                              beta  alpha  gamma  beta  calendar
             Figure  13.7  A directory structure composed of master and user directories.
             The file system creates several directories and uses a directory structure to
             organize them for providing file naming freedom and file sharing. We include
             schematic diagrams to illustrate directory structures, using the convention that
             a directory is represented by a rectangle, while a file is represented by a circle.
             Figure 13.7 shows a simple directory structure containing two kinds of directories.
             A user directory (UD) contains entries describing the files owned by one user. The
             master directory contains information about the UDs of all registered users of the
             system; each entry in the master directory is an ordered pair consisting of a user id
             and a pointer to a UD. In the file system shown, users A and B have each created
             their own file named beta. These files have entries in the users' respective UDs.
             We describe the directory structure shown in Figure 13.7 as a two-level directory
             structure.
             Use of separate UDs is what provides naming freedom. When a process
             created by user A executes the statement open (beta,       ...), the file system
             searches the master directory to locate A's UD, and searches for beta in it. If
             the call open(beta,        ...) had instead been executed by some process created
             by B, the file system would have searched B's UD for beta. This arrangement
             ensures that the correct file is accessed even if many files with identical names
             exist in the system.
             Use of UDs has one drawback, however. It inhibits users from sharing their
             files with other users. A special syntax may have to be provided to enable a user to
             refer to another user's file. For example, a process created by user C may execute
             the statement open       (Abeta,       ...) to open A's file beta. The file system
             can implement this simply by using A's UD, rather than C's UD, to search and
             locate file beta. To implement file protection, the file system must determine
             whether user C is permitted to open A's file beta. It checks the protection info
             field of beta's directory entry for this purpose. Details of file protection are
             discussed in Section 13.6.
             13.4.1 Directory Trees
             The MULTICS file system of the 1960s contained features that allowed the user
             to create a new directory, give it a name of his choice, and create files and other
             directories in it up to any desired level. The resulting directory structure is a tree;



                                                                            Chapter 13   File  Systems  491
                                        root
                  X                     A                        B
                                 admin                           projects
                          alpha
                                                                 real_time
                                           beta
                                              main_pgm
Figure  13.8  Directory trees of the file system and of user A.
we call it the directory tree. After MULTICS, most file systems have provided
directory trees.
A user can create a file to hold data or to act as a directory. When a distinction
between the two is important, we will call these files respectively data files and
directory files, or simply directories. The file system provides a directory called
root that contains the home directory for each user, which is a directory file that
typically has the same name as the user's name. A user structures his informa-
tion by creating directory files and data files in his home directory, creating files
and other directories in a directory file, and so on. We will assume that the file
system puts a "D" in the flags field of a file's entry if the file is a directory file.
Figure 13.8 shows the directory tree of the file system. The root of this tree is
the directory root, which contains a home directory for each user that bears the
user's name. User A has created a file called alpha and directories called admin
and projects. The projects directory contains a directory real_time,
which contains a file main_pgm. Thus user A has a directory tree of his own; its
root is his home directory.
At any time, a user is said to be "in" some specific directory, which is called his
current directory. When the user wishes to open a file, the file name is searched for
in this directory. Whenever the user logs in, the OS puts him in his home directory;
the home directory is then the user's current directory. A user can change his
current directory at any time through a "change directory" command.
A file's name may not be unique in the file system, so a user or a process
uses a path name to identify it in an unambiguous manner. A path name is a
sequence of one or more path components separated by a slash (/), where each
path component is a reference through a directory and the last path component
is the name of the file.
Path names for locating a file from the current directory are called relative
path names. Relative path names are often short and convenient to use; how-
ever, they can be confusing because a file may have different relative path names
when accessed from different current directories. For example, in Figure 13.8, the



492  Part 4  File Systems and I/O Management
                   file alpha has the simple relative path name alpha when accessed from cur-
                   rent directory A, whereas it has relative path names of the form ../alpha and
                   ../../alpha when accessed from the directories projects and real_time,
                   respectively.      To  facilitate    use  of  relative   path  names,  each   directory   stores
                   information about its own parent directory in the directory structure.
                       The absolute path name of a file starts on the root directory of the file system's
                   directory tree. Identically named files created in different directories differ in their
                   absolute path names. We will use the convention that the first path component in
                   an absolute path is a null symbol, and the home directory of a user A is specified
                   as~A. Thus, in Figure 13.8, the absolute path name of file alpha is /A/alpha.
                   An alternative path name for it is ~A/alpha.
                   13.4.2 Directory Graphs
                   In a directory tree, each file except the root directory has exactly one parent direc-
                   tory. This directory structure provides total separation of different users' files and
                   complete file naming freedom. However, it makes file sharing rather cumbersome.
                   A user wishing to access another user's files has to use a path name that involves
                   two or more directories. For example, in Figure 13.8, user B can access file beta
                   using the path name ../A/projects/beta or ~A/projects/beta.
                       Use of the tree structure leads to a fundamental asymmetry in the way dif-
                   ferent users can access a shared file. The file will be located in some directory
                   belonging to one of the users, who can access it with a shorter path name than
                   can other users. This problem can be solved by organizing the directories in an
                   acyclic graph structure. In this structure, a file can have many parent directories,
                   and so a shared file can be pointed to by directories of all users who have access
                   to it. Acyclic graph structures are implemented through links.
                   Links    A link is a directed connection between two existing files in the directory
                   structure. It can be written as a triple (<from_ file_name>, <to_ file_name>,
                   <link_name>), where <from_ file_name> is a directory and <to_ file_name> can
                   be a directory or a file. Once a link is established, <to_ file_name> can be accessed
                   as if it were a file named <link_name> in the directory <from_ file_name>. The
                   fact that <link_name> is a link in the directory <from_ file_name> is indicated
                   by putting the value "L" in its flags field. Example 13.4 illustrates how a link is
                   set up.
·
     Example 13.4  Link in a Directory Structure
                   Figure   13.9      shows      the  directory   structure  after  user   C    creates  a   link
                   using    the   command         (~C,  ~C/software/web_server,                  quest).     The
                   name     of   the  link   is   quest.     The  link  is  made  in  the  directory     ~C  and
                   it  points    to   the   file      ~C/software/web_server.              This  link    permits
                   ~C/software/web_server to be accessed by the name ~C/quest.
                   ·



                                                                                    Chapter 13      File  Systems  493
                                C
                                                                         quest
                personal        job                              software
                                                            web  server
Figure  13.9  A link in the directory structure.
An      unlink  command         nullifies         a  link.  Implementation      of  the  link  and
unlink commands involves manipulation of directories that contain the files
<from_ file_name> and <to_ file_name>. Deadlocks may arise while link and
unlink commands are implemented if several processes issue these commands
simultaneously. The file system can use some simple policy to ensure absence of
deadlocks (see Section 8.8.1).
13.4.3 Operations on Directories
A search is the most frequent operation on directories. Other operations on
directories are maintenance operations like creating or deleting files, updating
file entries when a process performs a close operation, listing a directory, and
deleting a directory.
The deletion operation specifies a path name for the file to be deleted. It
becomes complicated when the directory structure is a graph because a file may
have multiple parents. A file is deleted only if it has a single parent; otherwise, it is
simply made inaccessible from its parent directory in the path name specified in
the delete command. To simplify the delete operation, the file system maintains a
link count with each file. The count is set to 1 when the file is created, incremented
by 1 whenever a link is set to point to it, and decremented by 1 at a delete
command. The file can be deleted only when its link count becomes 0.
This simple strategy is not adequate if the directory structure contains cycles.
A cycle develops when a link is set from a directory to one of its ancestor direc-
tories, e.g., if a link is set up from the directory real_time in Figure 13.8 to the
directory projects. Now the link count of projects is 2, so its deletion by
using the path name ~A/projects would lead only to deletion of the entry of
projects in A. However, there is no reason to retain directory projects and
files reachable from it, since projects would not be accessible from the home
directory of any user! This problem can be solved either by using a technique
to detect cycles that are not reachable from any home directories, which can be
expensive, or by preventing cycles from arising in the directory structure, which
is equally expensive.
13.4.4 Organization of Directories
A directory could be a flat file that is searched linearly to find the required file
entry. However, this organization is inefficient if the directory contains a large



494  Part 4  File Systems and I/O Management
             number of entries. Hash tables and B+ trees are used to provide greater search
             efficiency.
             Hash Table Directory       A hash table using the hash with chaining organization was
             discussed in Section 12.2.3 in connection with inverted page tables. A directory
             can be maintained by using a simpler hash table organization called hash with
             open addressing that requires a single table. When a new file is to be created in a
             directory, a hashing function h is applied to a bit string obtained from the file's
             name, which yields an entry number e. If the eth entry in the directory is already
             occupied by another file, the entry given by (e + 1)mod(n), where n is the size
             of the hash table, is checked and so on until an unused entry is found, and the
             new file's details are entered in it. When a file is to be opened, a similar search
             is carried out to locate its entry in the directory. Hash table organizations that
             do not require more than two comparisons to locate a required file name are
             practical, so a hash table directory can be searched efficiently. However, use of
             a hash table directory organization has a few drawbacks--it is cumbersome to
             change the size of a directory, or to delete an entry from it.
             B+ Tree Directory     A B+ tree is an m-way search tree where m  2 × d, d being
             an integer called the order of the tree. The B+ tree is a balanced tree; i.e., the
             length of the path from the root to any leaf node is the same. This property has a
             useful implication for directory search--it takes approximately the same amount
             of time to find the information concerning any file name existing in the directory.
             A B+ tree directory is organized as follows: Information about files is
             recorded only in leaf nodes of the tree; nonleaf nodes are used merely to direct
             search to appropriate parts of the tree. The nonleaf nodes of the tree contain
             index entries, where each index entry is an ordered pair consisting of a pointer to
             another node in the tree and a file name. The last index entry in a node does not
             contain a file name; it contains only a pointer to another node in the tree. The
             leaf nodes of the tree contain only information entries for files--each entry is an
             ordered pair consisting of a pointer to information associated with a file name
             and the file name itself.
             The root node contains between 2 and 2 × d entries, both inclusive, where
             d is the order of the tree. A nonroot node contains between d and 2 × d entries,
             both inclusive. To facilitate search for a file name, the entries in a node--whether
             index entries or information entries--are lexicographically ordered on file names.
             Thus, a file name in an entry is "larger" than the file name in the preceding entry
             in the node, and "smaller" than the file name in the following entry in the node. A
             leaf node contains two extra pointers. These pointers point to tree nodes that are
             to its left and to its right in the tree, if any, respectively. These pointers are used
             to facilitate insertion and deletion of entries. We do not discuss their use here.
             To locate a file in a directory, the directory B+ tree is searched, starting with
             its root node. The file's name is compared with the file name in the first index
             entry in the node. If it is lexicographically "smaller" than the file name in the
             entry, the pointer in the index entry is used to locate another tree node, where the
             search is continued; otherwise, the search is continued with the next index entry
             in the node, if any, and so on. If the next index entry is the last index entry in the



                                                                Chapter 13                     File Systems        495
                                                k
               c  f                                       t  x
        a  b   c  d               f          g      k  r  t  u  x                        z
           Information in directory entries            Information in directory entries
Figure  13.10  A directory organized as a B+ tree.
node, the search is simply continued with the tree node pointed to by the pointer
in the index entry (note that the last index entry in a node does not contain a file
name). This procedure is followed until a leaf node of the tree is encountered.
Now, information entries in the leaf node are searched by using a convenient
search technique like linear or binary search. If an information entry is found
for the file name we are looking for, we use the pointer in the information entry
to locate the information associated with the file name; otherwise, the file name
does not exist in the directory.
                                                                                                                   ·
Directory as a B+ Tree                                                                         Example       13.5
Figure 13.10 shows a directory organized as B+ tree of order 2. A down-arrow
in a leaf node is a pointer to information associated with a file name. To search
for file c, we compare c with k, the file name in the first index entry in the root.
Since the file name c is "smaller" than k, we use the pointer in this index entry
to locate the tree node where the search is to be continued. This is the node
that contains index entries for file names c and f. Since c is not smaller than
the file name in the first index entry, we compare it with the file name in the
next index entry in the node, i.e., with f. It is smaller, hence we use the pointer
in this index entry. This pointer points to a leaf node. Hence we search for c in
the information entries in this node. We find a match in the first information
entry, so we use the pointer in this entry to locate the directory information
about file c.
                                                                                            ·
The advantages of a B+ tree are its fast search capability and the efficiency
of the methods for rebalancing the tree when insertions and deletions are made.
Windows NTFS uses B+ trees for directories.
13.5    MOUNTING OF FILE SYSTEMS                                                                                   ·
There can be many file systems in an operating system. Each file system is con-
stituted on a logical disk, i.e., on a partition of a disk. Files contained in a file



496  Part 4  File Systems and I/O Management
                   system can be accessed only when the file system is mounted. The mount oper-
                   ation is what "connects" the file system to the system's directory structure. An
                   unmount operation disconnects a file system. The mount and unmount opera-
                   tions are performed by the system administrator. These operations provide an
                   element of protection to files in a file system.
                      Mounting creates an effect analogous to that provided by a link. The dif-
                   ference is that mounting does not permanently alter the directory structure. Its
                   effect lasts only until the file system is unmounted or until the system is booted
                   again. Mounting of file systems is useful when there are multiple file systems in
                   the OS (see Section 13.14.1), or when a user of a distributed system wishes to
                   access files located in a remote machine (see Chapter 20).
                      A mount point is a directory in which a file system can be mounted. A
                   mount operation is performed by issuing the command mount (<FS_name>,
                   <mount_point_name>), where <FS_name> and <mount_point_name>, both of
                   which are path names, designate the root of the file system to be mounted and the
                   mount point, respectively. When the mount operation is performed, the root of
                   the mounted file system assumes the name <mount_point_name>. Thus, any file
                   with the relative path name api in the directory <FS_name> can be accessed by
                   the path name <mount_point_name>/api. If a file system is mounted in a direc-
                   tory that already contains some files, these files become invisible to the user until
                   the file system is unmounted. The next example illustrates the effect of executing
                   a mount command.
·
     Example 13.6  Mounting of a File System
                   In Figure 13.11(a), ~A/admin is a mount point in a directory structure, and
                   meeting is the root directory of another file system. Figure 13.11(b) shows
                   the effect of the command mount     (meeting,~A/admin). File items can
                   now be accessed as ~A/admin/agenda/items.
                   ·
                                     ~A       meeting                                   ~A
                           admin              agenda                             admin
                                                                     time
                                                                            agenda
                                                      items                                 time
                                                                                    items
                           (a)                                              (b)
                   Figure  13.11  Directory structures (a) before a  mount  command; (b) after a mount command.



                                                                    Chapter 13             File Systems  497
The effect of a mount operation is nullified by the corresponding command
unmount (<FS_name>, <mount_point_name>). The unmount operation suc-
ceeds only if no files of the mounted file system are currently open. To check
this condition easily, the file system keeps a count in the root of the mounted file
system to indicate how many of its files have been opened.
13.6     FILE PROTECTION                                                                                 ·
A user would like to share a file with collaborators, but not with others. We call
this requirement controlled sharing of files. To implement it, the owner of a file
specifies which users can access the file in what manner. The file system stores this
information in the protection info field of the file's directory entry (see Figure 13.6),
and uses it to control access to the file.
Different methods of structuring the protection information of files are dis-
cussed in Chapter 15. In this section, we assume that a file's protection information
is stored in the form of an access control list. Each element of the access control list
is an access control pair of the form (<user_name>, <list_of_access_privileges>).
When a process executed by some user X tries to perform an operation <opn>
on file alpha, the file system searches for the pair with <user_name>= X, in the
access control list of alpha and checks whether <opn> is consistent with the
<list_of_access_privileges>. If it is not, the attempt to access alpha fails. For
example, a write attempt by X will fail if the entry for user X in the access control
list is (X, read), or if the list does not contain an entry for X.
The size of a file's access control list depends on the number of users and the
number of access privileges defined in the system. To reduce the size of protection
information, users can be classified in some convenient manner and an access
control pair can be specified for each user class rather than for each individual
user. Now an access control list has only as many pairs as the number of user
classes. For example, Unix specifies access privileges for three classes of users--
the file owner, users in the same group as the owner, and all other users of the
system.
In most file systems, access privileges are of three kinds--read, write, and
execute. A write privilege permits existing data in the file to be modified and
also permits new data to be added: One can further differentiate between these
two privileges by defining a new access privilege called append; however, it would
increase the size of the protection information. The execute privilege permits a
user to execute the program contained in a file. Access privileges have differ-
ent meanings for directory files. The read privilege for a directory file implies
that one can obtain a listing of the directory, while the write privilege for a
directory implies that one can create new files in the directory. The execute
privilege for a directory permits an access to be made through it--that is, it
permits a file existing in the directory to be accessed. A user can use the exe-
cute privilege of directories to make a part of his directory structure visible to
other users.



498  Part 4  File Systems and I/O Management
             13.7     ALLOCATION OF DISK SPACE                                                      ·
             As mentioned in Section 13.5, a disk may contain many file systems, each in its
             own partition of the disk. The file system knows which partition a file belongs
             to, but the IOCS does not. Hence disk space allocation is performed by the file
             system.
                Early file systems adapted the contiguous memory allocation model (see
             Section 11.6) by allocating a single contiguous disk area to a file when it was
             created. This model was simple to implement. It also provided data access effi-
             ciency by reducing disk head movement during sequential access to data in a
             file. However, contiguous allocation of disk space led to external fragmentation.
             Interestingly, it also suffered from internal fragmentation because the file system
             found it prudent to allocate some extra disk space to allow for expansion of a file.
             Contiguity of disk space also necessitated complicated arrangements to avoid use
             of bad disk blocks: The file system identified bad disk blocks while formatting
             the disk and noted their addresses. It then allocated substitute disk blocks for the
             bad ones and built a table showing addresses of bad blocks and their substitutes.
             During a read/write operation, the IOCS checked whether the disk block to be
             accessed was a bad block. If it was, it obtained the address of the substitute disk
             block and accessed it.
                Modern file systems adapt the noncontiguous memory allocation model (see
             Section 11.7) to disk space allocation. In this approach, a chunk of disk space is
             allocated on demand, i.e., when the file is created or when its size grows because of
             an update operation. The file system has to address three issues for implementing
             this approach:
             ·  Managing free disk space: Keep track of free disk space and allocate from it
                when a file requires a new disk block.
             ·  Avoiding excessive disk head movement: Ensure that data in a file is not dis-
                persed to different parts of a disk, as it would cause excessive movement of
                the disk heads during file processing.
             ·  Accessing file data: Maintain information about the disk space allocated to
                a file and use it to find the disk block that contains required data.
                The file system can maintain a free list of disk space and allocate from it
             when a file requires a new disk block. Alternatively, it can use a table called the
             disk status map (DSM) to indicate the status of disk blocks. The DSM has one
             entry for each disk block, which indicates whether the disk block is free or has
             been allocated to a file. This information can be maintained in a single bit, and
             so a DSM is also called a bit map. Figure 13.12 illustrates a DSM. A 1 in an entry
             indicates that the corresponding disk block is allocated. The DSM is consulted
             every time a new disk block has to be allocated to a file.
                To avoid dispersing file data to different parts of a disk, file systems confine
             the disk space allocation for a file either to consecutive disk blocks, which form
             an extent, also called a cluster, or consecutive cylinders in a disk, which form
             cylinder groups (see Section 14.3.2). Use of a disk status map, rather than a free



                                                                                         Chapter  13  File  Systems  499
                      Disk block address          didi + 2
                      Disk block status           011100101 ...
                                                                Disk block
                                                            is allocated
                                                                Disk block
                                                                 is free
Figure  13.12  Disk status map (DSM).
        File          Location
        name             info                                                Free  list pointer
        alpha                                                                      Data
        beta                                      1              -        2        Metadata
                                                  3                       4
                                                  5                       6
                                                  7         --            8
               Directory
Figure  13.13  Linked allocation of disk  space.
list, has the advantage that it allows the file system to readily pick disk blocks
from an extent or cylinder group.
We discuss two fundamental approaches to noncontiguous disk space allo-
cation. They differ in the manner they maintain information about disk space
allocated to a file.
13.7.1 Linked Allocation
A file is represented by a linked list of disk blocks. Each disk block has two
fields in it--data and metadata. The data field contains the data written into the
file, while the metadata field is the link field, which contains the address of the
next disk block allocated to the file. Figure 13.13 illustrates linked allocation. The
location info field of the directory entry of file alpha points to the first disk block
of the file. Other blocks are accessed by following the pointers in the list of disk
blocks. The last disk block contains null information in its metadata field. Thus,
file alpha consists of disk blocks 3 and 2, while file beta consists of blocks 4, 5,
and 7. Free space on the disk is represented by a free list in which each free disk
block contains a pointer to the next free disk block. When a disk block is needed
to store new data added to a file, a disk block is taken off the free list and added
to the file's list of disk blocks. To delete a file, the file's list of disk blocks is simply
added to the free list.
Linked allocation is simple to implement, and incurs a low allocation/
deallocation overhead. It also supports sequential files quite efficiently. However,
files with nonsequential organization cannot be accessed efficiently. Reliability
is also poor since corruption of the metadata field in a disk block may lead to



500  Part 4  File Systems and I/O Management
                     File       Location
                     name       info                       1  free
                     alpha      3                          2  end                 1      -  2
                     beta       4                          3  2
                                                           4  5                   3         4
                                                           5  7
                                                           6  free                5         6
                                                           7  end                 7  --     8
                                                           8  free
                            Directory                      File allocation table
             Figure  13.14  File Allocation Table  (FAT).
             loss of data in the entire file. Similarly, operation of the file system may be dis-
             rupted if a pointer in the free list is corrupted. We discuss these reliability issues
             in Section 13.11.
             File Allocation Table (FAT)           MS-DOS uses a variant of linked allocation that
             stores the metadata separately from the file data. A file allocation table (FAT)
             of a disk is an array that has one element corresponding to every disk block
             in the disk. For a disk block that is allocated to a file, the corresponding FAT
             element contains the address of the next disk block. Thus the disk block and its
             FAT element together form a pair that contains the same information as the disk
             block in a classical linked allocation scheme.
             The directory entry of a file contains the address of its first disk block. The
             FAT element corresponding to this disk block contains the address of the second
             disk block, and so on. The FAT element corresponding to the last disk block con-
             tains a special code to indicate that the file ends on that disk block. Figure 13.14
             illustrates the FAT for the disk of Figure 13.13. The file alpha consists of disk
             blocks 3 and 2. Hence the directory entry of alpha contains 3. The FAT entry
             for disk block 3 contains 2, and the FAT entry for disk block 2 indicates that the
             file ends on that disk block. The file beta consists of blocks 4, 5, and 7. The FAT
             can also be used to store free space information. The list of free disk blocks can
             be stored as if it were a file, and the address of the first free disk block can be held
             in a free list pointer. Alternatively, some special code can be stored in the FAT
             element corresponding to a free disk block, e.g. the code "free" in Figure 13.14.
             Use of the FAT rather than the classical linked allocation involves a per-
             formance penalty, since the FAT has to be accessed to obtain the address of
             the next disk block. To overcome this problem, the FAT is held in memory
             during file processing. Use of the FAT provides higher reliability than classi-
             cal linked allocation because corruption of a disk block containing file data leads
             to limited damage. However, corruption of a disk block used to store the FAT is
             disastrous.
             13.7.2 Indexed Allocation
             In indexed allocation, an index called the file map table (FMT) is maintained
             to note the addresses of disk blocks allocated to a file. In its simplest form, an



                                                                   Chapter 13             File  Systems  501
        File   Location
        name   info
        alpha                                                      -
        beta                                         fmtalpha
                                                               --
               Directory                             fmtbeta
Figure  13.15  Indexed allocation  of  disk  space.
FMT can be an array containing disk block addresses. Each disk block contains a
single field--the data field. The location info field of a file's directory entry points
to the FMT for the file (see Figure 13.15). In the following discussion we use the
notation fmtalpha for the FMT of the file alpha. If the size of the file alpha
grows, the DSM is searched to locate a free block, and the address of the block
is added to fmtalpha. Deallocation is performed when alpha is deleted. All disk
blocks pointed to by fmtalpha are marked free before fmtalpha and the directory
entry of alpha are erased.
The reliability problem is less severe in indexed allocation than in linked
allocation because corruption of an entry in an FMT leads to only limited damage.
Compared with linked allocation, access to sequential-access files is less efficient
because the FMT of a file has to be accessed to obtain the address of the next disk
block. However, access to records in a direct-access file is more efficient since the
address of the disk block that contains a specific record can be obtained directly
from the FMT. For example, if address calculation analogous to (13.1)­(13.2)
shows that a required record exists in the ith disk block of a file, its address can
be obtained from the ith entry of the FMT.
For a small file, the FMT can be stored in the directory entry of the file; it is
both convenient and efficient. For a medium or large file, the FMT will not fit into
the directory entry. A two-level indexed allocation depicted in Figure 13.16 may
be used for such FMTs. In this organization, each entry of the FMT contains the
address of an index block. An index block does not contain data; it contains entries
that contain addresses of data blocks. To access the data block, we first access an
entry of the FMT and obtain the address of an index block. We then access an
entry of the index block to obtain the address of the data block. This arrangement
resembles a multilevel page table (see Section 12.2.3). The index blocks resemble
pages of a page table for the file, and the FMT resembles a higher-level page table.
Such an FMT is compact; hence even FMTs of large files may fit into a directory
entry. However, access to data blocks is slower since two levels of indirection are
involved.
Some file systems use a hybrid FMT organization that includes some of the
features of both classical and multilevel indexed allocation. Figure 13.17 shows
such an organization. The first few entries in the FMT, say n entries, point to



502  Part 4  File Systems and I/O Management
                                              ...                   Data
                                                                    blocks
                                              FMT
                                                            Index
                                                            blocks
             Figure  13.16  A  two-level FMT organization.
                               1                            Data
                                                   ...      blocks
                               n
                               m                                    Data
                                                                    blocks
                                              FMT
                                                            Index
                                                            blocks
             Figure  13.17  A  hybrid organization of FMT.
             data blocks as in the conventional indexed allocation. Other entries point to
             index blocks. The advantage of this arrangement is that small files containing n
             or fewer data blocks continue to be accessible efficiently, as their FMT does not
             use index blocks. Medium and large files suffer a marginal degradation of their
             access performance because of multiple levels of indirection. The Unix file system
             uses a variation of the hybrid FMT organization.
             13.7.3 Performance Issues
             Two performance issues are associated with the use of a disk block as the unit
             of disk space allocation--size of the metadata, i.e., the control data of the file
             system; and efficiency of accessing file data. Both issues can be addressed by using
             a larger unit of allocation of disk space. Hence modern file systems tend to use an
             extent, also called a cluster, as a unit of disk space allocation. An extent is a set
             of consecutive disk blocks. Use of large extents provides better access efficiency.
             However, it causes more internal fragmentation. To get the best of both worlds,
             file systems prefer to use variable extent sizes. Their metadata contains the size
             of an extent along with its address.



                                                                        Chapter 13      File  Systems  503
13.8  INTERFACE BETWEEN FILE SYSTEM AND IOCS                                                           ·
The file system uses the IOCS to perform I/O operations and the IOCS imple-
ments them through kernel calls. The interface between the file system and the
IOCS consists of three data structures--the file map table (FMT), the file con-
trol block (FCB), and the open files table (OFT)--and functions that perform
I/O operations. Use of these data structures avoids repeated processing of file
attributes by the file system, and provides a convenient method of tracking the
status of ongoing file processing activities.
As discussed earlier in Section 13.7.2, the file system allocates disk space to
a file and stores information about the allocated disk space in the file map table
(FMT). The FMT is typically held in memory during the processing of a file.
A file control block (FCB) contains all information concerning an ongoing
file processing activity. This information can be classified into the three categories
shown in Table 13.3. Information in the file organization category is either sim-
ply extracted from the file declaration statement in an application program, or
inferred from it by the compiler, e.g., information such as the size of a record and
number of buffers is extracted from a file declaration, while the name of the access
method is inferred from the type and organization of a file. The compiler puts this
information as parameters in the open call. When the call is made during execu-
tion of the program, the file system puts this information in the FCB. Directory
information is copied into the FCB through joint actions of the file system and
the IOCS when a new file is created. Information concerning the current state of
processing is written into the FCB by the IOCS. This information is continually
updated during the processing of a file.
The open files table (OFT) holds the FCBs of all open files. The OFT resides
in the kernel address space so that user processes cannot tamper with it. When a
      Table 13.3  Fields in the File Control Block (FCB)
      Category                     Fields
      File organization            File name
                                   File type, organization, and access method
                                   Device type and address
                                   Size of a record
                                   Size of a block
                                   Number of buffers
                                   Name of access method
      Directory information        Information about the file's directory entry
                                   Address of parent directory's FCB
                                   Address of the file map table (FMT)
                                   (or the file map table itself)
                                   Protection information
      Current state of processing  Address of the next record to be processed
                                   Addresses of buffers



504  Part 4  File Systems and I/O Management
                internal idalpha= 6                        File alpha
                                              fcbalpha     is opened                     fmtalpha
                                                                           alpha
                     fmtalpha                              File alpha
                                                           is closed       Directory
                                     Open files table
                                              (OFT)
                     File system data structures
                               in memory
             Figure  13.18  Interface between file system  and IOCS--OFT,  FCB and FMT.
             file is opened, the file system stores its FCB in a new entry of the OFT. The offset
             of this entry in the OFT is called the internal id of the file. The internal id is passed
             back to the process, which uses it as a parameter in all future file system calls.
                Figure 13.18 shows the arrangement set up when a file alpha is opened.
             The file system copies fmtalpha in memory; creates fcbalpha, which is an FCB for
             alpha, in the OFT; initializes its fields appropriately; and passes back its offset
             in OFT, which in this case is 6, to the process as internal_idalpha.
                The file system supports the following operations:
             ·  open (<file_name>, <processing_mode>, <file_attributes>)
             ·  close (<internal_id_of_file>)
             ·  read/write (<internal_id_of_file>, <record_info>, <I/O_area_addr>)
                <file_name> is an absolute or relative path name of the file to be opened.
             <processing_mode> indicates what kind of operations will be performed on the
             file--the values "input," "create," and "append" of it have obvious meanings,
             while "update" indicates that the process intends to update existing data in place.
             <file_attributes> is a list of file attributes, such as the file's organization, record
             size, and protection information. It is relevant only when a new file is being
             created--attributes from the list are copied into the directory entry of the file at
             this time. <record_info> indicates the identity of the record to be read or written
             if the file is being processed in a nonsequential mode. <I/O_area addr> indicates
             the address of the memory area where data from the record should be read, or
             the memory area that contains the data to be written into the record.
                The IOCS interface supports the following operations:
             ·  iocs-open (<internal_id_of_file>, <directory_entry_address>)
             ·  iocs-close (<internal_id_of_file>, <directory_entry_address>)
             ·  iocs-read/write (<internal_id_of_file>, <record_info>, <I/O_area_
                addr>)
                Each of these operations is a generic operation for the various file organi-
             zations supported by the file system. It works in two parts: It performs some



                                                                                Chapter 13   File  Systems  505
                                            Open  files table (OFT)
                       internal_ idalpha                             Directory
                                                                     ~U         alpha ...
                                                  fcbalpha
<file declaration>
                                                                                3         8
open (alpha,           open (alpha,`read',        1                      2
    `read')            <file_ attributes>)
read (alpha,           read (internal idalpha,    4         File         5
    <record_info>,     <record_info>,                       system                 IOCS
    xyz)               Ad(xyz))
close (alpha)          close (internal idalpha)   6                      7
Source program         Compiled program                     File system and IOCS actions
Figure 13.19 Overview  of file processing.
actions that are common to all file organizations, and invokes a module of the
access method mentioned in the FCB of the file for performing special actions
required for specific file organizations.
    The iocs-open and iocs-close operations are specialized read and
write operations that copy information into the FCB from the directory entry
or from the FCB into the directory entry. The iocs-read/write operations
access the FCB to obtain information concerning the current state of the file
processing activity, such as the address of the next record to be processed. When
a write operation requires more disk space, iocs-write invokes a function of
the file system to perform disk space allocation (see Section 13.7).
    Figure 13.19 is a schematic diagram of the processing of an existing file alpha
in a process executed by some user U. The compiler replaces the statements open,
read, and close in the source program with calls on the file system operations
open, read, and close, respectively. The following are the significant steps in
file processing involving the file system and the IOCS, shown by numbered arrows
in Figure 13.19:
1.  The process executes the call open (alpha, `read,' <file_attributes>). The
    call returns with internal_idalpha if the processing mode "read" is consistent
    with protection information of the file. The process saves internal_idalpha
    for use while performing operations on file alpha.
2.  The file system creates a new FCB in the open files table. It resolves the
    path name alpha as described later in Section 13.9.1, locates the directory
    entry of alpha, and stores the information about it in the new FCB for use
    while closing the file. Thus, the new FCB becomes fcbalpha. The file system
    now makes a call iocs-open with internal_idalpha and the address of the
    directory entry of alpha as parameters.



506  Part 4  File Systems and I/O Management
             3.   The IOCS accesses the directory entry of alpha, and copies the file size
                  and address of the FMT, or the FMT itself, from the directory entry into
                  fcbalpha.
             4.   When the process wishes to read a record of alpha into area xyz, it invokes
                  the read operation of the file system with internal_idalpha, <record_info>,
                  and Ad(xyz) as parameters.
             5.   Information about the location of alpha is now available in fcbalpha.
                  Hence the read/write operations merely invoke iocs-read/write
                  operations.
             6.   The     process  invokes    the  close  operation  with  internal_id alpha  as    a
                  parameter.
             7.   The file system makes a call iocs-close with internal_idalpha.
             8.   The IOCS obtains information about the directory entry of alpha from
                  fcbalpha and copies the file size and FMT address, or the FMT itself, from
                  fcbalpha into the directory entry of alpha.
             13.9  FILE PROCESSING                                                                  ·
             In this section we discuss the processing of structured files, in which read/write
             operations are performed on a record.
             13.9.1 File System Actions at open
             The   purpose     of  a  call    open  (<path_name>,    <processing_mode>,       <file_
             attributes>), where <path_name> is an absolute or relative path name for a file
             <file_name>, is to set up the processing of the file. As described in Section 13.8,
             open performs the following actions:
             1.   It aborts the process if <processing_mode> is not consistent with the pro-
                  tection information for the file. Otherwise, it creates an FCB for the file
                  <file_name> in the OFT, and puts relevant information in its fields. If
                  <file_name> is a new file, it also writes <file_attributes> into its directory
                  entry.
             2.   It passes the internal id of the file <file_name> back to the process for use
                  in file processing actions.
             3.   If the file <file_name> is being created or appended to, it makes provi-
                  sion to update the file's directory entry when a close call is made by the
                  process.
                  The procedure called path name resolution traverses all path components in
             a path name and checks the validity of each component. It uses two pointers
             called the file FCB pointer and the directory FCB pointer during the traversal. It
             points the file FCB pointer at the FCB of the file corresponding to the current
             component in the path name, and the directory FCB pointer at the FCB of its
             parent directory. At the end of path name resolution, the file FCB pointer is used to



                                                                     Chapter 13        File Systems        507
determine the internal id of the file. Path name resolution consists of the following
steps:
1.  If an absolute path name is used, locate the FCB of the file system root
    directory in the OFT; otherwise, locate the FCB of the current directory. (This
    step assumes that the FCBs of these directories have already been created in
    the OFT. If not, they should be created in this step.) Set directory FCB pointer
    to point to this FCB.
2.  a.  Search for the next path component of the path name in the directory
        represented by directory FCB pointer. Indicate an error if the component
        does not exist or if the process owner lacks privileges to access it.
    b.  Create an FCB for the file described by the path component. Store this
        FCB in a free entry of the OFT. Copy the directory FCB pointer in this
        FCB.
    c.  Set the file FCB pointer to point to this FCB.
    d.  If this is not the last path component in the path name, initialize the
        newly created FCB using information from the directory entry of the
        file. Set directory FCB pointer = file FCB pointer, and repeat step 2.
3.  a.  If the file already exists, copy the file size and the pointer to the FMT
        from the directory entry of the file into the FCB pointed to by file FCB
        pointer.
    b.  If the file does not already exist, create the FMT of the file and store its
        address in the FCB. (This action may involve allocating a disk block for
        the FMT.)
4.  Set internal id of the file to the offset of file FCB pointer in the OFT. Copy
    the directory FCB pointer into the FCB of the file. Return internal id to the
    process.
    Apart from the actions described above, the file system may perform some
other actions in the interest of efficiency. For example, while opening an existing
file it may copy a part or all of the file's FMT into memory [see Step 3(a)]. This
action ensures efficient access to data in the file. Also, only the FCBs pointed to
by directory FCB pointer and file FCB pointer are needed during file processing,
so other FCBs created during path name resolution may be destroyed.
    The following example illustrates the data structures built by the file system
when a file is opened.
                                                                                                           ·
    Implementation of the open Operation                                               Example       13.7
    Figure 13.20 shows the result of the file system actions after executing the call
                           open(/info/alpha, . .);
    The path name used in the open call is an absolute path name. The file
    system searches for the name info in the root directory, and creates an FCB



508  Part 4  File  Systems and I/O Management
                            Directory root
                      info
                                        Directory info
                                 alpha
                                                                6                           Directory
                                                                   fcbinfo                  FCB pointer
                                                                   fcbalpha                 File
                                                                                            FCB pointer
                                            fmtalpha
                                                                       OFT
                   Figure 13.20  File system actions at  open.
                   for info in the OFT. It now searches for the name alpha in info and creates
                   an FCB for alpha in the OFT. directory FCB pointer points to fcbinfo and
                   file FCB pointer points to fcbalpha. Since alpha is an existing file, its FMT
                   pointer is copied into fcbalpha from the directory entry of alpha. The call
                   returns with the internal id of alpha, which is 6.
                   ·
                      The mount command mount (<FS_name>, <mount_point_name>) mounts
                   <FS_name> at the mount point (see Section 13.4). A simple way to implement
                   mounting is to temporarily change the directory entry of <mount_point_name>
                   in its parent directory to point to the directory entry of <FS_name>.
                      When a mount point is crossed during path name resolution, the file system
                   has to switch from the directory structure of the mount point to the directory
                   structure of the mounted file system, or vice versa. To facilitate this, while pro-
                   cessing a mount command, the file system puts the value "M" in the flags field
                   of the directory entry of <FS_name> and maintains a mount table to store pairs
                   of the form (<FS_name>, <mount_point_name>). For example, when the call
                   mount    (meeting,~A/admin) of Section 13.4 is executed, the file system adds
                   the pair (meeting, ~A/admin) to the mount table. During path name resolu-
                   tion, this table is consulted when a mount point is encountered during traversal
                   of the directory structure from parent to child (for the slash (/) operator in the
                   path name) or child to parent (for the ".." operator). The file system also has to
                   ensure that disk space allocation performed during the processing of a mounted
                   file is in the mounted file system rather than in the host file system.



                                                                           Chapter 13         File Systems        509
13.9.2 File System Actions during a File Operation
After opening a file <file_name>, a process executed by user U performs some
read or write operations on it. Each such operation is translated into a call
         <opn> (internal id, record id, <IO_area addr>);
where internal id is the internal id of <file_name> returned by the open call,
and record id is absent if the operation is performed on a sequential-access file
because the operation is necessarily performed on the next record in the file. The
file system performs the following actions to process this call:
1.  Locate the FCB of <file_name> in the OFT using internal id.
2.  Search the access control list of <file_name> for the pair (U, ...). Give an
    error if the protection information found in the file's FCB does not permit
    user U to perform <opn> on the file.
3.  Make a call on iocs-read or iocs-write with the parameters internal id,
    record id and <IO_area addr>. For nonsequential-access files, the operation
    is performed on the indicated record. For sequential-access files, the opera-
    tion is performed on the record whose address is in the FCB field "address
    of the next record to be processed," and the contents of this field are updated
    to point to the next record in the file.
    In Step 3, the IOCS and the access method invoked by it obtains the FMT
of the file from its FCB and uses it to convert record id into a pair of the form
(disk block id, byte offset). If it runs out of disk space during a write operation, it
calls a module of the file system, which allocates a new disk block to the file and
adds its address to the FMT.
                                                                                                                  ·
    Implementation of read/write Operations                                                   Example       13.8
    Following the open call of Example 13.7, a call read  (alpha,          25,  ...)
    by the process, where 25 is record id, would lead to the call iocs-read          (6,
    25,  ..). If disk blocks have a size of 1000 bytes each, and a record is 100
    bytes in length, the IOCS will convert record id into disk block number 3 and
    record number 5 in the disk block, which implies a byte offset of 400. Now the
    address of the third disk block allocated to alpha is obtained from its FMT
    and this block is read to obtain the desired record.
                                                                                         ·
13.9.3 File System Actions at close
The file system performs the following actions  when      a       process  executes      the
statement close (internal id, ...).
1.  If the file has been newly created or appended to.
    a.   If it is a newly created file, create an entry for the file in the directory
         pointed to by the directory FCB pointer. If the directory entry format



510  Part 4  File Systems and I/O Management
                                   info                           info
                                   alpha                               alpha
                                                                       phi
                      Directory
                      FCB pointer         fcbinfo  fmtphi                                    fmtphi
                           File           fcbphi
                      FCB pointer
                      (a)                 OFT                     (b)
                   Figure 13.21    File system data structures (a) before; (b) after close.
                                 contains a field where the complete FMT can be stored, copy the FMT
                                 into this field; otherwise, first write the FMT into a disk block and copy
                                 the address of this disk block into the directory entry.
                           b.    If the file has been appended to, the directory entry of the file is updated
                                 by using directory FCB pointer.
                           c.    If necessary, repeat Steps 1b and 1c to update other directories in the path
                                 name of the file after setting file FCB pointer := directory FCB pointer
                                 and directory FCB pointer := address of parent directory's FCB found in
                                 the FCB of the file. If their FCBs were deleted after open, the directory
                                 files would have to be opened and updated.
                      2.   The FCB of the file and FCBs of its parent and ancestor directories are erased
                           from the OFT.
·
     Example 13.9  Implementation of File close Operation
                   Figure 13.21 illustrates the file system actions before and after executing the
                   command close          phi for a newly created file phi that was opened using the
                   path name /info/phi. An entry is created for phi in directory info and a
                   pointer to fmtphi is put in the location info field of this entry. Addition of this
                   entry to info increases the size of info; hence an additional disk block may
                   have to be allocated to info. It will involve updating the FMT of info and
                   the size of info in its entry in the root directory [see Steps 1(b) and 1(c) of
                   actions at close].
                   ·
                   13.10         FILE SHARING SEMANTICS                                                        ·
                   As discussed in Section 13.6, the owner of a file may authorize some other users
                   to access the file. Processes created by authorized users can read, write, or execute



                                                                  Chapter 13                File  Systems  511
the file in accordance with access privileges granted to them. In essence they share
the files to which they have access. The file system provides two methods of file
sharing so that processes can choose the one that permits them to collaborate
and build on each other's work effectively:
·  Sequential sharing: Processes access a shared file one after another. Thus, file
   modifications made by one process, if any, are visible to processes that access
   the file afterwards.
·  Concurrent sharing: Two or more processes access a file over the same period
   of time.
File sharing semantics is a set of rules that determine the manner in which results of
file manipulations performed by concurrent processes are visible to one another.
   Sequential sharing of a file can be implemented through the lock field in the
file's directory entry (see Figure 13.6). If the lock field of the file's directory entry
has the value "reset," an open operation would succeed and change the value to
"set"; otherwise, the open operation would fail and would have to be repeated.
A close operation would change the value in the lock to "reset."
   To facilitate concurrent sharing of a file, the file system has to ensure that
file processing activities of processes do not interfere. Accordingly, it creates a
separate FCB for each process by simply following the procedure of Section 13.9.1
every time a file is opened. Several FCBs may thus be created for concurrent
sharing of file alpha. We use the notation fcbPal1 pha for the FCB of alpha
created for process P1. Table 13.4 summarizes three modes of concurrent file
sharing provided in file systems.
Sharing Immutable Files     When the file alpha is shared as an immutable file,
none of the sharing processes can modify it. Hence the processes sharing file
alpha are independent of one another. Creation of an fcbalpha for each sharing
process is adequate to implement this form of file sharing.
Table 13.4       Modes of Concurrent File Sharing
Mode                        Description
Immutable files             The file being shared cannot be modified by any
                            process.
Single-image mutable files  All processes concurrently sharing a file "see" the same
                            image of the file, i.e., they have an identical view of file's
                            data. Thus, modifications made by one process are
                            immediately visible to other processes using the file.
Multiple-image mutable      Processes sharing a file may "see" different images of
files                       the file. Thus, updates made by a process may not be
                            visible to some concurrent processes. The file system
                            may maintain many images of a file, or it may reconcile
                            them in some manner to create a single image when
                            processes close the file.



512  Part 4  File  Systems and I/O Management
                                                                                 fcbaPl1 pha
                                     Data blocks
                                         of alpha                                fcbaPl2 pha
                                                   fmtalpha
                                                                                 OFT
                   Figure 13.22  Concurrent sharing of a single-image mutable file by processes P1 and P2.
                   Sharing Single-Image Mutable Files         A single copy of the file is shared by pro-
                   cesses accessing it. Hence modifications made by one process are immediately
                   visible to other processes. To implement this form of sharing, it is essential that a
                   single copy of the FMT be used by all sharing processes. Hence it is best to keep
                   a pointer to the FMT, rather than the FMT itself, in an FCB.
                        Figure 13.22 shows concurrent sharing of file alpha using such an arrange-
                   ment. The FCBs fcbPal1 pha and fcbPal2 pha are created when alpha is opened by
                   processes P1 and P2. Both FCBs point to the same copy of fmtalpha. Each FCB
                   contains the address of the next record to be accessed by a process. If the sets of
                   records processed by P1 and P2 overlapped, their modifications would be visible
                   to one another. Race conditions could also arise in such situations, and updates
                   made by processes might be lost. A typical file system does not provide any means
                   of tackling this problem; the processes have to evolve their own synchronization
                   conventions for this purpose. The Unix file system supports single-image mutable
                   files; we discuss Unix file sharing semantics in Section 13.14.1.
                   Sharing  Multiple-Image         Mutable    Files  When a multiple-image mutable file
                   alpha is shared by several processes, each process that modifies the file creates
                   a new version of alpha that is distinct from versions created by other concur-
                   rent processes. In this scheme, there has to be a distinct fmtalpha for each FCB,
                   and each FMT must point to an exclusive copy of the file. This requirement is
                   best implemented by making a copy of alpha (and its FMT) for each process
                   concurrently accessing it.
                        Figure 13.23 illustrates the arrangement for implementing multiple-image
                   mutable files. Processes P1 and P2 are engaged in updating alpha. alphaP1 rep-
                   resents the copy of alpha made for process P1. Processing by P1 uses fcbaPl1 pha
                   and  fmtaPl1 pha  to  access    alphaP1 ,  while  processing  by   P2      uses  fcbPal2 pha  and
                   fmtaPl2 pha to access alphaP2 . alphaP1 and alphaP2 are thus two versions of
                   alpha. To arrive at a unique implementation scheme, the file sharing semantics
                   must specify how alpha would be accessed by processes that wish only to read
                   it, i.e., which version of alpha they would access.
                        Sharing of multiple-image mutable files has special features that may not be
                   valid or applicable in many applications. Hence it can be used only in applications



                                                                                    Chapter 13    File  Systems  513
                                         fmtaPl1 pha
              Data blocks
              of alphaP1                                 fcbaPl1 pha
              Data blocks                                fcbaPl2 pha
              of alphaP2
                                         fmtaPl2 pha     OFT
Figure 13.23  Concurrent sharing  of  a  multiple-image  mutable file by processes  P1  and  P2.
where existence of multiple versions due to concurrent updates is meaningful.
We discuss one kind of semantics for multiple-image mutable files, called session
semantics, in Section 20.3. Unfortunately, file sharing semantics for multiple-
image mutable files are hard to understand and implement. Hence their use is not
very common.
13.11  FILE SYSTEM RELIABILITY                                                                                   ·
File system reliability is the degree to which a file system will function correctly
even when faults such as data corruption in disk blocks and system crashes due
to power interruptions occur. The two principal aspects of file system reliability
are:
· Ensuring correctness of file creation, deletion and updates.
· Preventing loss of data in files.
The former concerns consistency and correctness of metadata, i.e., the control
data of the file system, while the latter concerns consistency and correctness of
data stored in files.
      Reliability literature distinguishes between the terms fault and failure. A fault
is a defect in some part of the system. A failure is a system behavior that is
erroneous, or that differs from its expected behavior. Occurrence of a fault causes
a failure. Thus corruption of a disk block due to a damaged disk head or a power
outage is a fault, whereas inability of the file system to read a faulty block is a
failure. Chapter 19 discusses these terms formally.
13.11.1 Loss of File System Consistency
File system consistency implies correctness of metadata and correct operation of
the file system. Loss of consistency arises if the metadata of the file system is lost
or damaged. It is interesting to see how this can happen. Consider operation of
a process that updates a file alpha. To ensure efficient operation, the file system
maintains some of its metadata in memory. Thus, fcbalpha (which exists in the



514  Part 4  File Systems and I/O Management
             open files table), part of fmtalpha, and part of the disk status map or free list
             would be in memory. Some of this metadata, like fmtalpha, are written on a disk
             when alpha is closed. In addition, the file system may periodically copy the disk
             status map or free list on the disk. However, metadata is modified constantly, so
             disk copies of metadata generally do not contain up-to-date information during
             system operation. When power fails, metadata maintained in memory is lost, and
             when a disk fails metadata stored on the disk is lost. These situations may result
             in one or more of the following failures:
             1. Some data from file alpha may be lost.
             2. Part of file alpha may become inaccessible.
             3. Contents of two files may get mixed up.
             It is easy to visualize a situation of the first kind. For example, suppose a fault
             occurs after a new disk block has been added to the file alpha. The disk copy
             of fmtalpha will not contain this block's id, and so data in the newly added block
             will be lost when the fault occurs. The second and third kind of situation can arise
             in a file system that does not employ any reliability techniques. We illustrate these
             situations in a file system that uses linked allocation of disk space and employs
             Algorithm 13.1 to add a new disk block to a file. The third kind of situation can
             also arise in a file system that uses indexed allocation of disk space.
             Algorithm 13.1  Add Block dj between Blocks d1 and d2
             Input :
             d1, d2, dj      :  record
                                      next : . . .; { id of next block }
                                      data : . . .;
                                end
             1. dj .next := d1.next;
             2. d1.next := address (dj );
             3. Write d1 to disk.
             4. Write dj to disk.
             Algorithm 13.1 adds a new disk block dj between blocks d1 and d2 of the file.
             Figure 13.24 illustrates how parts of file alpha may become inaccessible due to
             a fault. Figures 13.24(a), (b) show the file before and after a normal execution of
             the algorithm. Figures 13.24(c) shows the file if a fault occurs between Steps 3
             and 4 of Algorithm 13.1. New contents have been written into disk block d1, but
             not into disk block dj . Hence d1.next points to dj , whereas dj does not contain
             correct metadata in its next field. Disk blocks d2, d3, . . . would not be accessible
             as parts of the file any more.
             Contents of two files may get mixed up if the file system writes metadata to
             the disk only while closing a file, and not after every file operation. Consider the
             following situation: A process P1 deletes a disk block dk from some file beta.
             dk will be returned to the free list (or will be marked free in the disk status map).
             Now process P2 adds a new record to file alpha. The file system allocates a new
             disk block dj for this purpose and adds it ahead of disk block dm in file alpha



                                                                                           Chapter 13        File Systems            515
                        Before adding dj           After adding dj                                   After a fault
                   d1       d2      d3        d1              dj       d2                  d1            d2         d2
                                                                                                         dj
                   (a)                        (b)                                          (c)
Figure     13.24   Inconsistencies in metadata due to faults: (a)­(b)  before  and  after  adding    dj  during  normal  operation;  (c)
after a    fault.
                        dh      dk        dl                  dh                    d1
                beta                          ···
                        d1      dj        d2                  d1       dj           d2
           alpha                              ···                                               ···
           (a)                                     (b)
Figure     13.25   Files alpha and beta: (a) after adding dj during    normal operation;
(b) if dj  = dk , alpha is closed and a power outage occurs.
[see Figure 13.25(a)]. Now, consider the situation when dj = dk and the following
events occur in the system:
1. File alpha is closed.
2. The file system updates the disk copy of file alpha. It involves adding disk
block dj to alpha.
3. A power outage occurs.
Note that file beta was not closed before the power outage occurred, so the disk
contains an old copy of beta that contains block dk, and the new copy of alpha
that contains block dj . Since dj = dk, alpha and beta now share disk block dj
and all other blocks accessible through it [see Figure 13.25(b)]. All disk blocks
of file beta that were previously accessible through dk, i.e., block dl and other
blocks accessible through it, are now inaccessible. In effect, some data is common
to files alpha and beta, while some data of beta has been lost.
13.11.2 Approaches to File System Reliability
By means of the two approaches described in Table 13.5, operating systems ensure
that user files are reliably stored over a period of time. Recovery is a classic
approach that is activated when a failure is noticed. It restores the data and
metadata of the file system to some previous consistent state. The file system now
resumes its operation from this state. Thus, deviations from correct behavior do
occur, but system operation is rectified when deviations are noticed. Fault toler-
ance, on the other hand, provides correct operation of the file system at all times,
i.e., it ensures that faults do not lead to failures. It achieves this ability through
some special techniques.



516  Part 4  File Systems and I/O Management
             Table 13.5       Approaches to File System Reliability
             Approach                         Description
             Recovery                         Restore data and metadata of the file system to some
                                              previous consistent state.
             Fault tolerance                  Guard against loss of consistency of data and metadata
                                              due to faults, so that system operation is correct at all
                                              times, i.e., failures do not occur.
             To see the difference between the two approaches, consider the example of
             a disk block that becomes unreadable. Inability of the file system to read the
             block is a failure. Under the recovery approach, the data in the block would
             be restored to an earlier value when a failure is noticed. With fault tolerance,
             each data unit would be recorded in two blocks--a primary block and an alter-
             native block. If a failure occurs while the primary block is being read, the file
             system would automatically read the alternative block. Of course, fault tolerance
             is not absolute. The system can tolerate only those faults that it is designed to.
             For example, when a data unit is recorded in two blocks, the system can toler-
             ate a fault in the primary block, but not faults in both primary and alternative
             blocks.
             13.11.2.1 Recovery Techniques
             The file system state at some time instant ti is the collection of all data and
             metadata in the file system at ti. A backup of the file system is a recording of
             the file system state. To support recovery, the file system periodically produces
             backups during its operation. Let tlb represent the time at which the latest backup
             was produced. In the event of a failure, say, at time tf , the file system is restored
             to the state recorded in its latest backup. File updates performed between tlb
             and tf are lost; operations that performed these updates need to be reprocessed
             after recovery. Recovery using backups thus involves two kinds of overheads--
             overhead of creating backups, and overhead of reprocessing.
             Reprocessing overhead in recovery can be reduced through a combination
             of backups and incremental backups of a file system. An incremental backup
             contains copies of only those files or disk blocks that were modified after the last
             backup or incremental backup was created. The file system creates backups at
             large intervals of time, e.g., a day, a few days, or a week. Incremental backups are
             created at shorter intervals and are discarded when the next backup is created. For
             example, an incremental backup may be created when a process closes a file after
             updating it; the incremental backup would contain a copy of only that file. Use
             of incremental backups increases the overhead of the backing up activity. The
             space overhead is also high because backups and incremental backups coexist
             and some files may exist in more than one incremental backup. However, the
             reprocessing overhead is low for the following reason: After a crash the system
             could be restored from the latest backup, and incremental backups would then be
             processed in the same order in which they were created. This action would restore



                                                           Chapter 13                      File Systems  517
all files whose modification was completed before the last of the incremental
backups was created. Only the file processing activities that were in progress at
the time of the failure would have to be repeated.
To reduce the recovery overhead, the file system could be restored by pro-
cessing all incremental backups and the latest backup in the reverse order, taking
care not to restore a file that has been already restored from a later incremental
backup. This approach would reduce overhead by restoring each file exactly once.
However, it would be effective only if the file system metadata is consistent at the
time of a failure.
                                                                                                                ·
Recovery in a File System                                                                  Example       13.10
Figure 13.26 illustrates a system in which backups were taken at times t1 and
t4, and incremental backups were taken at t2 and t3. The incremental backups
contain 3 and 2 disk blocks, respectively, because 3 disk blocks were updated
between t1 and t2 and 2 disk blocks were updated between t2 and t3. If a
failure occurs after t4, the system would be restored to the state recorded in
the backup taken at t4. However, if a failure occurred between t3 and t4, the
system would have been restored by using the backup taken at t1 and the
incremental backups taken at t2 and t3.
                                                                                        ·
Creating Backups    The key issue in creation of backups is consistency of meta-
data recorded in a backup. Consider the following scenario during operation of
a file system.
1. The free list data structure is written in the backup.
2. A record is added to a file phi, which requires a new disk block to be allocated
to phi from the free list.
3. File phi is now written in the backup.
Here, recording of the free list and file phi in the backup would be mutually incon-
sistent. It could lead to a mix-up of data in files as discussed in Section 13.11.1.
Similar problems would arise even if these three actions are performed in the
reverse order. Inconsistencies of metadata could be prevented by freezing all
activities in the file system while a backup is created; however, this method is
intrusive and it would cause delays in processes. An alternative is to create a
backup during normal operation of a system, but use some simplifications like
not writing the free list in a backup. When the state of the file system is restored
from such a backup, the file system could scan the complete disk and build the free
list anew. However, in this scheme files would have been recorded in the backup
at different times, so they would suffer loss of data to different extents if the file
system is restored by using this backup. Another issue is the backing up of a file
that is being processed when a backup is initiated--either its backing up should
be delayed until its processing is complete, or the user would not precisely know
how much of the file's processing would be lost if the file system is restored by



518  Part 4  File  Systems   and I/O Management
                                   Time  File system               Backup media              Kind of backup
                                   t1                                                        Backup
                                   t2                                                      Incremental backup
                                   t3                                                      Incremental backup
                                   t4                                                        Backup
                   Figure   13.26  Backups and incremental backups in a file system.
                   using the backup. An incremental backup that is created when a file is closed does
                   not face any of these consistency problems because only modified files are writ-
                   ten into the backup, so file system metadata like free lists would not be written
                   into it.
                          What about the overhead of creating a backup? When disk space was expen-
                   sive, backups were typically created on slower I/O devices like tapes; however,
                   disk space is affordable in modern computer systems, so it is possible to create
                   backups on disks. When indexed allocation of disk space is used, it is possible to
                   create an on-disk backup of a file cheaply by means of a technique that resem-
                   bles the copy-on-write technique of virtual memory. Figure 13.27 illustrates this
                   technique.
                   File Location                                       File      Location
                   name      info                                  name          info
                   phi                                                 phi
                   b_phi                                           b_phi
                                         fmtphi             23                               fmtphi                  23
                                         fmtb_phi
                                                                                                                     78
                        Directory                                      Directory
                                                                                             fmtb_phi
                   (a)                                      d1     d2(b)         d2
                   Figure 13.27    Creating a backup:  (a)  after  backing up file phi; (b)  when phi is  modified.



                                                                       Chapter 13       File  Systems  519
When file phi is to be backed up, the file system creates a copy of the directory
entry of phi and names the new file appropriately, say b_phi. Now, the FMT
pointers of phi and b_phi are identical [see Figure 13.27(a)], so file b_phi is
a copy of phi as desired. If contents of the second disk block allocated to phi
change from 23 to 78 because of a file update, the file system would perform the
following actions [see Figure 13.27(b)]:
1. If the FMT pointers of phi and b_phi are identical, make a copy of the
FMT and make the directory entry of b_phi point to the copy.
2. Allocate a new disk block to file phi.
3. Change the appropriate pointer in fmtphi to point to the new disk block.
4. Write the new contents into the new disk block.
Thus, only the FMT and the disk block whose contents are updated after the
backup is created would be copied. This arrangement conserves both disk space
and time.
13.11.2.2 Fault Tolerance Techniques
File system reliability can be improved by taking two precautions--preventing
loss of data or metadata due to I/O device malfunction, and preventing inconsis-
tency of metadata due to faults. These precautions are implemented by using the
fault tolerance techniques of stable storage and atomic actions, respectively.
Stable Storage  Lampson (1981) proposed the technique of redundant recording
of data to ensure reliability. It is called stable storage because it can tolerate one
fault in the recording of a data item. Two copies of a record, called its primary
and secondary copy, are maintained on a disk. A write operation updates both
copies--the primary copy is updated first, followed by the secondary copy. A read
operation accesses the disk block containing the primary copy. If it is unreadable,
the block containing the secondary copy is accessed. Since only single faults are
assumed to occur, one of the blocks is sure to contain readable data.
Figure 13.28 illustrates operation of the stable storage technique if faults
occur at times t1, t2, t3, or t4, respectively, while a process Pi is executing an
update operation on some data D. Parts (a)­(d) show timing charts and values
in the primary and secondary copies of D when faults occur. In Part (a), a fault
occurs at time t1, i.e., before the primary copy is updated. Hence the primary
copy, containing the old value of the data, is accessible after a fault. In Part (b),
a fault occurs while the primary copy is being updated, so that the primary copy
becomes unreadable. The old value of the data is accessible from the secondary
copy. In Part (c), a fault occurs after the primary copy is updated but before
the secondary copy is updated. New data is accessible in the primary copy after
the fault occurs. In Part (d), a fault occurs after both copies have been updated.
Hence both copies are accessible.
The stable storage technique can be applied to entire files. (Lampson called
this technique disk mirroring; however, it is different from the disk mirroring
we will come across in Section 14.3.) However, stable storage incurs high space
and time overhead, which makes it unsuitable for general use in a file system,



520  Part 4  File  Systems  and  I/O Management
                                          Primary           Secondary
                                          copy is           copy is             Primary     Secondary
                                          updated           updated             copy        copy
                                 (a)
                                                                                old         old
                                 (b)
                                                                                unreadable  old
                                 (c)
                                                                                new         old
                                 (d)
                                                                                new         new
                                      t1         t2     t3             t4 Time
                   Figure 13.28  Fault tolerance using  the stable storage technique.
                   so processes may use it selectively to protect some of their own data. Also, while
                   stable storage guarantees that one copy of data will survive a single fault, it cannot
                   indicate whether this value is old or new [see parts (a), (d) of Figure 13.28]. Hence
                   the user does not know whether to reexecute the update operation in Pi when
                   system operation is restored. An atomic action overcomes this problem.
                   Atomic Actions     An action may involve manipulation of many data structures,
                   e.g., consider Algorithm 13.1 of Section 13.11.1. These data structures may
                   become inconsistent if a fault interrupts execution of the action. An atomic action
                   is a method of avoiding such ill effects of faults.
                   Definition 13.1 Atomic Action            An action that consists of a set of subactions
                   and whose execution has the property that either
                   1. The effects of all of its subactions are realized, or
                   2. The effects of none of its subactions are realized.
                   Thus, an atomic action has an all-or-nothing property. This property avoids
                   data inconsistency when faults occur. Consistency of file system metadata can be
                   preserved by updating all file system data structures by using atomic actions.
                   Database systems use a concept called an atomic transaction or a database
                   transaction that ensures certain additional properties such as serializability; our
                   discussion is restricted to atomic actions for file system reliability only.
                   The subactions in an atomic action are enclosed between the statements begin
                   atomic action and end atomic action. Execution of the atomic action begins when
                   the begin atomic action statement is executed. The action can end in two ways--it
                   can either fail or succeed. It fails if it loses interest in continuing its execution and
                   executes an abort statement, or if a fault occurs before the statement end atomic
                   action is executed. If it fails, the state of each file or metadata used by it should be
                   left as it was prior to execution of the begin atomic action statement. An atomic
                   action succeeds when it executes the end atomic action statement. It is said to



                                                          Chapter 13                           File  Systems  521
                        begin atomic action add_a_block;
                        dj .next := d1.next;
                        d1 .next := address(dj);
                        write d1 ;
                        write dj ;
                        end atomic action add_a_block;
Figure 13.29  Atomic action add_a_block.
commit at this time. All updates made by it are guaranteed to survive any faults
after it commits.
Figure 13.29 shows Algorithm 13.1 of Section 13.11.1 coded as an atomic
action named add_a_block. It differs from Algorithm 13.1 only in the use of
the statements begin atomic action and end atomic action. If the atomic action
add_a_block commits, disk block dj is added to file alpha and alpha now
consists of disk blocks . . . d1, dj , d2, . . . . If it fails, disk block dj is not added to
file alpha; i.e., alpha continues to consist of disk blocks . . . d1, d2, . . . . Thus it
avoids the problem described in Section 13.11.1 and illustrated in Figure 13.24.
Atomic actions can be implemented in many ways. In one implementation
approach, files or metadata are not updated during execution of the atomic action.
They are updated only after the atomic action commits. This arrangement auto-
matically tolerates faults that occur before an atomic action commits since no
updates will have been made in files. Thus it implements the "nothing" part of
the all-or-nothing property. To implement the "all" part of the all-or-nothing
property, it is necessary to ensure that all updates will be made even if faults
occur. Two data structures called intentions list and commit flag are maintained
to ensure this. Both data structures are maintained in stable storage to protect
them against data corruption and loss due to faults.
Every time the atomic action modifies a file or metadata, the file system
makes an entry of the form (<disk block id>, <new contents>) in the intentions
list to indicate that <new contents> should be written in the disk block with the
id <disk block id>. The file system uses the information in the intentions list to
update the files when the atomic action commits. This action is called commit
processing. The commit flag contains two fields, transaction id and value. This
flag is created when the statement begin atomic action of an atomic action Ai is
executed and its fields are initialized to Ai and "not committed," respectively. The
value in the commit flag is changed to "committed" when end atomic action is
executed. The flag is destroyed after all updates described in the intentions list
have been carried out.
If a failure occurs, the file system checks for the presence of commit flags
when its operation is resumed. If a commit flag exists for Ai and has the value "not
committed," the file system simply destroys the commit flag and the intentions
list, and executes atomic action Ai again starting with the statement begin atomic
action. Existence of a commit flag for Ai with the value "committed" implies
that commit processing of Ai was in progress when occurrence of a fault led to



522  Part 4  File Systems and I/O Management
                                                                    Disk   New
                                                                    block  contents
                                                                    dj
                  d1                         Transaction id  Value  d1                   d1
                                     d2      add_a_block     NC                                          d2
                                              Commit flag           Intentions list      dj
                  (a)                                                                    (b)
                  Figure 13.30  (a)  Before  and (b) after commit processing. (Note: NC  means not  committed.)
                  a failure. Since it is not known whether any entries of the intentions list were
                  processed before the fault, the entire commit processing is now repeated.
                       If faults occur during commit processing, some entries of the intentions list
                  may be processed many times. However, it does not pose any data consistency
                  problems because the operation of writing <new contents> into <disk block id>
                  is an idempotent operation, which has the property that executing it many times
                  has the same effect as executing it once. The following algorithm summarizes all
                  actions concerning implementation of an atomic action.
                  Algorithm 13.2 Implementation of an Atomic Action
                  1.   Execution of an atomic action Ai:
                       a.  When the statement begin atomic action is executed, create a commit flag
                           and an intentions list in stable storage, and initialize them as follows:
                           commit flag := (Ai, "not committed");
                           intentions list := "empty";
                       b.  For every file update made by a subaction, add a pair (d, v) to the
                           intentions list, where d is a disk block id and v is its new content.
                       c.  When the statement end atomic action is executed, set the value of Ai's
                           commit flag to "committed" and perform Step 2.
                  2.   Commit processing:
                       a.  For every pair (d, v) in the intentions list, write v in the disk block with
                           the id d.
                       b.  Erase the commit flag and the intentions list.
                  3.   On recovering after a failure:
                       If the commit flag for atomic action Ai exists,
                       a.  If the value in commit flag is "not committed": Erase the commit flag
                           and the intentions list. Reexecute atomic action Ai.
                       b.  Perform Step 2 if the value in commit flag is "committed."
·
   Example 13.11  Implementation of an Atomic Action
                  Figure 13.30(a) shows the file alpha, the commit flag and the intentions
                  list when Algorithm 13.2 is applied to the atomic action add_a_block of



                                                            Chapter 13                     File Systems  523
Figure 13.29. The new contents of disk blocks dj and d1 are kept in the inten-
tions list until commit processing. Atomicity of the action is ensured as follows:
If a fault occurs during Step 13.2 of the algorithm, none of the file updates
are reflected on the disk. Hence the file contains the original sequence of disk
blocks d1, d2, . . . . A fault occurring in Step 2 cannot damage either the com-
mit flag or the intentions list because these data structures are recorded in
stable storage. Thus, processing of the intentions list eventually completes; the
file contains the sequence of disk blocks d1, dj, d2 . . . at the end of commit
processing, as shown in Figure 13.30(b).
                                                                                        ·
13.12  JOURNALING FILE SYSTEM                                                                            ·
As discussed in Section 13.11.1, a file system keeps some part of file data as well as
metadata such as file control blocks, file map tables, and free lists of disk blocks
in memory during its operation. When a file system's operation is shut down
by a system administrator, the file system copies all the data and metadata held
in memory onto the disk, so that the copy on disk is complete and consistent.
However, when a power outage occurs, or when the system is switched off abruptly,
the file system does not get an opportunity to copy the file data and metadata
from memory to disk. Such a shutdown is called an unclean shutdown; it results
in loss of file data and metadata that was held in memory.
Traditionally, file systems relied on recovery techniques to protect against
loss of data and metadata because they were so simple to implement. Thus,
backups were created periodically, and files were recovered from backups when
failures were detected. Metadata was recovered by laborious searches to find and
fix inconsistencies. Use of recovery techniques imposed little overhead during
normal operation of the system. When a failure was detected, however, CPU
overhead was incurred in checking consistency of metadata, and the system was
unavailable during recovery, as well. As an example, consider what happened
when a Unix system using the ext2 file system was shut down uncleanly. On
rebooting, the file system would realize that it was shut down uncleanly, and hence
its metadata was likely to be inconsistent. It would invoke the fsck program to
recover the metadata. fsck would look through every file system data structure
on the disk and try to fix any inconsistencies it could find. Operation of the OS
was delayed while fsck executed.
A modern file system uses fault tolerance techniques so that it can resume its
operation quickly after an unclean shutdown. A journaling file system implements
fault tolerance by maintaining a journal, which resembles the intentions list used
to implement atomic actions (see Section 13.11.2). The file system records actions
that it is about to perform in the journal before actually performing them. When
operation of a file system is restored after an unclean shutdown, it consults the
journal to identify actions that were not performed as a result of the shutdown
and performs them, thus ensuring correctness of file data and metadata. The ext3



524  Part 4  File  Systems and I/O Management
                   Table 13.6    Journaling    Modes
                   Mode                        Description
                   Write behind                Protects only metadata. Does not provide any
                                               protection to file data.
                   Ordered data                Protects metadata. Limited protection is offered for  file
                                               data as well--it is written to disk before metadata
                                               concerning it is written.
                   Full data                   Journals both file data and metadata.
                   file system of Linux, XFS of Silicon Graphics, JFS of IBM, and VxFS of Veritas
                   are some examples of journaling file systems.
                   Use of fault tolerance techniques to protect consistency of both metadata
                   and file data causes high overhead--it amounts to performing every file update
                   as an atomic action. Hence a journaling file system offers a menu of journaling
                   modes, each mode providing a different kind of protection to metadata and file
                   data. A system administrator can choose a journaling mode to suit the kind of
                   reliability that is necessary in the computing environment. Table 13.6 describes
                   three journaling modes.
                   In the write behind mode, metadata is protected but file data is not. When
                   new data is added to a file, this mode ensures that the disk blocks allocated to
                   hold the new data would be added in the disk copy of the file's FMT. However,
                   it does not ensure that new data added to the file would be recorded in these
                   blocks before a fault can occur. Consequently, if a fault occurs while the file is
                   being processed, the disk copy of the file may contain junk data. The ordered
                   data mode avoids this problem by ensuring that file data is written to disk before
                   metadata is written. However, when this mode is used, we may have a situation
                   where disk blocks in which the new file data have been written are not added to
                   the file map table. The full data mode protects both metadata and file data.
                   13.13  VIRTUAL FILE SYSTEM                                                              ·
                   Users have diverse requirements of a file system, such as convenience, high reli-
                   ability, fast response, and access to files on other computer systems. A single file
                   system cannot provide all these features, so an operating system provides a virtual
                   file system (VFS), which facilitates simultaneous operation of several file systems.
                   This way each user gets to use the file system he prefers.
                   A virtual file system (VFS) is an abstraction that supports a generic file
                   model. The abstraction is implemented by a VFS layer that is situated between a
                   process and a file system (see Figure 13.31). The VFS layer has two interfaces--an
                   interface with the file systems, and an interface with processes. Any file system that
                   conforms to the specification of the VFS­file system interface can be installed to
                   work under the VFS. This feature makes it easy to add a new file system. The VFS­
                   process interface provides functionalities to perform generic open, close, read, and



                                                                                Chapter 13  File  Systems  525
                                   Processes
                                                           Virtual file system
                                   Metadata                (VFS)
   Metadata    File data           Metadata  File data     Metadata             File data
   File systems of type X          File systems of type Y  File systems of type Z
Figure 13.31 Virtual file system.
write operations on files, and mount, unmount operations on file systems. These
functionalities are invoked through system calls. The VFS determines which file
system a file actually belongs to and invokes the open, close, read, and write
functionalities of the specific file system through the VFS­file system interface.
It also invokes functions of the specific file system to implement mount and
unmount operations.
   All file systems operating under the VFS are available for use simultaneously.
In the system of Figure 13.31, one process may use a file system of type X while
another process simultaneously uses a file system of type Y. The virtual file system
can also be used to compose a heterogeneous file system. For example, a user can
mount a file system of type X in a directory of a file system of type Y. This feature
is useful with removable media like CDs; it permits a user to mount the file system
that exists in a CD in his current directory and access its files without any concern
for the fact that file data is recorded in a different format. This feature is also useful
in a distributed environment for mounting a remote file system into a file system
of a computer. It is described in Section 20.6.1.
   As shown in the schematic diagram of Figure 13.31, the virtual file system
does not contain any file data. It merely contains data structures that constitute
VFS metadata. Each file system contains its own metadata and file data. The key
data structure used by the virtual file system is the virtual node, popularly called
vnode, which contains the information needed for performing operations on a
file. It can be looked upon as a file object with the following three parts:
·  File-system-independent data such as a file id that is unique within the
   domain of the VFS, which may be the individual computer system or a net-
   work; the file type, e.g., directory, data file, or a special file; and other fields
   such as an open count, lock, and flags.
·  File-system-specific data such as the file map table.
·  Addresses of functions in the file system that contains this file. These func-
   tions implement the open, close, read, and write operations on files of this
   file type.



526  Part 4  File Systems and I/O Management
                Operating systems have provided virtual file systems since the 1990s. Sun OS
             and Solaris operating systems of Sun, Unix System V version 4, Unix 4.2 BSD,
             and Linux provide a virtual file system.
             13.14      CASE STUDIES OF FILE SYSTEMS                                                    ·
             13.14.1 Unix File System
             The design of the Unix file system is greatly influenced by the MULTICS file
             system. In this section we describe important features common to most versions
             of Unix, in the context of the generic description of file processing in Sections 13.4
             and 13.8.
             Inodes, File Descriptors, and File Structures    The information that constituted
             the directory entry of a file in Figure 13.6 is split in Unix between the directory
             entry and the inode of the file. The directory entry contains only the file name
             and the inode number; the bulk of the information concerning a file is contained
             in its inode. Files are considered to be streams of characters and are accessed
             sequentially. The system administrator can specify a disk quota for each user. It
             prevents a user from occupying too much disk space.
                The inode data structure is maintained on disk. Some of its fields contain the
             following information:
             ·  File type, e.g., whether directory, link, or special file
             ·  Number of links to the file
             ·  File size
             ·  Id of the device on which the file is stored
             ·  Inode serial number
             ·  User and group ids of the owner
             ·  Access permissions
             ·  Allocation information
                The splitting of the conventional directory entry into the directory entry and
             the inode facilitates creation and deletion of links. A file can be deleted when its
             number of links drops to zero. Note the similarity between fields of the inode and
             those of the FCB (see Table 13.3).
                Figure 13.32 illustrates the arrangement in memory during the processing
             of a file. It consists of inodes, file structures, and file descriptors. A file structure
             contains two fields--the current position in an open file, which is in the form of
             an offset from the start of the file; and a pointer to the inode for the file. Thus an
             inode and a file structure together contain all the information necessary to access
             the file. A file descriptor points to a file structure. File descriptors are stored in
             a per-process table. This table resembles the open files table (OFT) described in
             Section 13.8.
                When a process opens a file alpha, the directory entry for alpha is located.
             A directory lookup cache is employed to speed up this operation. Once the entry
             of alpha is located, its inode is copied into memory, unless memory already



                                                                         Chapter        13   File  Systems  527
               0
               1
               2                    Offset
                                    Inode pointer
                  Per-process       File                         Disk
                  table of          structure                    blocks
               file descriptors                                  of
                                                                 alpha
                                                      Inode
                                                      for alpha
Figure  13.32     Unix file system  data structures.
contains such a copy. The arrangement shown in Figure 13.32 is now set up and
the index of the file descriptor in the file descriptors table, which is an integer,
is passed back to the process that opened the file. The process can use it in a
manner that resembles use of the internal id of a file in the generic arrangement
of Sections 13.4 and 13.8.
When a process creates a child process, a table of descriptors is created for
the child process, and the file descriptors of the parent process are copied into it.
Thus more than one file descriptor may point to the same file structure. Processes
owning these file descriptors share the offset into the file. A read or write by one
process will modify the offset for the other processes as well.
File Sharing Semantics           Several processes may independently open the same file.
In that case, the arrangement of Figure 13.32 is set up for each process. Thus,
two or more file structures may point to the same inode. Processes using these file
structures have their own offsets into the file, so a read or write by one process
does not modify the offset used by other processes.
Unix provides single-image mutable file semantics for concurrent file sharing.
As shown in Figure 13.32, every process that opens a file points to the copy
of its inode through the file descriptor and file structure. Thus, all processes
sharing a file use the same copy of the file; changes made by one process are
immediately visible to other processes sharing the file. Implementation of these
semantics is aided by the fact that Unix uses a disk cache called buffer cache
rather than buffers for individual file processing activities (see Section 14.13.1.2).
To avoid race conditions while the inode of a shared file is accessed, a lock field
is provided in the memory copy of an inode. A process trying to access an inode
must sleep if the lock is set by some other process. Processes concurrently using a
file must make their own arrangements to avoid race conditions on data contained
in the file.
Disk Space Allocation            Unix uses indexed disk space allocation, with a disk block
size of 4 KB. Each file has a file allocation table analogous to an FMT, which is
maintained in its inode. The allocation table contains 15 entries (see Figure 13.33).
Twelve of these entries directly point to data blocks of the file. The next entry in
the allocation table points to an indirect block, i.e., a block that itself contains
pointers to data blocks. The next two entries point to double and triple indirect



528  Part 4  File  Systems  and  I/O  Management
                                      1
                                          ...
                                      12                         Single
                                      13                         indirection
                                      14                                      Double
                                      15                                 indirection
                                                                                      Triple
                                                                                      indirection
                   Figure   13.33  Unix file allocation table.
                   blocks, respectively. In this manner, the total file size can be as large as 242 bytes.
                   However, the file size information is stored in a 32-bit word of the inode. Hence
                   file size is limited to 232-1 bytes, for which the direct, single, and double indirect
                   blocks of the allocation table are adequate.
                   For file sizes smaller than 48 KB, this arrangement is as efficient as the
                   flat FMT arrangement discussed in Section 13.7. Such files also have a small
                   allocation table that can fit into the inode itself. The indirect blocks permit files
                   to grow to large sizes, although their access involves traversing the indirection in
                   the file allocation table. A survey of Unix file sizes conducted in 1996 reported
                   that the average file size in Unix was 22 KB, and over 93 percent of files had sizes
                   smaller than 32 KB. Thus the Unix file allocation table is as efficient as the flat
                   FMT for most files.
                   Unix maintains a free list of disk blocks. Each entry in the list is similar to an
                   indirect block in an FMT--it contains addresses of free disk blocks, and the id of
                   the next disk block in the free list. This arrangement minimizes the overhead of
                   adding disk blocks to the free list when a file is deleted; only marginal processing
                   is required for files that contain only direct and single indirect blocks. A lock field
                   is associated with the free list to avoid race conditions when disk blocks are added
                   and deleted from it. A file system program named mkfs is used to form the free
                   list when a new file system is created. mkfs lists the free blocks in ascending order
                   by block number while forming the free list. However, this ordering is lost as disk
                   blocks are added to and deleted from the free list during file system operation.
                   The file system makes no effort to restore this order. Thus blocks allocated to a
                   file may be dispersed throughout a disk, which reduces the access efficiency of a
                   file. BSD Unix uses cylinder groups to address this issue (see Section 13.7).
                   Multiple File Systems       The root of a file system is called the superblock. It con-
                   tains the size of the file system, the free list, and the size of the inode list. In the
                   interest of efficiency, Unix maintains the superblock in memory but copies it onto
                   the disk periodically. This arrangement implies that some part of file system state
                   is lost in the event of a system crash. The file system can reconstruct some of this
                   information, e.g., the free list, by analyzing the disk status. This is done as a part
                   of the system booting procedure.



                                                                         Chapter 13      File  Systems  529
There can be many file systems in a Unix system. Each file system has to
be kept on a single logical disk device; hence files cannot span different logical
disks. A physical disk can be partitioned into many logical disks and a file system
can be constructed on each of them. Such partitioning provides some protection
across file systems, and also prevents a file system from occupying too much disk
space. A file system has to be mounted before being accessed. Only a user with
the root password, typically a system administrator, can mount a file system.
Mounting and unmounting of file systems works as follows: A logical disk
containing a file system is given a device special file name. This name is indi-
cated as FS_name in a mount command (see Section 13.5). When a file system is
mounted, the superblock of the mounted file system is loaded in memory. Disk
block allocation for a file in the mounted file system is performed within the
logical disk device of the mounted file system. Files in a mounted file system are
accessed as described in Section 13.9.1.
A file open call in Unix specifies three parameters--path name, flags, and
mode. Flags indicate what kind of operations will be performed on the file--
whether read, write, or read/write. The mode parameter is provided only when
a file is being created. It specifies the access privileges to be associated with the
file. This information is typically copied from the file creation mask of the user.
The owner of a file can change the file protection information any time through
a chmod command.
13.14.1.1 Berkeley Fast File System
The Berkeley fast file system (FFS) for Unix was developed to address the limita-
tions of the file system s5fs. It supports a symbolic link, which is merely a file that
contains a reference to another file. If the symbolic link is encountered during
path name resolution, the path name resolution is simply continued at the refer-
enced file. It also includes several innovations concerning disk block allocation
and disk access, which we describe in the following.
FFS permits use of large disk blocks--blocks can be as large as 8 KB.
Different file systems can use different block sizes; however, block size cannot vary
within one file system. A large block size makes larger files accessible through the
direct blocks in the file allocation table. A large block size also makes I/O opera-
tions more efficient and makes efficient use of the disk. However, a large block size
leads to large internal fragmentation in the last disk block of a file. FFS counters
this effect by allocating a part of a disk block to the last portion of a file. This
way, a disk block may be shared by many files. To facilitate such allocation, a disk
block is divided into equal-size parts called fragments. The number of fragments
in a disk block is a parameter of a file system, and is either 1, 2, 4, or 8. FFS uses
a bit map to keep track of free fragments of a block. File growth requires special
attention in this scheme, because a file may need more fragments, which might
not be available in the same disk block. In such cases, all its fragments are moved
to another disk block and the previously allocated fragments are freed.
FFS uses the notion of cylinder groups to reduce the movement of disk heads
(see Section 13.7). To reduce disk head movement further, it puts all inodes of
a file system in the same cylinder group and tries to put the inode of a file and



530  Part 4  File Systems and I/O Management
             the file itself in the same cylinder group. It also prevents a file from filling up
             a cylinder group. If a file grows to a size that would violate this constraint, it
             relocates the entire file into a larger cylinder group. This technique increases the
             possibility that concurrently accessed files will be found within the same cylinder
             group, which would reduce disk head movement.
             FFS tries to minimize rotational latency while reading a sequential file. As
             described later in Section 14.3.2, a certain period of time elapses between the
             end of a disk read operation and start of the next disk read operation. During
             this time, the next few disk blocks inevitably pass under the disk head. Even if a
             command to read the next disk block is issued immediately, the block can therefore
             be read only during the next revolution of the disk. To ensure that consecutively
             numbered blocks on a track can be read during the same disk revolution, FFS
             separates them by putting a few other disk blocks between them. This feature
             is similar to the technique of interleaving of sectors in a track discussed later in
             Section 14.3.2. As illustrated there, this technique has a significant impact on disk
             throughput.
             13.14.2 Linux File System
             Linux provides a virtual file system (VFS) which supports a common file model
             that resembles the Unix file model. This file model is implemented by using Unix-
             like data structures such as superblocks and inodes. When a file is opened, the VFS
             transforms its directory entry into a dentry object. This dentry object is cached
             so that the overhead of building it from the directory entry is avoided if the file
             is opened repeatedly during a computing session. The standard file system of
             Linux is called ext2. The file system ext3 incorporates journaling, which provides
             integrity of file data and metadata and fast booting after an unclean shutdown
             (see Section 13.12).
             Ext2 provides a variety of file locks for process synchronization. Advisory
             locks are those that are supposed to be heeded by processes to ensure mutual
             exclusion; however, the file system does not enforce their use. Unix file locks
             belong to this category of locks. Mandatory locks are those that are checked by
             the file system; if a process tries to access data that is protected by a mandatory
             lock, the process is blocked until the lock is reset by its holder. A lease is a special
             kind of file lock that is valid for a specific amount of time after another process
             has tried to access the data protected by it. It is implemented as follows: If a
             process accesses some data that is protected by a lease, the holder of the lease
             is intimated by the file system. It now has a stipulated interval of time to finish
             accessing the file and release the lease. If it does not do so, its lease is broken and
             awarded to the process that tried to access the data protected by it.
             Design of ext2 was influenced by BSD's fast file system (see Section 13.14.1).
             Ext2 uses the notion of a block group, which is a set of consecutive disk blocks, to
             reduce the movement of disk heads when a file is opened and its data is accessed.
             It uses a bit map to keep track of free disk blocks in a block group. When a file
             is created, it tries to allocate disk space for the inode of the file within the same
             block group that contains its parent directory, and also accommodates the file



                                                                                Chapter 13        File Systems  531
data within the same block group. Every time a file is extended through addition
of new data, it searches the bit map of the block group to find a free disk block
that is close to a target disk block. If such a disk block is found, it checks whether
a few adjoining disk blocks are also free and preallocates a few of these to the file.
If such a free disk block is not found, it preallocates a few contiguous disk blocks
located elsewhere in the block group. This way it is possible to read large sections
of data without having to move the disk head. When the file is closed, preallocated
but unused disk blocks are freed. This strategy of disk space allocation ensures use
of contiguous disk blocks for contiguous sections of file data even when files are
created and deleted at a high rate; it contributes to high file access performance.
13.14.3 Solaris File System
The    Solaris  file  system   provides   Unix-like  file  access  permissions      in  which
three  access   control     pairs  exist   in  each  access  control     list--for    the   file
owner, for other users in the file owner's group, and for all other users in
the  system     (see  Section  13.6).  To   provide  flexibility   that  is  lacking    in  this
basic  scheme,  it    also  permits    new  pairs  containing     <list_of_user_ids>        and
<list_of_access_privileges> to be added to the access control list of a file; the
system administrator specifies a new pair through the setfacl command.
     Solaris offers convenience and flexibility in file processing, through a virtual
file system as described in Section 13.13 and through a variety of file processing
modes. An exclusive open operation on a file fails if the file already exists; oth-
erwise, it creates the file and returns its descriptor in a single indivisible action.
This operation avoids race conditions while a new file is created; it is used by pro-
cesses that create a lock file to synchronize their activities. Record-level locking
is provided to implement fine-grained synchronization between processes that
concurrently access a file; when a process tries to access a record whose lock has
been set by another process, it is blocked until the lock is reset. The nonblocked
I/O mode is provided to avoid indefinite waits due to this feature. In this mode,
an I/O operation that tries to access a record that is locked by another process
simply fails. The process issuing the operation now has an opportunity to perform
some other actions and retry the I/O operation later. An asynchronous I/O mode
is provided in which a process is not blocked for its I/O operation to complete.
This mode is useful in real-time applications. In the direct I/O mode, the file sys-
tem does not buffer or cache file data; this mode facilitates applications such as
database systems that wish to perform their own buffering or caching.
     Data synchronization and file integrity flags can be set in the directory entry
of a file to obtain reliable operation. When some of these flags are set for a file,
I/O operations on the file ensure the integrity of metadata and/or the file data in
a manner resembling the journaling modes summarized in Table 13.6.
13.14.4 Windows File System
The NTFS file system of Windows is designed to meet the requirements of servers
and workstations. It provides support for client­server applications for file and



532  Part 4  File Systems and I/O Management
             database servers. A key feature of NTFS is recoverability of the file system, which
             we will discuss later in this section.
             A partition is a large collection of contiguous sectors on a disk; A volume is
             a logical partition on a disk; i.e., it is a virtual disk. A simple volume contains
             a single partition, while a multipartition volume called a spanned volume may
             contain up to 32 partitions located on one or more disks. NTFS performs disk
             space allocation in units called clusters. Each cluster is a group of contiguous
             sectors; the number of sectors in a cluster is a power of 2. A cluster on a volume is
             assigned a logical cluster number (LCN), whereas that in a file is assigned a virtual
             cluster number (VCN).
             An NTFS volume contains a boot sector, a master file table (MFT), some
             system files and user files. The presence of a boot sector makes every volume
             bootable. The MFT typically contains a 1 KB record for each file and directory
             on the volume, though large files may need multiple MFT records. The MFT also
             contains information about unused areas on the volume. Each file on a volume has
             a unique file reference, which consists of two components--a 48-bit file number,
             which is simply the record number of the MFT record occupied by it, and a 16-bit
             sequence number, which is a count of the number of times the MFT record has
             been used to date. The sequence number is used to prevent mix-ups between two
             files that have used the same MFT record at different times.
             Each file has a set of attributes, where each attribute is an independent byte
             stream that can be edited. Some standard attributes are common to all files.
             In addition, a file may have special attributes required in an application. Each
             file has an MFT record called its base file record, which contains the file ref-
             erence of the file, the time of its last update, and its attributes. An unnamed
             data attribute of a file contains file data. This arrangement permits the data in
             a small file or directory to be stored in its base file record itself, which provides
             high file access efficiency. If an attribute cannot fit in the file's base file record,
             it is stored as a nonresident attribute--it is stored in another MFT record and
             a pointer to it is put in its base file record. If the nonresident attribute itself
             cannot fit in one MFT record, it is stored in clusters on the disk and the MFT
             record pointed to by the file's base file record contains a VCN-to-LCN map-
             ping for its clusters. When a process opens a file, NTFS sets up a stream control
             block (SCB) for each of its attributes. An SCB contains a pointer to a file con-
             trol block for the file, which contains its file reference, and an offset into an
             attribute. When the process wishes to access an attribute of a file, NTFS uses
             the SCB to locate the file's base file record, finds information about location
             of the attribute, and then applies the offset to access the required portion of
             the attribute.
             A directory is organized as a B+ tree with files as its leaf nodes, and it is
             implemented by using an index file. The B+ tree data structure has the property
             that the length of each path in the tree is the same. This feature facilitates efficient
             search for a file in a directory (see Section 13.4.4). NTFS provides hard links to
             set up multiple paths to a file. It also supports symbolic links, called junctions,
             that redirect path name translation from a directory to an alternative one. This
             feature provides an effect that is analogous to mounting of file systems.



                                                                          Chapter 13    File  Systems  533
   NTFS employs two techniques to save disk space. If a file is sparse, it does not
allocate disk space to that portion of the file into which either no data has been
written, or the written data is such that one or more complete sectors contain
zeroes. It performs data compression for nonsparse files, using 16 consecutive
virtual clusters in a file as a unit. It replaces them by a compressed form only
if that action would save at least one cluster, and notes this fact so that it can
automatically perform decompression when the file is accessed.
   NTFS stores its metadata also in files. Some of these files are as follows:
·  The MFT file contains MFT records.
·  The log file contains information used for recovery; its use is described later
   in this section.
·  The attribute definition table contains information about attributes.
·  A bit map file indicates which clusters in a volume are allocated and which
   are free.
·  The boot file contains the boot sector.
·  A bad clusters file keeps track of clusters that are unusable due to hardware
   problems.
   NTFS provides robustness by ensuring consistency of the metadata when a
crash occurs. It is achieved by treating every modification of the metadata as an
atomic transaction. From the discussion of atomic actions in Section 13.11.2, it
would appear that atomic transactions can be implemented simply by writing
the "intentions" of a transaction in a write-ahead log file, and actually carrying
out the intentions when the transaction commits. However, certain actions like
creation of a new file's record in the MFT cannot be delayed until a transaction
commits, so NTFS uses a combined redo/undo log that contains two kinds of
records. The collection of redo records in the log resembles the intentions list of
Section 13.11.2, while the undo records pertain to actions that have been already
performed by transactions that are yet to commit. During normal operation, only
the redo records are used--they are processed to actually perform modification
of NTFS's metadata when a transaction commits. The undo records are used
only during recovery from a crash, as described in the following.
   NTFS performs recovery as follows: It modifies its metadata according to
the redo entries in the log pertaining to transactions that had committed prior to
the crash. It then processes the undo entries to undo the modifications performed
by transactions that had not committed prior to the crash. The metadata is in
a consistent state at the end of these actions, so NTFS now resumes normal
operation. This feature provides the write behind capabilities of journaling file
systems discussed in Section 13.12.
   In principle, log entries pertaining to a transaction can be discarded after all
of its actions are carried out during normal operation or recovery, or after all
of its actions are undone during recovery. However, NTFS cannot discard log
entries in this manner for two reasons--it stores its metadata in files, and it uses a
file cache (see Section 14.13.3) to speed up file processing activities. Thus, changes
made in a file containing metadata while processing the redo or undo entries in
the log would remain in the file cache for a long time and may be lost if a crash



534  Part 4  File Systems and I/O Management
             occurred before they were written to the disk. To prevent indefinite growth of the
             log, NTFS takes a checkpoint every 5 seconds. It puts a checkpoint record into
             the log at this time, in which it writes contents of dirty blocks existing in the file
             cache. When a crash occurs, NTFS locates the latest checkpoint record in the log,
             restores values of disk blocks found there in the file cache, and then processes the
             redo/undo entries of transactions that were in progress at the time of the crash.
             This recovery procedure does not require the log entries of transactions that had
             committed or aborted before the checkpoint was taken, hence NTFS deletes these
             log entries while taking the checkpoint.
                File data may be lost if a crash damages some disk blocks. The volume
             manager driver that runs under NTFS employs the RAID technology to tolerate
             such faults. Disk mirroring implies recording of identical data on disk blocks in
             two disks, so that one of the disk blocks would be accessible even if the other one
             is damaged because of a fault. (Disk mirroring and other RAID configurations
             are discussed in Section 14.3.5.)
                Windows Vista has many new features for recovery. The kernel transaction
             manager implements transaction semantics over files and objects which can span
             several computer systems. The backup and recovery center permits a user to specify
             when and how frequently each file should be backed up, and to request recovery
             of a specific previous version of the file. To conserve disk space, it stores only the
             changes made in a file in a backup.
             13.15  PERFORMANCE OF FILE SYSTEMS                                                      ·
             File systems employ five techniques to provide high file access performance:
             ·  Use of efficient data structures: Directories are organized by using data
                structures that facilitate fast search.
             ·  Effective disk space allocation: Disk space is allocated to a file in such a
                manner that little disk head movement and rotational delays are involved in
                processing of a sequential file.
             ·  Caching: Part of memory is used as a cache for data stored on an I/O device.
                As discussed in Section 2.2.3, caching speeds up accesses to information that
                exhibits either temporal locality or spatial locality--that is, data that is either
                repeatedly accessed or located in proximity of previously accessed data.
             ·  Buffering: A buffer is a memory area that is used to store data temporarily.
                The file system loads data from an I/O device into a buffer before a process
                needs it, so that the process can access the data without having to wait for an
                I/O operation to complete. Converse actions are performed when a process
                wishes to write data in a file.
             ·  Disk scheduling: I/O operations on a disk are performed in an order that
                reduces disk head movement; it ensures high throughput of a disk.
                Figure 13.34 summarizes how a file system uses these techniques to speed up
             file processing. Hash tables and B+ trees enable fast searches in a directory (see
             Section 13.4.3). Disk space allocation of a file is confined to extents and cylinder



                                                                             Chapter 13  File  Systems  535
                          Cached and buffered
                          data and metadata
        Process Pi        phi
                               Directories
        open   phi
                               FMTs
        read   phi,..
                               File data
Operation                 Techniques employed for speedup
Directory access          Directory cache
Directory search          Hashtables, B+ trees
Accessing file map table  File map table cache in memory
Accessing a disk block    Disk block allocation in extents and cylinder groups,
                          Disk block cache in memory, disk scheduling, disk
                          block cache in I/O device
Accessing data            Buffering and blocking of data, or use of a file cache
Figure  13.34  Techniques employed to provide high file access performance.
groups to reduce disk head movement and rotational delays (see Section 13.7).
The other techniques provide fast access to file data and metadata of a file system,
such as directory entries and file map tables.
Directories are cached in memory when accessed for the first time. Thus a
directory used to resolve a path name is retained in the cache to speed up future
references to files located in it. This cache is called a directory names cache. A
file map table is buffered in memory when the file is opened, in anticipation of
accesses to it. It may be cached after its first access. Buffering may not be feasible
if a file map table is large in size. In that case, parts of it may be cached in memory
when first referenced.
A disk cache stores disk blocks in memory following their first use in a file
processing activity. Hit ratios better than 0.9 are possible in the disk cache. Hence
its use reduces the number of I/O operations on a disk significantly. An access
method uses buffering and blocking of file data or stores file data in a file cache
to reduce the wait time involved in an I/O operation. Disk scheduling is used to
reduce disk head movement and the average wait time for I/O operations. These
techniques are employed by the IOCS; they are discussed later in Chapter 14.
As technology advances, techniques that were developed for use in soft-
ware become implemented in the hardware. Modern I/O device technology
incorporates some of the techniques mentioned in Figure 13.34. Thus SCSI disks



536  Part 4  File Systems and I/O Management
                  provide disk scheduling in the device itself. RAID units contain a disk block
                  buffer, which can be used to both buffer and cache disk blocks. These technologies
                  are discussed later in Chapter 14.
                  13.15.1 Log-Structured File System
                  Disk caching reduces the number of read operations directed at a disk. Hence
                  disk usage is dominated by disk head movement and write operations. Disk head
                  movement can be reduced through disk scheduling and through the use of cylinder
                  groups in disk space allocation for files. However, these techniques are less effective
                  when files located in different parts of a disk are processed simultaneously, which
                  is the case most of the time in a shared computer system. For example, in a Unix
                  system, write operations to a disk consume only about 10 percent of the disk
                  time; the rest of the time is spent in disk head movement, which leads to poor
                  throughput of a disk.
                     A log-structured file system reduces disk head movement through a radically
                  different file organization. It writes file data of all files together in a single sequen-
                  tial structure that resembles a journal. We call it the log file. When an update or
                  write operation is performed on any file, the new data is simply added to the end
                  of the log file. Hence little disk head movement is involved in this operation. The
                  file system writes special index blocks into the log file to contain metadata about
                  the location of each file's data in the log file. These index blocks are used when file
                  data has to be read off the disk. Thus, little disk head movement is required for
                  reading data that was written into a file recently; however, more disk head move-
                  ment is involved for older data. Performance studies on the Sprite log-structured
                  file system showed that disk head movement accounted for only 30 percent of the
                  disk time consumed during file processing, and its performance was superior to
                  the conventional file system for frequent small writes. Example 13.12 illustrates
                  operation of a log-structured file system.
·
   Example 13.12  Log-Structured File System
                  Figure 13.35(a) is a schematic diagram of the arrangement used in a log-
                  structured file system. For simplicity, it shows the metadata and file data of
                  a single file in the log file. The data blocks in the log file are numbered for
                  convenience. The directory entry of a file points to an index block in the log
                  file; we assume the index block to contain the FMT of the file. When file data
                  residing in block 1 is updated, the new values are written into a new disk block,
                  i.e., block 4. Similarly some file data is written into disk block 5 when the data in
                  block 3 is updated. The file system now writes a new index block that contains
                  the updated FMT of the file and sets the FMT pointer in the directory entry
                  of the file to point to the new index block. The new FMT contains pointers to
                  the two new data blocks and to data block 2 that has not been modified [see
                  Figure 13.35(b)]. The old index block and disk blocks 1 and 3 are now free.
                  ·



                                                                             Chapter 13  File  Systems              537
        (a)             Index block
               1  2  3                                                  Log file
        (b)                                                     Index block
               1  2  3  4                                    5          Log file
Figure  13.35  File update in a log-structured file system.
Since the log file is written as a sequential-access file, the file system has to
ensure that a large-enough disk area is always available to write the log file. It
achieves this by moving data blocks around on the disk to make a large free
area available for the log file. This operation is analogous to memory compaction
(see Section 11.5.1.4). It involves considerable disk head movement, which now
dominates the disk usage; however, compaction is performed as a background
activity so it does not delay file processing activities in processes.
13.16   SUMMARY                                                                                                          ·
Computer users have many expectations of a file                 organizations suit sequential and random access
system--convenience, good performance of a file                 to records in a file, respectively. Several hybrid
processing activity, and efficient use of I/O devices.          organizations, such as the index sequential organi-
To deal with these concerns effectively, the file sys-          zation, are also widely used. Second, a file system
tem is structured into two layers: The file system              allows users to group related files logically and con-
layer deals with convenience issues such as sharing             veniently by creating files and directories to any
and protection of files and reliability; the input-             desired level. Third, it allows a user to specify which
output control system (IOCS) layer implements file              other users may access his files in what manner,
operations and deals with efficiency issues. In this            which facilitates sharing and protection of files.
chapter, we discussed the techniques of file systems.           The file system allocates disk space to a file
A file may be a structured file, i.e., it may con-              such that fragmentation of disk space is avoided
tain records of data, or it may be an unstructured,             and file data can be accessed efficiently. Indexed
or byte stream, file. A file system provides con-               allocation of disk space to a file uses a disk block
venience to its users through three means. First,               or an extent as the unit of disk space for alloca-
it provides different file organizations, where each            tion. The disk blocks or extents allocated to a file
organization suits a specific pattern of accessing              are confined to cylinder groups to ensure efficient
records in a file--it provides a method of arranging            access to file data. Information concerning the disk
records of a file on an I/O device and access-                  space allocated to a file is stored in a file map table
ing them efficiently. The sequential and direct file            (FMT).



538       Part 4     File Systems and I/O Management
     Before reading from or writing into a file, a             inconsistent by faults such as power outages. It is
process has to open the file by specifying its path            achieved through an atomic action, which ensures
name in the directory structure. The file system               that all actions in a set of related actions are com-
traverses the path name, determines which file is              pleted even if faults occur. An atomic action incurs
being opened, and sets up a file control block (FCB)           considerable overhead, therefore journaling file sys-
to contain information such as the file's type and             tems provide a menu of reliability modes that guard
organization, address of its FMT, and address of its           data and metadata to different extents, so that a
next record. When the process wishes to perform                system administrator can choose the mode that is
a read or write operation, the file system passes              cost-effective for a computing environment.
the FCB to the IOCS, and the IOCS implements                   A virtual file system (VFS) is a software layer
the operation, using the information accessible                that permits several file systems to be in opera-
through the FCB. The file system specifies the file            tion on a computer system simultaneously, so that
sharing semantics, which determine how the results             a user can choose the file system that is most
of a file update made by a process should be visible           suitable for his application. The VFS provides a
to other processes using the file concurrently.                unified method of accessing different file systems.
     The file system ensures reliability of opera-             A process invokes the VFS layer using generalized
tion by ensuring that the file data and metadata               commands to access files, and the VFS layer directs
such as FMTs and FCBs are not lost or made                     the commands to the appropriate file system.
TEST  YOUR CONCEPTS                                                                                                    ·
13.1  Classify each of the following statements as true        g.    During creation of a new file in a mounted
      or false:                                                      file system, the file is allocated disk space
      a. Allocation of contiguous disk space for a                   in the logical disk used by the mounted file
          sequential-access file leads to more efficient             system.
          file processing than allocation of noncontigu-       h.    The effect of mounting a file system is similar
          ous disk space.                                            to that of setting up a link in the directory
      b. Cycles in the directory structure create diffi-             structure, except that the effect is obliterated
          culties with the file deletion operation.                  when the file system is unmounted.
      c. Absolute path names for two different files           i.    When a user updates the data in a single-
          cannot be identical, whereas their relative                image mutable file, changes made to the file
          path names could be identical.                             are not immediately visible to users concur-
      d. The purpose of the file control block (FCB)                 rently using the file.
          is to facilitate a file open operation; the FCB      j.    When a fault occurs, a single incremental
          can be deleted immediately after the file is               backup is adequate for restoring the entire
          opened.                                                    file system to a previous consistent state.
      e.  When    a  file   is  closed  after  updating,  the  k.    Journaling incurs overhead during operation
          directory containing the file may have to be               of a file system.
          updated as well.                                     l.    A virtual file system permits use of many file
      f. Maintaining a file's file map table (FMT)                   systems in a computer; however, these file
          in memory while the file is being processed                systems cannot be used concurrently.
          reduces the number of disk accesses during           13.2  Select the appropriate alternative in each of
          file processing.                                           the following questions:



                                                                                     Chapter 13      File Systems           539
      a. The       file  control  block     (FCB)      of  a  file  b.    The stable storage technique is:
          alpha:                                                          i.    A fault tolerance technique that is used to
             i.    Contains only information copied from                        recover from two faulty blocks on a disk
                   the directory entry of alpha                           ii.   A recovery technique used to recover the
             ii.   Is used to avoid frequent accesses to the                    file system after a power failure
                   directory entry of alpha                               iii.  A fault tolerance technique that is used to
             iii.  Is    used  only     to  protect  file  alpha                recover from one faulty block on a disk
                   against invalid accesses                               iv.   None of the above
EXERCISES                                                                                                                        ·
13.1  A file named data is frequently accessed by                         If all records in the index sequential file have the
      users in a system. The following alternatives are                   same probability of being accessed, show that
      proposed to simplify access to data.                                access efficiency of the file will be affected by the
      a. Set up links from every user's home directory                    presence of records in the overflow area. Can
          to data.                                                        access efficiency be restored by rewriting the file
      b. Copy data into every user's home directory.                      as a new file that does not contain any overflow
      Compare the advantages and drawbacks of these                       records?
      approaches.                                                   13.4  The Amoeba distributed operating system uses
13.2  An index sequential file contains 10,000 records.                   contiguous allocation of disk space. When a file
      Its index contains 100 entries. Each index entry                    is updated, it writes the updated file as a new file
      describes an area of the file that contains 100                     and deletes its old copy.
      records.     If    all   records  in  the  file  have   the         Comment on the advantages and drawbacks of
      same probability of being accessed, calculate                       this approach.
      the average number of disk operations involved                13.5  Does noncontiguous allocation of disk space
      in  accessing      a    record.   Compare      this  number         influence  the  feasibility   and  effectiveness       of
      with the number of disk operations required if                      the fundamental file organizations discussed in
      the same records were stored in a sequential                        Section 13.3?
      file.                                                         13.6  A file system uses indexed disk space allocation.
13.3  Consider the index sequential file of Figure 13.5.                  The size of each disk block is 4 KB and each disk
      The following problem arises when a new record,                     block address is 4 bytes in length. The size of the
      say record for employee number 8 (we will call                      FMT is one disk block. It contains 12 pointers
      it record 8), is added to it. There is no space                     to data blocks. All other pointers point to index
      to store the new record on the track. Hence the                     blocks.
      access method takes out record 13 from the track                    A sequential file info contains 5000 records,
      and shifts records 10 and 12 to make space for                      each of size 4 KB. Characteristics of the disk and
      the new record. Record 13 is now put into an                        of a process that reads and processes all records
      overflow area. A new field called overflow area                     in file info are as follows:
      pointer is added to each entry in the track index.                  Average time to read a disk block = 3 ms
      This field in the first entry of the track index is                 Average time to process a record = 5 ms
      set to point to record 13 in the overflow area. If
      more records overflow out of the first track, they                  Calculate the elapsed time of the process under
      are put into a linked list and the overflow area                    the following conditions:
      pointer of the track index points to the head of                    a. The file system keeps the FMT in memory,
      the list. Similar linked lists may be formed for                    but does not keep any index blocks in memory
      several tracks over a period of time.                               while processing info.



540          Part 4  File Systems and I/O Management
       b. The file system keeps the FMT and one index                           directory structure rooted at X is mounted in
           block of info in memory.                                             directory Y/A. It should be possible to access
13.7   A new record is to be added to the file info of                          file D as ..Y/A/B/D.
       Problem 13.15.1. What is the minimum number                          b. Multiple    mounts:     The    directory       structure
       of disk operations required to reflect this change                       rooted at some directory, say, W, is mounted
       in info on the disk? What is the maximum                                 at many mount points simultaneously.
       number?                                                       13.13  When indexed allocation is used for files, explain
13.8   A file system uses indexed allocation of disk                        how a disk block may occur in more than one
       space;    however,     it  permits     a  sequential    file         file if a fault occurs.
       to  contain   partially       full  disk  blocks.   What      13.14  Let  Algorithm    13.1     be  rewritten      as  follows:
       are the advantages and disadvantages of this                         1. dj .next := d1.next;
       scheme?                                                              2. d1.next := address (dj );
13.9   A file system uses contiguous allocation of disk                     3. Write dj to disk.
       space. The sequential access method handles                          4. Write d1 to disk.
       bad blocks on a disk as follows: If an error occurs                  Does this modified algorithm           prevent    mix-up
       while reading/writing a block, it consults the bad                   between files in the event of a fault?
       blocks table that is itself stored on the disk and            13.15  Explain how the byte offset into a Unix file can
       accesses the alternative disk block assigned to                      be converted into the pair (<disk block id>,
       the bad block. Assuming all disk accesses to                         <byte offset>).
       require identical access times, calculate degra-              13.16  By   default,  Unix      assigns  the  files   stdin  and
       dation in file access performance if 2 percent                       stdout to the keyboard and terminal, respec-
       of the disk blocks allocated to a file are bad                       tively. A user can use the redirection operators
       blocks. Suggest a method to improve the access                       < and > in a command to override the default
       performance.                                                         assignments and use some other files for input
13.10  To reduce the overhead of file access valida-                        and output. The "redirect and append" operator
       tion  (see    Step  2  of     Section     13.9.2),  an  OS           >> appends the output of a process to the end
       designer proposes to perform validation only at                      of an existing file. The default assignments of
       file "open" time. As mentioned in Section 13.9.1,                    the files are restored at the end of the command.
       the open statement specifies the kind of accesses                    These features can be implemented by perma-
       which will be made to the file, e.g., open          (abc,            nently associating FCBs for stdin and stdout with
       `read',       ..).  Is     a  single   access  validation            each process.
       check at file open time adequate? If not, explain                    a. Describe the file system actions involved in
       why. In either case, suggest an implementation                           implementing      the  default     assignments    for
       outline.                                                                 stdin and stdout and the redirection operators
13.11  Step 2 of Section 13.9.1 creates an FCB for every                        < and >.
       directory appearing in a path name.                                  b. Describe the file system actions involved in
       a. Is this arrangement adequate when a relative                          implementing the >> operator.
           path name is used?                                        13.17  Disk blocks allocated to a file are added to
       b. Are these entries necessary if a file is being                    the free list when the file is deleted. Write an
           opened for reading?                                              algorithm to perform this operation in Unix.
       c. Can the number of FCBs created per file be                 13.18  The Unix file system associates a lock field with
           reduced?                                                         the free list (see Section 13.14.1). Classify the
13.12  Explain how the following features can be incor-                     following statement as true or false: "Locking
       porated in a file system:                                            of the free list is necessary due to the nature
       a.  Cascaded  mounts:         Directory   C    contains  a           of   Unix  processes.    Such     locking  is     unneces-
           file D. The directory structure rooted at C                      sary in an OS using the conventional process
           is mounted at mount point X/B. Later, the                        model."



                                                                                             Chapter 13  File Systems             541
BIBLIOGRAPHY                                                                                                                      ·
Organick (1972) is historically the most important paper                  3.   Bina, E. J., and P. A. Emrath (1989): "A faster
on directory structures, since the MULTICS directory                           fsck for BSD UNIX," Proceedings of the Winter
structure has influenced most contemporary file sys-                           1989 USENIX Technical Conference, 173­185.
tems like Unix, Linux, Solaris, and Windows. USENIX                       4.   Bovet, D. P., and M. Cesati (2005): Understanding
(1992)    contains      proceedings    of   a   file  system      work-        the Linux Kernel, 3rd ed., O'Reilly, Sebastopol,
shop. Grosshans (1986), Weiderhold (1987), and Livadas                         Calif.
(1990) discuss file organizations and file systems.                       5.   Burrows, M., C. Jerian, B. Lampson, and
        McKusick et al. (1990) describes a memory-based                        T. Mann (1992): "On-line data compression in a
file system, which provides memory-mapped files and                            log-structured file system," ACM Sigplan Notices,
directory  structures      implemented         in  pageable       mem-         27, 9, 2­9.
ory. Levy and Silberschatz (1990) discusses file shar-                    6.   Florido, J. I. S. (2000): "Journal file systems,"
ing     semantics.      Lampson  (1981)     describes      the    stable       Linux Gazette, issue 55.
storage   technique     for    reliability  of     disk    data,  while   7.   Grosshans, D. (1986): File Systems: Design and
Svobodova      (1984)   surveys        how  atomic         actions  are        Implementation, Prentice Hall, Englewood Cliffs,
performed in various file servers. Florido (2000) dis-                         N.J.
cusses design of journaling file systems. Kleiman (1986)                  8.   Kleiman, S. R. (1986): "Vnodes: an architecture
describes the virtual file system design. Vahalia (1996)                       for multiple file system types in Sun Unix,"
describes the Unix virtual file system interface. Rosen-                       Proceedings of the Summer 1986 USENIX
blum and Ousterhout (1992) discusses design of the                             Technical Conference, 238­247.
Sprite log-structured file system, while Matthews et al.                  9.   Kowalski, T. (1978): "Fsck--the Unix system
(1997) discusses adaptive methods for improving the                            check program," Bell Laboratories, Murray Hill,
performance of log-structured file systems. McKusick                           N.J.
et   al.  (1996)    discusses  the   log-structured        file   system  10.  Lampson, B. W. (1981): "Atomic transactions," in
of Unix 4.4 BSD.                                                               Distributed systems--Architecture and
        Bach (1986) and Vahalia (1996) describe the Unix                       Implementation: An Advanced Course, Goos, G.,
file system. Kowalski (1978) describes the Unix program                        and J. Hartmanis (eds), Springer Verlag, Berlin,
used to check file system integrity. This program looks                        246­265.
through every file system data structure on disk. Bina                    11.  Levy, H. M., and A. Silberschatz (1990):
and Emrath (1989) discusses how the file system integrity                      "Distributed file systems: concepts and
checks can be speeded up in the Unix file system. Beck                         examples," ACM Computing Surveys, 22, 4,
et al. (2002) and Bovet and Cesati (2005) discuss the                          321­374.
ext2 file system of Linux. Mauro and McDougall (2006)                     12.  Livadas, P. (1990): File Structures: Theory and
discusses the Solaris file system. Nagar (1997) and Russi-                     Practice, Prentice Hall, Englewood Cliffs, N.J.
novich    and     Solomon      (2005)  describe       the  NTFS     file  13.  Love, R. (2005): Linux Kernel Development,
system of Windows.                                                             2nd ed., Novell Press.
                                                                          14.  Matthews, J. N., D. Roselli, A. M. Costello,
    1.                                                                         R. Y. Wang, and T. E. Anderson (1997):
          Bach, M. J. (1986): The Design of the Unix                           "Improving the performance of log-structured file
          Operating System, Prentice Hall, Englewood                           systems with adaptive methods," Proceedings of
          Cliffs, N.J.                                                         Sixteenth Symposium on Operating Systems
    2.    Beck, M., H. Bohme, M. Dziadzka, U. Kunitz,                          Principles, 238­251.
          R. Magnus, C. Schroter, and D. Verworner                        15.  Mauro, J., and R. McDougall (2006): Solaris
          (2002): Linux Kernel Programming, Pearson                            Internals, 2nd ed., Prentice-Hall, Englewood
          Education, New York.                                                 Cliffs, N.J.



542  Part 4  File Systems and I/O Management
16.  McKusick, M. K., K. Bostic, M. Karels, and           log-structured file system," ACM Transactions on
     J. S. Quarterman (1996): The Design and              Computer Systems, 10, 2, 26­52.
     Implementation of the 4.4BSD Operating System,  21.  Russinovich, M. E., and D. A. Solomon (2005):
     Addison Wesley, Reading, Mass.                       Microsoft Windows Internals, 4th ed., Microsoft
17.  McKusick, M. K., M. Karels, and K. Bostic            Press, Redmond, Wash.
     (1990): "A pageable memory based filesystem,"   22.  Svobodova, L. (1984): "File servers for
     Proceedings of the Summer 1990 USENIX                network-based distributed systems," ACM
     Technical Conference, 137­144.                       Computing Surveys, 16, 4, 353­398.
18.  Nagar, R. (1997): Windows NT File System        23.  USENIX (1992): Proceedings of the File Systems
     Internals, O'Reilly, Sebastopol, Calif.              Workshop, Ann Arbor, Mich., May 1992.
19.  Organick, E. I. (1972): The MULTICS System,     24.  Vahalia, U. (1996): Unix Internals: The New
     MIT Press, Cambridge, Mass.                          Frontiers, Prentice Hall, Englewood Cliffs, N.J.
20.  Rosenblum, M., and J. K. Ousterhout (1992):     25.  Weiderhold, G. (1987): File Organization for
     "The design and implementation of a                  Database Design, McGraw-Hill, New York.
