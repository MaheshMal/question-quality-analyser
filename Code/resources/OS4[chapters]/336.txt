Message Passing


                                  Chapte                                                  r  9
Message Passing
M essage passing suits diverse situations where exchange of information
     between processes plays a key role. One of its prominent uses is in
     the client­server paradigm, wherein a server process offers a service,
and other processes, called its clients, send messages to it to use its service. This
paradigm is used widely--a microkernel-based OS structures functionalities such
as scheduling in the form of servers, a conventional OS offers services such as
printing through servers, and, on the Internet, a variety of services are offered
by Web servers. Another prominent use of message passing is in higher-level
protocols for exchange of electronic mails and communication between tasks
in parallel or distributed programs. Here, message passing is used to exchange
information, while other parts of the protocol are employed to ensure reliability.
     The key issues in message passing are how the processes that send and receive
messages identify each other, and how the kernel performs various actions related
to delivery of messages--how it stores and delivers messages and whether it blocks
a process that sends a message until its message is delivered. These features are
operating system­specific.
     We describe different message passing arrangements employed in operating
systems and discuss their significance for user processes and for the kernel. We
also describe message passing in Unix and in Windows operating systems.
9.1  OVERVIEW OF MESSAGE PASSING                                                       ·
In Section 5.2.5, we summarized four ways in which processes interact with
one another--data sharing, message passing, synchronization, and signals (see
Table 5.7). Of these, we discussed data sharing and synchronization in Chapter 6
and signals in Chapter 5. Data sharing provides means to access values of shared
data in a mutually exclusive manner. Process synchronization is performed by
blocking a process until other processes have performed certain specific actions.
Capabilities of message passing overlap those of data sharing and synchroniza-
tion; however, each form of process interaction has its own niche application area.
We discuss this aspect after taking an overview of message passing.
     Figure 9.1 shows an example of message passing. Process Pi sends a message
to process Pj by executing the statement send (Pj, <message>). The compiled
code of the send statement invokes the library module send. send makes a
                                                                                                315



316  Part 2  Process Management
                                       Process Pi                    Process Pj
                                       ···                           ···
                                 send  (Pj , <message>);  receive    (Pi ,  msg_area);
                                       ···                           ···
             Figure 9.1  Message passing.
             system call send, with Pj and the message as parameters. Execution of the state-
             ment receive (Pi,         msg_area), where msg_area is an area in Pj's address
             space, results in a system call receive.
             The semantics of message passing are as follows: At a send call by Pi, the ker-
             nel checks whether process Pj is blocked on a receive call for receiving a message
             from process Pi. If so, it copies the message into msg_area and activates Pj. If
             process Pj has not already made a receive call, the kernel arranges to deliver the
             message to it when Pj eventually makes a receive call. When process Pj receives
             the message, it interprets the message and takes an appropriate action.
             Messages may be passed between processes that exist in the same computer or
             in different computers connected to a network. Also, the processes participating in
             message passing may decide on what a specific message means and what actions
             the receiver process should perform on receiving it. Because of this flexibility,
             message passing is used in the following applications:
             · Message passing is employed in the client­server paradigm, which is used to
             communicate between components of a microkernel-based operating system
             and user processes, to provide services such as the print service to processes
             within an OS, or to provide Web-based services to client processes located in
             other computers.
             · Message passing is used as the backbone of higher-level protocols employed
             for communicating between computers or for providing the electronic mail
             facility.
             · Message passing is used to implement communication between tasks in a
             parallel or distributed program.
             In principle, message passing can be performed by using shared variables. For
             example, msg_area in Figure 9.1 could be a shared variable. Pi could deposit a
             value or a message in it and Pj could collect it from there. However, this approach
             is cumbersome because the processes would have to create a shared variable with
             the correct size and share its name. They would also have to use synchronization
             analogous to the producers­consumers problem (see Section 6.7.1) to ensure
             that a receiver process accessed a message in a shared variable only after a sender
             process had deposited it there. Message passing is far simpler in this situation. It
             is also more general, because it can be used in a distributed system environment,
             where the shared variable approach is not feasible.
             The producers­consumers problem with a single buffer, a single producer
             process, and a single consumer process can be implemented by message passing
             as shown in Figure 9.2. The solution does not use any shared variables. Instead,
             process Pi, which is the producer process, has a variable called buffer and process



                                                                             Chapter 9  Message Passing  317
   begin
        Parbegin
             var buffer : . . . ;                var message_area : . . . ;
             repeat                              repeat
              { Produce in buffer }              receive (Pi, message_area);
              send (Pj , buffer);                { Consume from message_area     }
              { Remainder of the cycle }         { Remainder of the cycle }
             forever;                            forever;
        Parend;
        end.
                       Process Pi                          Process Pj
Figure  9.2  Producers­consumers solution using  message passing.
Pj, which is the consumer process, has a variable called message_area. The pro-
ducer process produces in buffer and sends the contents of buffer in a message to
the consumer. The consumer receives the message in message_area and consumes
it from there. The send system call blocks the producer process until the message
is delivered to the consumer, and the receive system call blocks the consumer until
a message is sent to it.
   The producers­consumers solution of Figure 9.2 is much simpler than the
solutions discussed in Chapter 6; however, it is restrictive because it permits a
single producer and a single consumer process. In the general case, it is effective
to use the process synchronization means discussed in Chapter 6 to implement a
system containing producers and consumers.
Issues in Message Passing          Two important issues in message passing are:
·  Naming of processes: Whether names of sender and receiver processes are
   explicitly indicated in send and receive statements, or whether their
   identities are deduced by the kernel in some other manner.
·  Delivery of messages: Whether a sender process is blocked until the message
   sent by it is delivered, what the order is in which messages are delivered to
   the receiver process, and how exceptional conditions are handled.
   These issues dictate implementation arrangements and also influence the
generality of message passing. For example, if a sender process is required to know
the identity of a receiver process, the scope of message passing would be limited
to processes in the same application. Relaxing this requirement would extend
message passing to processes in different applications and processes operating in
different computer systems. Similarly, providing FCFS message delivery may be
rather restrictive; processes may wish to receive messages in some other order.
9.1.1 Direct and Indirect Naming
In direct naming, sender and receiver processes mention each other's name. For
example, the send and receive statements might have the following syntax:



318  Part 2  Process Management
             send (<destination_ process>, <message_length>, <message_address>);
             receive (<source_ process>, <message_area>);
             where <destination_ process> and <source_ process> are process names (typi-
             cally, they are process ids assigned by the kernel), <message_address> is the
             address of the memory area in the sender process's address space that contains
             the textual form of the message to be sent, and <message_area> is a memory area
             in the receiver's address space where the message is to be delivered. The processes
             of Figure 9.2 used direct naming.
             Direct naming can be used in two ways: In symmetric naming, both sender
             and receiver processes specify each other's name. Thus, a process can decide which
             process to receive a message from. However, it has to know the name of every
             process that wishes to send it a message, which is difficult when processes of
             different applications wish to communicate, or when a server wishes to receive a
             request from any one of a set of clients. In asymmetric naming, the receiver does
             not name the process from which it wishes to receive a message; the kernel gives
             it a message sent to it by some process.
             In indirect naming, processes do not mention each other's name in send and
             receive statements. We discuss indirect naming in Section 9.3.
             9.1.2 Blocking and Nonblocking Sends
             A blocking send blocks a sender process until the message to be sent is delivered to
             the destination process. This method of message passing is called synchronous mes-
             sage passing. A nonblocking send call permits a sender to continue its operation
             after making a send call, irrespective of whether the message is delivered immedi-
             ately; such message passing is called asynchronous message passing. In both cases,
             the receive primitive is typically blocking.
             Synchronous message passing provides some nice properties for user pro-
             cesses and simplifies actions of the kernel. A sender process has a guarantee
             that the message sent by it is delivered before it continues its operation. This
             feature simplifies the design of concurrent processes. The kernel delivers the
             message immediately if the destination process has already made a receive call
             for receiving a message; otherwise, it blocks the sender process until the des-
             tination process makes a receive call. The kernel can simply let the message
             remain in the sender's memory area until it is delivered. However, use of block-
             ing sends has one drawback--it may unnecessarily delay a sender process in
             some situations, for example, while communicating with a heavily loaded print
             server.
             Asynchronous message passing enhances concurrency between the sender
             and receiver processes by letting the sender process continue its operation. How-
             ever, it also causes a synchronization problem because the sender should not
             alter contents of the memory area which contains text of the message until the
             message is delivered. To overcome this problem, the kernel performs message
             buffering--when a process makes a send call, the kernel allocates a buffer in
             the system area and copies the message into the buffer. This way, the sender



                                                                      Chapter 9        Message Passing  319
process is free to access the memory area that contained text of the message.
However, this arrangement involves substantial memory commitment for buffers
when many messages are awaiting delivery. It also consumes CPU time, as a
message has to be copied twice--once into a system buffer when a send call is
made, and later into the message area of the receiver at the time of message
delivery.
9.1.3 Exceptional Conditions in Message Passing
To facilitate handling of exceptional conditions, the send and receive calls take
two additional parameters. The first parameter is a set of flags indicating how the
process wants exceptional conditions to be handled; we will call this parameter
flags. The second parameter is the address of a memory area in which the kernel
provides a condition code describing the outcome of the send or receive call; we
will call this area status_area.
    When a process makes a send or receive call, the kernel deposits a con-
dition code in status_area. It then checks flags to decide whether it should
handle any exceptional conditions and performs the necessary actions. It then
returns control to the process. The process checks the condition code pro-
vided by the kernel and handles any exceptional conditions it wished to handle
itself.
    Some exceptional conditions and their handling actions are as follows:
1.  The destination process mentioned in a send call does not exist.
2.  In symmetric naming, the source process mentioned in a receive call does not
    exist.
3.  A send call cannot be processed because the kernel has run out of buffer
    memory.
4.  No message exists for a process when it makes a receive call.
5.  A set of processes becomes deadlocked when a process is blocked on a receive
    call.
    In cases 1 and 2, the kernel may abort the process that made the send or receive
call and set its termination code to describe the exceptional condition. In case 3,
the sender process may be blocked until some buffer space becomes available.
Case 4 is really not an exception if receives are blocking (they generally are!), but
it may be treated as an exception so that the receiving process has an opportunity
to handle the condition if it so desires. A process may prefer the standard action,
which is that the kernel should block the process until a message arrives for it, or
it may prefer an action of its own choice, like waiting for a specified amount of
time before giving up.
    More severe exceptions belong to the realm of OS policies. The deadlock situ-
ation of case 5 is an example. Most operating systems do not handle this particular
exception because it incurs the overhead of deadlock detection. Difficult-to-
handle situations, such as a process waiting a long time on a receive call, also
belong to the realm of OS policies.



320  Part 2  Process Management
             9.2  IMPLEMENTING MESSAGE PASSING                                                               ·
             9.2.1 Buffering of Interprocess Messages
             When a process Pi sends a message to some process Pj by using a nonblocking
             send, the kernel builds an interprocess message control block (IMCB) to store
             all information needed to deliver the message (see Figure 9.3). The control block
             contains names of the sender and destination processes, the length of the message,
             and the text of the message. The control block is allocated a buffer in the kernel
             area. When process Pj makes a receive call, the kernel copies the message from
             the appropriate IMCB into the message area provided by Pj.
                  The pointer fields of IMCBs are used to form IMCB lists to simplify message
             delivery. Figure 9.4 shows the organization of IMCB lists when blocking sends
             and FCFS message delivery are used. In symmetric naming, a separate list is
             used for every pair of communicating processes. When a process Pi performs a
             receive call to receive a message from process Pj, the IMCB list for the pair Pi­Pj
             is used to deliver the message. In asymmetric naming, a single IMCB list can
             be maintained per recipient process. When a process performs a receive, the first
             IMCB in its list is processed to deliver a message.
                  If blocking sends are used, at most one message sent by a process can be
             undelivered at any point in time. The process is blocked until the message is
             delivered. Hence it is not necessary to copy the message into an IMCB. The
                                                       Sender process
                                                     Destination process
                                                       Message length
                                                       Message text
                                                       or address
                                                       IMCB pointer
             Figure 9.3  Interprocess message control block (IMCB).
                  List headers           IMCB lists                    List headers       IMCB lists
                  for process pairs                                    for processes
             Pi­Pj                                                     Pi
                                                       ­                                                  ­
             Pi­Pk                                                     Pj   ­
                                                                            ...
                         ...             ­
                                                                       Pr
             Pi­Pl       ­                                                                ­
             (a)                                                       (b)
             Figure 9.4  Lists of IMCBs  for blocking  sends  in  (a)  symmetric naming;  (b) asymmetric  naming.



                                                                      Chapter 9            Message  Passing  321
kernel can simply note the address of the message text in the sender's memory
area, and use this information while delivering the message. This arrangement
saves one copy operation on the message. However, it faces difficulties if the
sender is swapped out before the message is delivered, so it may be preferable to
use an IMCB. Fewer IMCBs would be needed than when sends are nonblocking,
because at most one message sent by each process can be in an IMCB at any time.
   The kernel may have to reserve a considerable amount of memory for inter-
process messages, particularly if nonblocking sends are used. In such cases, it may
save message texts on the disk. An IMCB would then contain the address of the
disk block where the message is stored, rather than the message text itself.
9.2.2 Delivery of Interprocess Messages
When a process Pi sends a message to process Pj, the kernel delivers the message
to Pj immediately if Pj is currently blocked on a receive call for a message from
Pi, or from any process. After delivering the message, the kernel must also change
the state of Pj to ready. If process Pj has not already performed a receive call, the
kernel must arrange to deliver the message when Pj performs a receive call later.
Thus, message delivery actions occur at both send and receive calls.
   Recall from Section 5.2.4 that the kernel uses an event control block (ECB)
to note actions that should be performed when an anticipated event occurs. The
ECB contains three fields:
·  Description of the anticipated event
·  Id of the process that awaits the event
·  An ECB pointer for forming ECB lists
   Figure 9.5 shows use of ECBs to implement message passing with symmetric
naming and blocking sends. When Pi makes a send call, the kernel checks whether
an ECB exists for the send call by Pi, i.e., whether Pj had made a receive call and
was waiting for Pi to send a message. If it is not the case, the kernel knows that
the receive call would occur sometime in future, so it creates an ECB for the event
"receive from Pi by Pj" and specifies Pi as the process that will be affected by
the event. Process Pi is put into the blocked state and the address of the ECB is
put in the event info field of its PCB [see Figure 9.5(a)]. Figure 9.5(b) illustrates
            Pi        receive from Pi            Pj                   send to Pj
          blocked           by Pj                blocked              by Pi
        Event info          Pi                   Event info           Pj
          PCB of            ECB of               PCB of               ECB of
   sender process Pi  receiver process Pj   receiver process Pj       sender process Pi
   (a)                                      (b)
Figure 9.5  ECBs to   implement symmetric  naming and blocking sends  (a) at send; (b) at
receive.



322  Part 2  Process Management
             the case when process Pj makes a receive call before Pi makes a send call. An ECB
             for a "send to Pj by Pi" event is now created. The id of Pj is put in the ECB to
             indicate that the state of Pj will be affected when the send event occurs.
             Figure 9.6 shows complete details of the kernel actions for implementing
             message passing by using symmetric naming and blocking sends. For reasons
             mentioned earlier, the kernel creates an IMCB even though a sender process is
             blocked until message delivery. When process Pi sends a message to process Pj,
             the kernel first checks whether the send was anticipated, i.e., whether an ECB was
             created for the send event. It will have happened if process Pj has already made a
             receive call for a message from Pi. If this is the case, action S3 immediately delivers
             the message to Pj and changes its state from blocked to ready. The ECB and the
             IMCB are now destroyed. If an ECB for send does not exist, step S4 creates an
             ECB for a receive call by process Pj, which is now anticipated, blocks the sender
             process, and enters the IMCB in the IMCB list of process Pj. Converse actions
             are performed at a receive call: If a matching send has already occurred, a message
             is delivered to process Pj and Pi is activated; otherwise, an ECB is created for a
             send call and Pj is blocked.
                     At send to Pj by Pi:
                          Step                             Description
                          S1     Create an IMCB and initialize its fields;
                          S2     If an ECB for a `send to Pj by Pi' event exists
                          S3     then
                                       (a) Deliver the message to Pj ;
                                       (b) Activate Pj ;
                                       (c) Destroy the ECB and the IMCB;
                                       (d) Return to Pi;
                          S4     else
                                       (a) Create an ECB for a `receive from Pi by Pj ' event and
                                                 put id of Pi as the process awaiting the event;
                                       (b) Change the state of Pi to blocked and put the ECB
                                                 address in Pi's PCB;
                                       (c) Add the IMCB to Pj 's IMCB list;
                     At receive from Pi by Pj :
                          Step                             Description
                          R1     If a matching ECB for a `receive from Pi by Pj ' event exists
                          R2     then
                                       (a) Deliver the message from appropriate IMCB in Pj 's list;
                                       (b) Activate Pi;
                                       (c) Destroy the ECB and the IMCB;
                                       (d) Return to Pj ;
                          R3     else
                                       (a) Create an ECB for a `send to Pj by Pi' event and
                                                 put id of Pj as the process awaiting the event;
                                       (b) Change the state of Pj to blocked and put the ECB
                                                 address in Pj 's PCB;
             Figure  9.6  Kernel actions in message passing using symmetric naming and blocking sends.



                                                                           Chapter 9  Message  Passing  323
     Actions when nonblocking sends are used are simpler. It is not necessary
to block and activate the sender [see Steps S4(b) and R2(b) in Figure 9.6]. Cre-
ation of an ECB when a message being sent cannot be delivered immediately [see
Step S4(a)] is also unnecessary since a sender is not blocked until the message is
delivered.
9.3  MAILBOXES                                                                                          ·
A mailbox is a repository for interprocess messages. It has a unique name. The
owner of a mailbox is typically the process that created it. Only the owner process
can receive messages from a mailbox. Any process that knows the name of a
mailbox can send messages to it. Thus, sender and receiver processes use the name
of a mailbox, rather than each other's names, in send and receive statements;
it is an instance of indirect naming (see Section 9.1.1).
     Figure 9.7 illustrates message passing using a mailbox named sample. Pro-
cess Pi creates the mailbox, using the statement create_mailbox. Process
Pj sends a message to the mailbox, using the mailbox name in its send state-
ment. If Pi has not already executed a receive statement, the kernel would
store the message in a buffer. The kernel may associate a fixed set of buffers with
each mailbox, or it may allocate buffers from a common pool of buffers when
a message is sent. Both create_mailbox and send statements return with
condition codes.
     The kernel may provide a fixed set of mailbox names, or it may permit user
processes to assign mailbox names of their choice. In the former case, confidential-
ity of communication between a pair of processes cannot be guaranteed because
any process can use a mailbox. Confidentiality greatly improves when processes
can assign mailbox names of their own choice.
     To exercise control over creation and destruction of mailboxes, the kernel
may require a process to explicitly "connect" to a mailbox before starting to use
it, and to "disconnect" when it finishes using it. This way it can destroy a mailbox
                      Process Pi                           Process Pj
                          ···                              ···
            create_mailbox        (sample);      send  (sample, `. . .');
                          ···                              ···
            receive   (sample, `. . .');                   ···
                                                                Pj
                                          sample
            Owner of  Pi                                        Pk         Users of
            sample                                                         sample
                               buffers                          Pl
Figure 9.7  Creation and use of mailbox sample.



324  Part 2  Process Management
                  if no process is connected to it. Alternatively, it may permit the owner of a mailbox
                  to destroy it. In that case, it has the responsibility of informing all processes that
                  have "connected" to the mailbox. The kernel may permit the owner of a mailbox
                  to transfer the ownership to another process.
                     Use of a mailbox has following advantages:
                  ·  Anonymity of receiver: A process sending a message to request a service may
                     have no interest in the identity of the receiver process, as long as the receiver
                     process can perform the needed function. A mailbox relieves the sender pro-
                     cess of the need to know the identity of the receiver. Additionally, if the OS
                     permits the ownership of a mailbox to be changed dynamically, one process
                     can readily take over the service of another.
                  ·  Classification of messages: A process may create several mailboxes, and use
                     each mailbox to receive messages of a specific kind. This arrangement permits
                     easy classification of messages (see Example 9.1, below).
                     Anonymity of a receiver process, as we just saw, can offer the opportunity to
                  transfer a function from one process to another. Consider an OS whose kernel is
                  structured in the form of multiple processes communicating through messages.
                  Interrupts relevant to the process scheduling function can be modeled as messages
                  sent to a mailbox named scheduling. If the OS wishes to use different process
                  scheduling criteria during different periods of the day, it may implement several
                  schedulers as processes and pass ownership of the scheduling mailbox among
                  these processes. This way, the process scheduler that currently owns scheduling
                  can receive all scheduling-related messages. Functionalities of OS servers can be
                  similarly transferred. For example, all print requests can be directed to a laser
                  printer instead of a dot matrix printer by simply changing the ownership of a
                  print mailbox.
                     Although a process can also remain anonymous when sending a message
                  to a mailbox, the identity of the sender often has to be known. For example, a
                  server may be programmed to return status information for each request. It can be
                  achieved by passing the sender's id along with the text of the message. The sender
                  of the message, on the other hand, might not know the identity of the server; then,
                  it would have to receive the server's reply through an asymmetric receive. As an
                  alternative, the compiler can implement the send call as a blocking call requiring
                  a reply containing the status information; so, return of status information would
                  be a kernel responsibility.
·
     Example 9.1  Use of Mailboxes
                  An airline reservation system consists of a centralized data base and a set
                  of booking processes; each process represents one booking agent. Figure 9.8
                  shows a pseudocode for the reservation server. It uses three mailboxes named
                  enquire, book, and cancel, and expects a booking process to send enquiry,
                  booking, and cancellation messages to these mailboxes, respectively. Values



                                                  Chapter 9                             Message  Passing  325
     repeat
        while receive  (book,       flags1,  msg_area1) returns a message
              while receive  (cancel,    flags2,  msg_area2) returns a message
              process the cancellation;
              process the booking;
        if receive  (enquire,       flags3,  msg_area3) returns a message then
              while receive  (cancel,    flags2,  msg_area2) returns a message
              process the cancellation;
              process the enquiry;
     forever
Figure  9.8   Airline reservation server using three mailboxes: enquire, book, and cancel.
of flags in the receive calls are chosen such that a receive call returns with an
error code if no message exists. For improved effectiveness, the server processes
all pending cancellation messages before processing a booking request or an
enquiry, and performs bookings before enquiries.
                                                                                            ·
9.4  HIGHER-LEVEL PROTOCOLS USING MESSAGE PASSING                                                         ·
In this section, we discuss three protocols that use the message passing paradigm
to provide diverse services. The simple mail transfer protocol (SMTP) delivers
electronic mail. The remote procedure call (RPC) is a programming language
facility for distributed computing; it is used to invoke a part of a program that
is located in a different computer. Parallel virtual machine (PVM) and message
passing interface (MPI) are message passing standards for parallel programming.
9.4.1 The Simple Mail Transfer Protocol (SMTP)
SMTP is used to deliver electronic mail to one or more users reliably and effi-
ciently. It uses asymmetric naming (see Section 9.1.1). A mail would be delivered
to a user's terminal if the user is currently active; otherwise, it would be deposited
in the user's mailbox. The SMTP protocol can deliver mail across a number of
interprocess communication environments (IPCEs), where an IPCE may cover a
part of a network, a complete network, or several networks. SMTP is an applica-
tions layer protocol. It uses the TCP as a transport protocol and IP as a routing
protocol. Details of these networking layers, and details of reliable delivery are,
however, beyond the scope of this chapter; they are discussed later in Chapter 16.
     SMTP consists of several simple commands. The relevant ones for our pur-
poses are as follows: The MAIL command indicates who is sending a mail.
It contains a reverse path in the network, which is an optional list of hosts and
the name of the sender mailbox. The RCPT command indicates who is to receive
the mail. It contains a forward path that is an optional list of hosts and a desti-
nation mailbox. One or more RCPT commands can follow a MAIL command.
The DATA command contains the actual data to be sent to its destinations. After
processing the DATA command, the sender host starts processing of the MAIL



326  Part 2  Process Management
             command to send the data to the destination(s). When a host accepts the data
             for relaying or for delivery to the destination mailbox, the protocol generates a
             timestamp that indicates when the data was delivered to the host and inserts it at
             the start of the data. When the data reaches the host containing the destination
             mailbox, a line containing the reverse path mentioned in the MAIL command
             is inserted at the start of the data. The protocol provides other commands to
             deliver a mail to the user's terminal, to both the user's terminal and the user's
             mailbox, and either to the user's terminal or the user's mailbox. SMTP does not
             provide a mailbox facility in the receiver, hence it is typically used with either the
             Internet Message Access Protocol (IMAP) or the Post Office Protocol (POP);
             these protocols allow users to save messages in mailboxes.
             9.4.2 Remote Procedure Calls
             Parts of a distributed program are executed in different computers. The remote
             procedure call (RPC) is a programming language feature that is used to invoke
             such parts. Its semantics resemble those of a conventional procedure call. Its
             typical syntax is
                                 call <proc_id> (<message>);
             where <proc_id> is the id of a remote procedure and <message> is a list of param-
             eters. The call results in sending <message> to remote procedure <proc_id>. The
             result of the call is modeled as the reply returned by procedure <proc_id>. RPC
             is implemented by using a blocking protocol. We can view the caller­callee rela-
             tionship as a client­server relationship. Thus, the remote procedure is the server
             and a process calling it is a client. We will call the computers where the client and
             the server processes operate as the client node and server node, respectively.
             Parameters may be passed by value or by reference. If the architecture of the
             server node is different from that of the client node, the RPC mechanism performs
             appropriate conversion of value parameters. For reference parameters, the caller
             must construct systemwide capabilities for the parameters (see Chapter 15). These
             capabilities would be transmitted to the remote procedure in the message. Type
             checks on parameters can be performed at compilation time if the caller and
             the callee are integrated during compilation; otherwise, type checks have to be
             performed dynamically when a remote procedure call is made.
             The schematic diagram of Figure 9.9 depicts the arrangement used to imple-
             ment a remote procedure call. The server procedure is the remote procedure that
             is to be invoked. The client process calls the client stub procedure, which exists
             in the same node. The client stub marshals the parameters--collects the parame-
             ters, converts them into a machine-independent format, and prepares a message
             containing this representation of parameters. It now calls the server stub, which
             exists in the node that contains the remote procedure. The server stub converts
             the parameters into a machine-specific form and invokes the remote procedure.
             Results of the procedure call are passed back to the client process through the
             server stub and the client stub. Details concerning naming of the remote procedure
             and reliability of the remote procedure call are discussed later in Chapter 16.



                                                                                 Chapter 9  Message  Passing  327
               Client          Client                    Server          Server
               process         stub                      stub    procedure
                       Client                                    Server
                        node                                     node
Figure  9.9  Overview of a remote procedure call (RPC).
   Two standards for remote procedure calls--SunRPC and OSF/DCE--have
emerged and are in use widely. Their use simplifies making of RPCs, and makes
programs using RPCs portable across computers and their operating systems.
These standards specify an external representation of data for passing parameters
and results between the client and the server, and an interface compiler that
handles the drudgery of marshaling of parameters.
   The remote method invocation (RMI) feature of Java is an implementation of
the remote procedure call that is integrated with the Java language. The remote
method to be invoked is a method of some object. Parameters that are local objects
are passed by value, while nonlocal objects are passed by reference. Integra-
tion with the Java language simplifies naming of the remote method and reliably
passing parameters and results between the client and the server.
9.4.3 Message Passing Standards for Parallel Programming
A parallel program consists of a set of tasks that can be performed in parallel.
Such programs can be executed on a heterogeneous collection of computers or
on a massively parallel processor (MPP). Parallel programs use message passing
libraries that enable parallel activities to communicate through messages. Parallel
virtual machine (PVM) and message passing interface (MPI) are the two standards
that are used in coding message passing libraries. Both standards provide the
following facilities:
·  Point-to-point communication between two processes, using both symmet-
   ric and asymmetric naming, and collective communication among pro-
   cesses, which includes an ability to broadcast a message to a collection of
   processes.
·  Barrier synchronization between a collection of processes wherein a process
   invoking the barrier synchronization function is blocked until all processes
   in that collection of processes have invoked the barrier synchronization
   function.
·  Global operations for scattering disjoint portions of data in a message to
   different processes, gathering data from different processes, and performing
   global reduction operations on the received data.



328  Part 2  Process Management
                  In the PVM standard, a collection of heterogeneous networked computers
             operates as a parallel virtual machine, which is a single large parallel computer.
             The individual systems can be workstations, multiprocessors, or vector supercom-
             puters. Hence message passing faces the issue of heterogeneous representation of
             data in different computers forming the parallel virtual machine. After a message
             is received, a sequence of calls can be made to library routines that unpack and
             convert the data to a suitable form for consumption by the receiving process.
             PVM also provides signals that can be used to notify tasks of specific events.
                  MPI is a standard for a massively parallel processor. It provides a nonblock-
             ing send, which is implemented as follows: The message to be sent, which is some
             data, is copied into a buffer, and the process issuing the send is permitted to
             continue its operation. However, the process must not reuse the buffer before the
             previous send on the buffer has been completed. To facilitate it, a request han-
             dle is associated with every nonblocking send, and library calls are provided for
             checking the completion of a send operation by testing its request handle and
             for blocking until a specific send operation, or one of many send operations, is
             completed.
             9.5    CASE STUDIES IN MESSAGE PASSING                                                 ·
             9.5.1 Message Passing in Unix
             Unix supports three interprocess communication facilities called pipes, message
             queues, and sockets. A pipe is a data transfer facility, while message queues and
             sockets are used for message passing. These facilities have one common feature--
             processes can communicate without knowing each other's identities. The three
             facilities are different in scope. Unnamed pipes can be used only by processes that
             belong to the same process tree, while named pipes can be used by other processes
             as well. Message queues can be used only by processes existing within the "Unix
             system domain," which is the domain of Unix operating on one computer system.
             Sockets can be used by processes within the Unix system domain and within
             certain Internet domains. Figure 9.10 illustrates the concepts of pipes, message
             queues, and sockets.
             Pipes  A pipe is a first-in, first-out (FIFO) mechanism for data transfer between
             processes called reader processes and writer processes. A pipe is implemented in
             the file system in many versions of Unix; however, it differs from a file in one
             important respect--the data put into a pipe can be read only once. It is removed
             from the pipe when it is read by a process. Unix provides two kinds of pipes,
             called named and unnamed pipes. Both kinds of pipes are created through the
             system call pipe. Their semantics are identical except for the following differences:
             A named pipe has an entry in a directory and can thus be used by any process,
             subject to file permissions, through the system call open. It is retained in the
             system until it is removed by an unlink system call. An unnamed pipe does not
             have an entry in a directory; it can be used only by its creator and its descendants



                                                                                Chapter 9        Message  Passing  329
Writer process(es)        Sender process(es)
      write                                           Client                            Server
      offset              Message                                     Messages
Pipe                      queue                                       ···
      read                                                    Socket            Socket
Data  offset                            Message
Reader process(es)        Receiver process(es)
(a)                       (b)                         (c)
Figure 9.10 Interprocess  communication in Unix: (a)  pipe;   (b) message queue; (c)    socket.
in the process tree. The kernel deletes an unnamed pipe when readers or writers
no longer exist for it.
A pipe is implemented like a file, except for two differences (see Section 13.14.1
for a discussion of file implementation in Unix). The size of a pipe is limited so that
data in a pipe is located in the direct blocks of the inode. The kernel treats a pipe
as a queue by maintaining two offsets--one offset is used for writing data into the
pipe and the other for reading data from the pipe [see Figure 9.10(a)]. The read
and write offsets are maintained in the inode instead of in the file structure. This
arrangement forbids a process from changing the offset of a pipe through any
means other than reading or writing of data. When data is written, it is entered
into the pipe by using the write offset, and the write offset is incremented by the
number of bytes written. Data written by multiple writers gets mixed up if their
writes are interleaved. If a pipe is full, a process wishing to write data into it would
be put to sleep. A read operation is performed by using the read offset, and the
read offset is incremented by the number of bytes read. A process reading data
from a pipe would be put to sleep if the pipe is empty.
Message Queues      A message queue in Unix is analogous to a mailbox. It is
created and owned by one process. Other processes can send or receive messages
to or from a queue in accordance with access permissions specified by the creator
of the message queue [see Figure 9.10(b)]. These permissions are specified by
using the same conventions as file permissions in Unix (see Section 15.6.3). The
size of a message queue, in terms of the number of bytes that it can buffer, is
specified at the time of its creation.
A message queue is created by a system call msgget (key, flag) where key
specifies the name of the message queue and flag indicates some options. The
kernel maintains an array of message queues and their keys. The position of a
message queue in this array is used as the message queue id; it is returned by
the msgget call, and the process issuing the call uses it for sending or receiving
messages. The naming issue is tackled as follows: If a process makes a msgget
call with a key that matches the name of an existing message queue, the kernel
simply returns its message queue id. This way, a message queue can be used by
any process in the system. If the key in a msgget call does not match the name of



330  Part 2  Process Management
                  an existing message queue, the kernel creates a new message queue, sets the key as
                  its name, and returns its message queue id. The process making the call becomes
                  the owner of the message queue.
                  Each message consists of a message type, in the form of an integer, and a
                  message text. The kernel copies each message into a buffer and builds a message
                  header for it indicating the size of the message, its type, and a pointer to the
                  memory area where the message text is stored. It also maintains a list of mes-
                  sage headers for each message queue to represent messages that were sent to the
                  message queue but have not yet been received.
                  Messages are sent and received by using following system calls:
                                 msgsnd (msgqid, msg_struct_ ptr, count, flag)
                                 msgrcv (msgqid, msg_struct_ ptr, maxcount, type, flag)
                  The count and flag parameters of a msgsnd call specify the number of bytes in
                  a message and the actions to be taken if sufficient space is not available in the
                  message queue, e.g., whether to block the sender, or return with an error code.
                  msg_struct_ ptr is the address of a structure that contains the type of a message,
                  which is an integer, and the text of the message; maxcount is the maximum length
                  of the message; and type indicates the type of the message to be received.
                  When a process makes a msgrcv call, the type parameter, which is an integer,
                  indicates the type of message it wishes to receive. When the type parameter has a
                  positive value, the call returns the first message in the queue with a matching type.
                  If the type value is negative, it returns the lowest numbered message whose type
                  is smaller than the absolute value of the type. If the type value is zero, it returns
                  with the first message in the message queue, irrespective of its type. The process
                  becomes blocked if the message queue does not contain any message that can be
                  delivered to it.
                  When a process makes a msgsnd call, it becomes blocked if the message queue
                  does not contain sufficient free space to accommodate the message. The kernel
                  activates it when some process receives a message from the message queue, and
                  the process repeats the check to find whether its message can be accommodated
                  in the message queue. If the check fails, the process becomes blocked once again.
                  When it eventually inserts its message into the message queue, the kernel activates
                  all processes blocked on a receive on the message queue. When scheduled, each
                  of these processes checks whether a message of the type desired by it is available
                  in the message queue. If the check fails, it becomes blocked once again.
                  Example 9.2 shows how these features can be used to code the reservation
                  server of Example 9.1.
·
     Example 9.3  Unix Message Queues
                  Figure 9.11 shows the reservation server coded using the system calls of
                  Unix 5.4. The cancellation, booking, and enquiry messages are assigned the
                  types 1, 2, and 3, respectively. The msgrcv call with type = -4 and flag =
                  "no wait" returns a cancellation message, if one is present. If no cancellation



                                                                          Chapter 9       Message  Passing  331
reservation_server()
{
         msgqid = msgget  (reservation_data,        flags);
         ...
         repeat
               msgrcv   (msgqid,  &msg_struct,      200,     -4,   "no    wait");
               if  ...    /* a message exists */
               then  ...          /* process it */
         while(true);
}
Figure   9.11    A reservation server in Unix 5.4.
messages are present, it returns a bookings message if present, or an enquiry
message. This arrangement results in processing of cancellations before book-
ings, and bookings before enquiries, as desired. It also obviates the need for
the three mailboxes used in Figure 9.8.
                                                                                          ·
Sockets  A socket is simply one end of a communication path. Sockets can be
used for interprocess communication within the Unix system domain and in the
Internet domain; we limit this discussion to the Unix system domain. A com-
munication path between a client and the server is set up as follows: The client
and server processes create a socket each. These two sockets are then connected
together to set up a communication path for sending and receiving messages [see
Figure 9.10(c)]. The server can set up communication paths with many clients
simultaneously.
The naming issue is tackled as follows: The server binds its socket to an
address that is valid in the domain in which the socket will be used. The address
is now widely advertised in the domain. A client process uses the address to
perform a connect between its socket and that of the server. This method avoids
the use of process ids in communication; it is an instance of indirect naming (see
Section 9.1.1).
A server creates a socket s using the system call
                        s = socket (domain, type, protocol)
where type and protocol are irrelevant in the Unix system domain. The socket call
returns a socket identifier to the process. The server process now makes a call bind
(s, addr, . . . ), where s is the socket identifier returned by the socket call and addr
is the address for the socket. This call binds the socket to the address addr; addr
now becomes the `name' of the socket, which is widely advertised in the domain
for use by clients. The server performs the system call listen (s, . . . ) to indicate
that it is interested in considering some connect calls to its socket s.
A client creates a socket by means of a socket call, e.g., cs = socket (. . .), and
attempts to connect it to a server's socket using the system call
               connect (cs, server_socket_addr, server_socket_addrlen)



332  Part 2  Process Management
             The server is activated when a client tries to connect to its socket. It now makes
             the call new_soc = accept (s, client_addr, client_addrlen). The kernel creates a
             new socket, connects it to the socket mentioned in a client's connect call, and
             returns the id of this new socket. The server uses this socket to implement the
             client­server communication. The socket mentioned by the server in its listen
             call is used merely to set up connections. Typically, after the connect call the
             server forks a new process to handle the new connection. This method leaves
             the original socket created by the server process free to accept more connections
             through listen and connect calls. Communication between a client and a server
             is implemented through read and write or send and receive calls. A send call has
             the format
                                 count = send (s, message, message_length, flags)
             It returns the count of bytes actually sent. A socket connection is closed by using
             the call close (s) or shutdown (s, mode).
             9.5.2 Message Passing in Windows
             Windows provides several facilities for secure message passing within a host and
             within a Windows domain, which consists of a group of hosts. A named pipe
             is used for reliable bidirectional byte or message mode communication between
             a server and its clients. It is implemented through the file system interface and
             supports both synchronous and asynchronous message passing. The name of a
             pipe follows the Windows universal naming convention (UNC), which ensures
             unique names within a Windows network. The first createnamedpipe call for a
             named pipe is given by a server, which specifies its name, a security descriptor,
             and the number of simultaneous connections it is to support. The kernel notes
             this information and creates one connection to the pipe. The server now makes a
             connectnamedpipe call, which blocks it until a client connects to the pipe. A client
             connects to a pipe through a createfile or callnamedpipe function with the name
             of the pipe as a parameter. The call succeeds if the kind of access requested by it
             matches with the security descriptor of the pipe. Now the client can use readfile
             and writefile functions to access the pipe. The server can give additional create-
             namedpipe calls to create additional connections to the pipe. Windows provides
             a mailslot for unreliable unidirectional communication. It can be used for both
             point-to-point message passing and broadcasting of a short message across a
             Windows domain.
             Local Procedure Call (LPC)  The LPC facility performs message passing between
             processes located within the same host. It is used by components of the Windows
             OS for purposes such as invocation of the security authentication server, and
             by processes in user computations to communicate with environment subsystem
             processes. It is also invoked by the remote procedure call facility when the sender
             and receiver processes are located within the same host.
             LPC provides a choice of three methods of message passing that suit passing
             of small and large messages, and special messages for use by Win32 GUI. The



                                                                   Chapter 9            Message  Passing  333
first two types of LPC use port objects to implement message passing. Each port
object is like a mailbox. It contains a set of messages in a data structure called
a message queue. To set up communication with clients, a server creates a port,
publishes its name within the host, and awaits connection requests from clients.
It is activated when a client sends a connection request to the port and gives a
port handle to the client. The client uses this handle to send a message. The server
can communicate with many clients over the same port. For small messages, the
message queue contains the text of the message. As discussed in Section 9.1.2,
such messages are copied twice during message passing. When a process sends a
message, it is copied into the message queue of the port. From there, it is copied
into the address space of the receiver. To control the overhead of message passing,
the length of a message is limited to 256 bytes.
       The second method of message passing is used for large messages. The client
and server processes map a section object into their address spaces. When the
client wishes to send a message, it writes the text of the message in the section
object and sends a short message containing its address and size to the port. On
receiving this message, the server views the message text in the section object.
This way, the message is copied only once.
       The third method of LPC is called quick LPC. It uses a section object to pass
messages and an event pair object to perform synchronization between client and
server processes. The server creates an event pair object for each client, which
consists of two event objects. It also creates a thread for every client, which is
devoted exclusively for handling requests made by the client. Message passing
takes place as follows: The client process deposits a message in the section object,
signals the event object on which the server thread is waiting and itself waits
on the other event object of the pair. The server thread processes the message,
signals the event object on which the client is waiting, and itself waits on the other
event object. To facilitate message passing, the kernel provides a function that
atomically signals one event object of the pair and issues a wait on the other event
object.
Sockets and Remote Procedure Calls  Windows socket (Winsock) was originally
modeled on the Unix BSD socket but later included several extensions. Its fea-
tures and implementation are analogous to those of Unix sockets described in
Section 9.5. Winsock is integrated with Windows message passing. Hence a pro-
gram can perform an asynchronous socket operation and receive a notification
of completion of the operation through a Windows callback message.
       The remote procedure call (RPC) facility of Windows is compatible with
the OSF/DCE standard. It is implemented by using the LPC if the procedure
being invoked exists on the same host as its client; otherwise, it is implemented
along the lines discussed in Section 9.4.2. An asynchronous RPC is also sup-
ported, where the remote procedure operates concurrently with its client and
at its completion the client is notified in the manner specified in the call--
through an event synchronization object, through an asynchronous procedure
call,  through  an  I/O  port,  or  through  status  information,  which  the  client
can poll.



334       Part 2       Process Management
9.6     SUMMARY                                                                                                                       ·
The message passing paradigm realizes exchange                         receive call; the kernel considers messages sent by
of information among processes without using                           all processes to it for delivery. In indirect naming,
shared    memory.      This  feature       makes        it  useful     sender and receiver processes mention the name
in diverse situations such as in communication                         of a mailbox, rather than names of receiver and
between OS functionalities in a microkernel-based                      sender processes, respectively. It permits the same
OS, in client­server computing, in higher-level pro-                   sender and destination processes to engage in mul-
tocols for communication, and in communication                         tiple independent conversations through different
between   tasks    in  a     parallel  or    distributed        pro-   mailboxes. A mailbox contains a set of buffers
gram. In this chapter, we studied message passing                      in which messages can be stored pending their
facilities in programming languages and operating                      delivery. When mailboxes are not used, the ker-
systems.                                                               nel employs its own buffers to store undelivered
     The key issues in message passing are nam-                        messages.
ing of the sender and receiver processes in the send                   Message passing is employed in higher-level
and receive calls, and delivery of messages. In sym-                   protocols such as the simple mail transfer protocol
metric naming, the sender and receiver processes                       (SMTP), the remote procedure call (RPC), and the
name each other in send and receive calls. It permits                  parallel virtual machine (PVM) and message pass-
a process to engage in multiple independent con-                       ing interface (MPI) standards for parallel program-
versations simultaneously. In asymmetric naming,                       ming. Operating systems provide many message
the receiver process does not name a sender in its                     passing facilities for use in diverse situations.
TEST    YOUR CONCEPTS                                                                                                                 ·
9.1     Classify each of the following statements as true                         of the process to which the message will be
        or false:                                                                 delivered.
        a. When a process sends a message by using a                   9.2  Select the appropriate alternative in each of the
          blocking send call, the kernel has to copy the                    following questions:
          message into a buffer area.                                       a. If an OS has n processes and uses blocking
        b. When    a   nonblocking        send  call  is    used,  a              send calls and asymmetric receive calls,
          message has to be copied two times before                               i. The OS may require up to n - 1 buffers for
          the      receiver  process      can   be    allowed      to                  each of the n processes at any time.
          examine it.                                                             ii.  The  OS  may  require  upto  n  ×  n  buffers  at
        c. In  symmetric     naming,      a    process    that    has                  any time.                    2     2
          become       blocked  on     a  receive   call    will   be             iii. The OS may require upto n buffers at any
          activated whenever any process sends it a                                    time.
          message.                                                                iv. None of (i)­(iii).
        d. When indirect naming is used, a process send-                    b. Answer question 9.2(a) if processes use block-
          ing a message need not know the identity                                ing send calls and symmetric receive calls.
EXERCISES                                                                                                                             ·
9.1 In Figure 9.6, a process may be blocked because                         an ECB. Explain how these conditions should
        of lack of memory needed to create an IMCB or                       be handled.



                                                                       Chapter 9     Message Passing                335
9.2  Modify the scheme of Figure 9.6 to implement           9.5  It is proposed to introduce a time-out facility in
     message passing with asymmetric naming and                  message passing whereby a process performing
     blocking sends.                                             a receive specifies the amount of time it is pre-
9.3  The reservation system of Example 9.1 uses flags            pared to wait for a message. If this period elapses,
     in a receive call to check for presence of pend-            a time-out occurs and the process is activated.
     ing messages. A hypothetical mailbox facility               Give a design to implement this facility using
     does not support flags. Hence a process uses                the event handling mechanism.
     the following approach to obtain an equivalent         9.6  Processes in an OS use asymmetric and asyn-
     effect: When a process wishes to check whether              chronous message passing. The kernel reserves
     messages exist in a mailbox, it sends a special             a limited amount of memory for use as mes-
     message with the text "testing for messages" to             sage buffers and does not use disk space for this
     the mailbox, and then performs a receive from               purpose. Analyze this system for deadlocks (see
     the mailbox. If its own special message is deliv-           Chapter 8). How should the kernel detect such
     ered to it, it concludes that there are no other            deadlocks?
     messages in the mailbox. Rewrite the reserva-          9.7  Give a design to implement the asynchronous
     tion system using this approach. (Hint: Beware              send  of       the  message  passing  interface  (MPI)
     of outdated special messages!)                              standard described in Section 9.4.3.
9.4  Modify the scheme of Figure 9.6 to implement
     Unix message queues.
BIBLIOGRAPHY                                                                                                           ·
Interprocess    communication  in  the  RC4000  system      4.   Brinch Hansen, P. (1970): "The nucleus of a
is described in Brinch Hansen (1970). Accetta et al.             multiprogramming system," Communications of
(1986) discusses the scheme used in Mach. Bach (1986),           the ACM, 13 (4), 238­241, 250.
McKusick et al. (1996), Vahalia (1996), and Stevens         5.   Geist, G., J. A. Kohl, and P. M. Papadopoulos
and Rago (2005) discusses message passing in Unix.               (1996): "PVM and MPI: a comparison of
Bovet and Cesati (2005) discusses message passing in             features," Calculateurs Paralleles, 8 (2).
Linux, while Russinovich and Solomon (2005) discusses       6.   McKusick, M. K., K. Bostic, M. J. Karels, and
message passing in Windows.                                      J. S. Quarterman (1996): The Design and
    Geist   et  al.  (1996)  describes  and  compares  the       Implementation of the 4.4 BSD Operating System,
PVM and MPI message passing standards for parallel               Addison Wesley, Reading, Mass.
programming.                                                7.   Russinovich, M. E., and D. A. Solomon (2005):
1.  Accetta, M., R. Baron, W. Bolosky, D. B. Golub,              Microsoft Windows Internals, 4th ed., Microsoft
    R. Rashid, A. Tevanian, and M. Young (1986):                 Press, Redmond, Wash.
    "Mach: A new kernel foundation for Unix                 8.   Stevens, W. R., and S. A. Rago (2005): Advanced
    development," Proceedings of the Summer 1986                 Programming in the Unix Environment, 2nd ed.,
    USENIX Conference, June 1986, 93­112.                        Addison Wesley Professional, Reading, Mass.
2.  Bach, M. J. (1986): The Design of the Unix              9.   Tanenbaum, A. S. (2001): Modern Operating
    Operating System, Prentice Hall, Englewood                   Systems, 2nd ed., Prentice Hall, Englewood
    Cliffs, N. J.                                                Cliffs, N. J.
3.  Bovet, D. P., and M. Cesati (2005): Understanding       10.  Vahalia, U. (1996): Unix Internals--The New
    the Linux Kernel, 3rd ed., O'Reilly, Sebastopol,             frontiers, Prentice Hall, Englewood Cliffs, N. J.
    Calif.
