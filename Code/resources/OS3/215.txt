Summary
     A thread is a flow of control within a process. A multithreaded process contains
     several different flows of control within the same address space. The benefits of
     multithreading include increased responsiveness to the user, resource sharing
     within the process, economy, and scalability factors, such as more efficient use
     of multiple processing cores.
          User-level threads are threads that are visible to the programmer and are
     unknown to the kernel. The operating-system kernel supports and manages
     kernel-level threads. In general, user-level threads are faster to create and
     manage than are kernel threads, because no intervention from the kernel is
     required.
          Three different types of models relate user and kernel threads. The many-
     to-one model maps many user threads to a single kernel thread. The one-to-one
     model maps each user thread to a corresponding kernel thread. The many-to-
     many model multiplexes many user threads to a smaller or equal number of
     kernel threads.
          Most modern operating systems provide kernel support for threads. These
     include Windows, Mac OS X, Linux, and Solaris.
          Thread libraries provide the application programmer with an API for
     creating and managing threads. Three primary thread libraries are in common
     use: POSIX Pthreads, Windows threads, and Java threads.
          In addition to explicitly creating threads using the API provided by a
     library, we can use implicit threading, in which the creation and management
     of threading is transferred to compilers and run-time libraries. Strategies for
     implicit threading include thread pools, OpenMP, and Grand Central Dispatch.
          Multithreaded programs introduce many challenges for programmers,
     including  the   semantics  of  the  fork()  and  exec()  system  calls.  Other
     issues include signal handling, thread cancellation, thread-local storage, and
     scheduler activations.
Practice  Exercises
     4.1  Provide two programming examples in which multithreading provides
          better performance than a single-threaded solution.
     4.2  What are two differences between user-level threads and kernel-level
          threads? Under what circumstances is one type better than the other?
     4.3  Describe the actions taken by a kernel to context-switch between kernel-
          level threads.
     4.4  What resources are used when a thread is created? How do they differ
          from those used when a process is created?



192  Chapter 4  Threads
     4.5   Assume that an operating system maps user-level threads to the kernel
           using the many-to-many model and that the mapping is done through
           LWPs. Furthermore, the system allows developers to create real-time
           threads for use in real-time systems. Is it necessary to bind a real-time
           thread to an LWP? Explain.
Exercises
     4.6   Provide two programming examples in which multithreading does not
           provide better performance than a single-threaded solution.
     4.7   Under what circumstances does a multithreaded solution using multi-
           ple kernel threads provide better performance than a single-threaded
           solution on a single-processor system?
     4.8   Which of the following components of program state are shared across
           threads in a multithreaded process?
           a.   Register values
           b.   Heap memory
           c.   Global variables
           d.   Stack memory
     4.9   Can a multithreaded solution using multiple user-level threads achieve
           better  performance     on  a  multiprocessor  system  than  on   a  single-
           processor system? Explain.
     4.10  In Chapter 3, we discussed Google's Chrome browser and its practice
           of opening each new website in a separate process. Would the same
           benefits have been achieved if instead Chrome had been designed to
           open each new website in a separate thread? Explain.
     4.11  Is it possible to have concurrency but not parallelism? Explain.
     4.12  Using Amdahl's Law, calculate the speedup gain of an application that
           has a 60 percent parallel component for (a) two processing cores and (b)
           four processing cores.
     4.13  Determine if the following problems exhibit task or data parallelism:
           ·    The multithreaded statistical program described in Exercise 4.21
           ·    The multithreaded Sudoku validator described in Project 1 in this
                chapter
           ·    The multithreaded sorting program described in Project 2 in this
                chapter
           ·    The multithreaded web server described in Section 4.1
     4.14  A system with two dual-core processors has four processors available
           for scheduling. A CPU-intensive application is running on this system.
           All input is performed at program start-up, when a single file must
           be opened. Similarly, all output is performed just before the program



                                                                     Exercises       193
      terminates,   when    the  program        results  must  be   written   to  a  single
      file. Between startup and termination, the program is entirely CPU-
      bound. Your task is to improve the performance of this application
      by multithreading it. The application runs on a system that uses the
      one-to-one threading model (each user thread maps to a kernel thread).
      ·   How many threads will you create to perform the input and output?
          Explain.
      ·   How many threads will you create for the CPU-intensive portion of
          the application? Explain.
4.15  Consider the following code segment:
                pid t      pid;
                pid     =   fork();
                if   (pid   ==   0)  {  /*      child    process     */
                    fork();
                    thread create(           .  .  .);
                }
                fork();
      a.  How many unique processes are created?
      b.  How many unique threads are created?
4.16  As  described     in  Section  4.7.2,  Linux       does  not  distinguish   between
      processes and threads. Instead, Linux treats both in the same way,
      allowing a task to be more akin to a process or a thread depending on the
      set of flags passed to the clone() system call. However, other operating
      systems,    such  as  Windows,    treat      processes   and   threads  differently.
      Typically, such systems use a notation in which the data structure for
      a process contains pointers to the separate threads belonging to the
      process. Contrast these two approaches for modeling processes and
      threads within the kernel.
4.17  The program shown in Figure 4.16 uses the Pthreads API. What would
      be the output from the program at LINE             C and LINE  P?
4.18  Consider a multicore system and a multithreaded program written
      using the many-to-many threading model. Let the number of user-level
      threads in the program be greater than the number of processing cores
      in the system. Discuss the performance implications of the following
      scenarios.
      a.  The number of kernel threads allocated to the program is less than
          the number of processing cores.
      b.  The number of kernel threads allocated to the program is equal to
          the number of processing cores.
      c.  The number of kernel threads allocated to the program is greater
          than the number of processing cores but less than the number of
          user-level threads.



194  Chapter 4    Threads
           #include   <pthread.h>
           #include   <stdio.h>
           #include <types.h>
           int value = 0;
           void   *runner(void         *param);      /*  the  thread     */
           int   main(int    argc,      char  *argv[])
           {
           pid t pid;
           pthread t tid;
           pthread attr      t  attr;
              pid  =  fork();
              if   (pid  ==     0)  {  /*  child     process   */
                  pthread attr init(&attr);
                  pthread create(&tid,&attr,runner,NULL);
                  pthread join(tid,NULL);
                  printf("CHILD:        value     =     %d",value);   /*     LINE  C     */
              }
              else if (pid > 0) { /* parent process */
                  wait(NULL);
                  printf("PARENT:          value     =   %d",value);     /*  LINE     P  */
              }
           }
           void   *runner(void         *param)    {
              value   =  5;
              pthread exit(0);
           }
                           Figure 4.16     C program for Exercise 4.17.
     4.19  Pthreads   provides      an  API   for    managing    thread      cancellation.   The
           pthread setcancelstate() function is used to set the cancellation
           state. Its prototype appears as follows:
                 pthread setcancelstate(int              state,    int   *oldstate)
           The two possible values for the state are PTHREAD CANCEL ENABLE and
           PTHREAD CANCEL DISABLE.
                 Using the code segment shown in Figure 4.17, provide examples of
           two operations that would be suitable to perform between the calls to
           disable and enable thread cancellation.



                                                 Programming Problems              195
int oldstate;
pthread setcancelstate(PTHREAD CANCEL DISABLE, &oldstate);
/*    What  operations      would  be    performed  here?     */
pthread setcancelstate(PTHREAD CANCEL               ENABLE,   &oldstate);
                   Figure 4.17  C program for Exercise 4.19.
Programming Problems
4.20  Modify programming problem Exercise 3.20 from Chapter 3, which asks
      you to design a pid manager. This modification will consist of writing
      a multithreaded program that tests your solution to Exercise 3.20. You
      will create a number of threads--for example, 100--and each thread will
      request a pid, sleep for a random period of time, and then release the pid.
      (Sleeping for a random period of time approximates the typical pid usage
      in which a pid is assigned to a new process, the process executes and
      then terminates, and the pid is released on the process's termination.) On
      UNIX and Linux systems, sleeping is accomplished through the sleep()
      function, which is passed an integer value representing the number of
      seconds to sleep. This problem will be modified in Chapter 5.
4.21  Write a multithreaded program that calculates various statistical values
      for a list of numbers. This program will be passed a series of numbers on
      the command line and will then create three separate worker threads.
      One thread will determine the average of the numbers, the second
      will determine the maximum value, and the third will determine the
      minimum value. For example, suppose your program is passed the
      integers
                   90 81 78 95 79 72 85
      The program will report
            The    average  value        is  82
            The    minimum  value        is  72
            The    maximum  value        is  95
      The variables representing the average, minimum, and maximum values
      will be stored globally. The worker threads will set these values, and the
      parent thread will output the values once the workers have exited. (We
      could obviously expand this program by creating additional threads
      that determine other statistical values, such as median and standard
      deviation.)
4.22  An interesting way of calculating  is to use a technique known as Monte
      Carlo, which involves randomization. This technique works as follows:
      Suppose you have a circle inscribed within a square, as shown in Figure



196  Chapter 4    Threads
                     (-1, 1)                                    (1, 1)
                                               (0, 0)
                     (-1, -1)                                   (1, -1)
                     Figure 4.18  Monte Carlo technique for calculating pi.
           4.18. (Assume that the radius of this circle is 1.) First, generate a series of
           random points as simple (x, y) coordinates. These points must fall within
           the Cartesian coordinates that bound the square. Of the total number of
           random points that are generated, some will occur within the circle.
           Next, estimate  by performing the following calculation:
                   = 4× (number of points in circle) / (total number of points)
           Write a multithreaded version of this algorithm that creates a separate
           thread to generate a number of random points. The thread will count
           the number of points that occur within the circle and store that result
           in a global variable. When this thread has exited, the parent thread will
           calculate and output the estimated value of . It is worth experimenting
           with the number of random points generated. As a general rule, the
           greater the number of points, the closer the approximation to .
           In the source-code download for this text, we provide a sample program
           that provides a technique for generating random numbers, as well as
           determining if the random (x, y) point occurs within the circle.
           Readers interested in the details of the Monte Carlo method for esti-
           mating  should consult the bibliography at the end of this chapter. In
           Chapter 5, we modify this exercise using relevant material from that
           chapter.
     4.23  Repeat Exercise 4.22, but instead of using a separate thread to generate
           random points, use OpenMP to parallelize the generation of points. Be
           careful not to place the calculcation of  in the parallel region, since you
           want to calculcate  only once.
     4.24  Write  a  multithreaded  program    that    outputs  prime        numbers.  This
           program should work as follows: The user will run the program and
           will enter a number on the command line. The program will then create
           a separate thread that outputs all the prime numbers less than or equal
           to the number entered by the user.
     4.25  Modify the socket-based date server (Figure 3.21) in Chapter 3 so that
           the server services each client request in a separate thread.



                                                             Programming Projects       197
4.26  The  Fibonacci  sequence  is      the  series  of      numbers  0, 1, 1, 2, 3, 5, 8, ....
      Formally, it can be expressed as:
                    f ib0  =0
                    f ib1  =1
                    f ibn  =  f i bn-1  +  f i bn-2
      Write a multithreaded program that generates the Fibonacci sequence.
      This program should work as follows: On the command line, the user
      will enter the number of Fibonacci numbers that the program is to
      generate.  The  program   will       then      create  a  separate  thread  that  will
      generate the Fibonacci numbers, placing the sequence in data that can
      be shared by the threads (an array is probably the most convenient
      data structure). When the thread finishes execution, the parent thread
      will output the sequence generated by the child thread. Because the
      parent thread cannot begin outputting the Fibonacci sequence until the
      child thread finishes, the parent thread will have to wait for the child
      thread to finish. Use the techniques described in Section 4.4 to meet this
      requirement.
4.27  Exercise 3.25 in Chapter 3 involves designing an echo server using the
      Java threading API. This server is single-threaded, meaning that the
      server cannot respond to concurrent echo clients until the current client
      exits. Modify the solution to Exercise 3.25 so that the echo server services
      each client in a separate request.
Programming Projects
Project 1 --Sudoku Solution Validator
A Sudoku puzzle uses a 9 × 9 grid in which each column and row, as well as
each of the nine 3 × 3 subgrids, must contain all of the digits 1 · · · 9. Figure
4.19 presents an example of a valid Sudoku puzzle. This project consists of
designing a multithreaded application that determines whether the solution to
a Sudoku puzzle is valid.
      There are several different ways of multithreading this application. One
suggested strategy is to create threads that check the following criteria:
·     A thread to check that each column contains the digits 1 through 9
·     A thread to check that each row contains the digits 1 through 9
·     Nine threads to check that each of the 3 × 3 subgrids contains the digits 1
      through 9
      This would result in a total of eleven separate threads for validating a
Sudoku puzzle. However, you are welcome to create even more threads for
this project. For example, rather than creating one thread that checks all nine



198  Chapter 4     Threads
                               6       2  4    5  3  9   1   8     7
                               5       1  9    7  2  8   6   3     4
                               8       3  7    6  1  4   2   9     5
                               1       4  3    8  6  5   7   2     9
                               9       5  8    2  4  7   3   6     1
                               7       6  2    3  9  1   4   5     8
                               3       7  1    9  5  6   8   4     2
                               4       9  6    1  8  2   5   7     3
                               2       8  5    4  7  3   9   1     6
                   Figure 4.19            Solution to a 9 × 9 Sudoku puzzle.
     columns, you could create nine separate threads and have each of them check
     one column.
     Passing Parameters to Each Thread
     The parent thread will create the worker threads, passing each worker the
     location that it must check in the Sudoku grid. This step will require passing
     several parameters to each thread. The easiest approach is to create a data
     structure using a struct. For example, a structure to pass the row and column
     where a thread must begin validating would appear as follows:
                /* structure for          passing    data    to  threads      */
                typedef     struct
                {
                   int row;
                   int column;
                } parameters;
     Both Pthreads and Windows programs will create worker threads using a
     strategy similar to that shown below:
     parameters    *data            =  (parameters   *)  malloc(sizeof(parameters));
     data->row = 1;
     data->column           =  1;
     /*  Now       create      the     thread  passing   it  data     as  a   parameter  */
     The data pointer will be passed to either the pthread create() (Pthreads)
     function or the CreateThread() (Windows) function, which in turn will pass
     it as a parameter to the function that is to run as a separate thread.
     Returning Results to the Parent Thread
     Each worker thread is assigned the task of determining the validity of a
     particular region of the Sudoku puzzle. Once a worker has performed this



                                                                    Bibliographical    Notes         199
                                         Original List
                                7,  12,  19, 3, 18, 4, 2,  6,  15,  8
               Sorting                                                     Sorting
               Thread0                                                     Thread1
               7, 12, 19,  3,  18                                      4, 2, 6, 15, 8
                                         Merge Thread
                                2, 3, 4, 6, 7, 8, 12, 15, 18, 19
                                         Sorted List
                           Figure 4.20   Multithreaded sorting.
check, it must pass its results back to the parent. One good way to handle this
is to create an array of integer values that is visible to each thread. The ith
index in this array corresponds to the ith worker thread. If a worker sets its
corresponding value to 1, it is indicating that its region of the Sudoku puzzle
is valid. A value of 0 would indicate otherwise. When all worker threads have
completed, the parent thread checks each entry in the result array to determine
if the Sudoku puzzle is valid.
Project 2 --Multithreaded Sorting Application
Write a multithreaded sorting program that works as follows: A list of integers
is divided into two smaller lists of equal size. Two separate threads (which we
will term sorting threads) sort each sublist using a sorting algorithm of your
choice. The two sublists are then merged by a third thread--a merging thread
--which merges the two sublists into a single sorted list.
Because global data are shared cross all threads, perhaps the easiest way
to set up the data is to create a global array. Each sorting thread will work on
one half of this array. A second global array of the same size as the unsorted
integer array will also be established. The merging thread will then merge
the two sublists into this second array. Graphically, this program is structured
according to Figure 4.20.
This programming project will require passing parameters to each of the
sorting threads. In particular, it will be necessary to identify the starting index
from which each thread is to begin sorting. Refer to the instructions in Project
1 for details on passing parameters to a thread.
The parent thread will output the sorted array once all sorting threads have
exited.
Bibliographical Notes
Threads  have  had  a  long     evolution,  starting                   as  "cheap      concurrency"  in
programming languages and moving to "lightweight processes," with early
examples that included the Thoth system ([Cheriton et al. (1979)]) and the Pilot



200  Chapter 4  Threads
     system ([Redell et al. (1980)]). [Binding (1985)] described moving threads into
     the UNIX kernel. Mach ([Accetta et al. (1986)], [Tevanian et al. (1987)]), and V
     ([Cheriton (1988)]) made extensive use of threads, and eventually almost all
     major operating systems implemented them in some form or another.
     [Vahalia (1996)] covers threading in several versions of UNIX. [McDougall
     and Mauro (2007)] describes developments in threading the Solaris kernel.
     [Russinovich and Solomon (2009)] discuss threading in the Windows operating
     system family. [Mauerer (2008)] and [Love (2010)] explain how Linux handles
     threading, and [Singh (2007)] covers threads in Mac OS X.
     Information         on    Pthreads      programming  is   given   in   [Lewis    and  Berg
     (1998)]  and  [Butenhof       (1997)].  [Oaks   and  Wong    (1999)]   and  [Lewis    and
     Berg (2000)] discuss multithreading in Java. [Goetz et al. (2006)] present a
     detailed discussion of concurrent programming in Java. [Hart (2005)] describes
     multithreading using Windows. Details on using OpenMP can be found at
     http://openmp.org.
     An analysis of an optimal thread-pool size can be found in [Ling et al.
     (2000)]. Scheduler activations were first presented in [Anderson et al. (1991)],
     and [Williams (2002)] discusses scheduler activations in the NetBSD system.
     [Breshears (2009)] and [Pacheco (2011)] cover parallel programming in
     detail. [Hill and Marty (2008)] examine Amdahl's Law with respect to multicore
     systems. The Monte Carlo technique for estimating  is further discussed in
     http://math.fullerton.edu/mathews/n2003/montecarlopimod.html.
Bibliography
     [Accetta et al. (1986)]      M. Accetta, R. Baron, W. Bolosky, D. B. Golub, R. Rashid,
     A.  Tevanian,      and    M.  Young,    "Mach:  A    New  Kernel  Foundation     for  UNIX
     Development",       Proceedings     of  the  Summer  USENIX  Conference     (1986),   pages
     93­112.
     [Anderson et al. (1991)]      T. E. Anderson, B. N. Bershad, E. D. Lazowska, and
     H. M. Levy, "Scheduler Activations: Effective Kernel Support for the User-Level
     Management of Parallelism", Proceedings of the ACM Symposium on Operating
     Systems Principles (1991), pages 95­109.
     [Binding (1985)]    C. Binding, "Cheap Concurrency           in   C",  SIGPLAN   Notices,
     Volume 20, Number 9 (1985), pages 21­27.
     [Breshears (2009)]       C. Breshears, The Art of Concurrency, O'Reilly & Associates
     (2009).
     [Butenhof (1997)]        D.  Butenhof,  Programming  with  POSIX       Threads,  Addison-
     Wesley (1997).
     [Cheriton (1988)]        D. Cheriton, "The V Distributed System", Communications of
     the ACM, Volume 31, Number 3 (1988), pages 314­333.
     [Cheriton et al. (1979)]      D. R. Cheriton, M. A. Malcolm, L. S. Melen, and G. R.
     Sager, "Thoth, a Portable Real-Time Operating System", Communications of the
     ACM, Volume 22, Number 2 (1979), pages 105­115.



                                                                 Bibliography           201
[Goetz et al. (2006)]      B. Goetz, T. Peirls, J. Bloch, J. Bowbeer, D. Holmes, and
D. Lea, Java Concurrency in Practice, Addison-Wesley (2006).
[Hart (2005)]     J. M. Hart, Windows System Programming, Third Edition, Addison-
Wesley (2005).
[Hill and Marty (2008)]    M. Hill and M. Marty, "Amdahl's Law in the Multicore
Era", IEEE Computer, Volume 41, Number 7 (2008), pages 33­38.
[Lewis and Berg (1998)]    B. Lewis and D. Berg, Multithreaded Programming with
Pthreads, Sun Microsystems Press (1998).
[Lewis and Berg (2000)]    B. Lewis and D. Berg, Multithreaded Programming with
Java Technology, Sun Microsystems Press (2000).
[Ling et al. (2000)]       Y. Ling, T. Mullen, and X. Lin, "Analysis of Optimal Thread
Pool Size", Operating System Review, Volume 34, Number 2 (2000), pages 42­55.
[Love (2010)]     R. Love, Linux Kernel Development, Third Edition, Developer's
Library (2010).
[Mauerer (2008)]        W. Mauerer, Professional Linux Kernel Architecture, John Wiley
and Sons (2008).
[McDougall and Mauro (2007)]         R. McDougall and J. Mauro, Solaris Internals,
Second Edition, Prentice Hall (2007).
[Oaks and Wong (1999)]     S. Oaks and H. Wong, Java Threads, Second Edition,
O'Reilly & Associates (1999).
[Pacheco (2011)]        P. S. Pacheco, An Introduction to Parallel Programming, Morgan
Kaufmann (2011).
[Redell et al. (1980)]     D. D. Redell, Y. K. Dalal, T. R. Horsley, H. C. Lauer, W. C.
Lynch, P. R. McJones, H. G. Murray, and S. P. Purcell, "Pilot: An Operating System
for a Personal Computer", Communications of the ACM, Volume 23, Number 2
(1980), pages 81­92.
[Russinovich and Solomon (2009)]           M. E. Russinovich and D. A. Solomon, Win-
dows Internals: Including Windows Server 2008 and Windows Vista, Fifth Edition,
Microsoft Press (2009).
[Singh (2007)]        A. Singh, Mac OS X Internals: A Systems Approach, Addison-
Wesley (2007).
[Tevanian et al. (1987)]   A. Tevanian, Jr., R. F. Rashid, D. B. Golub, D. L. Black,
E. Cooper, and M. W. Young, "Mach Threads and the Unix Kernel: The Battle
for Control", Proceedings of the Summer USENIX Conference (1987).
[Vahalia (1996)]       U.  Vahalia,  Unix  Internals:  The  New  Frontiers,  Prentice  Hall
(1996).
[Williams (2002)]       N. Williams, "An Implementation of Scheduler Activations
on the NetBSD Operating System", 2002 USENIX Annual Technical Conference,
FREENIX Track (2002).



