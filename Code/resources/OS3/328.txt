Summary
     CPU scheduling is the task of selecting a waiting process from the ready queue
     and allocating the CPU to it. The CPU is allocated to the selected process by the
     dispatcher.
          First-come, first-served (FCFS) scheduling is the simplest scheduling algo-
     rithm, but it can cause short processes to wait for very long processes. Shortest-
     job-first (SJF) scheduling is provably optimal, providing the shortest average
     waiting time. Implementing SJF scheduling is difficult, however, because pre-
     dicting the length of the next CPU burst is difficult. The SJF algorithm is a special
     case of the general priority scheduling algorithm, which simply allocates the
     CPU to the highest-priority process. Both priority and SJF scheduling may suffer
     from starvation. Aging is a technique to prevent starvation.
          Round-robin (RR) scheduling is more appropriate for a time-shared (inter-
     active) system. RR scheduling allocates the CPU to the first process in the ready
     queue for q time units, where q is the time quantum. After q time units, if
     the process has not relinquished the CPU, it is preempted, and the process is
     put at the tail of the ready queue. The major problem is the selection of the
     time quantum. If the quantum is too large, RR scheduling degenerates to FCFS
     scheduling. If the quantum is too small, scheduling overhead in the form of
     context-switch time becomes excessive.



                                                             Practice Exercises              305
     The FCFS algorithm is nonpreemptive; the RR algorithm is preemptive. The
SJF and priority algorithms may be either preemptive or nonpreemptive.
     Multilevel queue algorithms allow different algorithms to be used for
different classes of processes. The most common model includes a foreground
interactive queue that uses RR scheduling and a background batch queue that
uses FCFS scheduling. Multilevel feedback queues allow processes to move
from one queue to another.
     Many contemporary computer systems support multiple processors and
allow each processor to schedule itself independently. Typically, each processor
maintains its own private queue of processes (or threads), all of which are
available to run. Additional issues related to multiprocessor scheduling include
processor affinity, load balancing, and multicore processing.
     A real-time computer system requires that results arrive within a deadline
period; results arriving after the deadline has passed are useless. Hard real-time
systems must guarantee that real-time tasks are serviced within their deadline
periods. Soft real-time systems are less restrictive, assigning real-time tasks
higher scheduling priority than other tasks.
     Real-time  scheduling     algorithms    include       rate-monotonic    and     earliest-
deadline-first  scheduling.    Rate-monotonic       scheduling       assigns    tasks    that
require the CPU more often a higher priority than tasks that require the
CPU less often. Earliest-deadline-first scheduling assigns priority according
to  upcoming    deadlines -- the    earlier  the  deadline,  the  higher        the  priority.
Proportional    share  scheduling   divides     up  processor    time     into  shares   and
assigning each process a number of shares, thus guaranteeing each process
a proportional share of CPU time. The POSIX Pthread API provides various
features for scheduling real-time threads as well.
     Operating systems supporting threads at the kernel level must schedule
threads -- not  processes -- for    execution.    This  is  the  case  with     Solaris  and
Windows. Both of these systems schedule threads using preemptive, priority-
based scheduling algorithms, including support for real-time threads. The
Linux process scheduler uses a priority-based algorithm with real-time support
as well. The scheduling algorithms for these three operating systems typically
favor interactive over CPU-bound processes.
     The wide variety of scheduling algorithms demands that we have methods
to select among algorithms. Analytic methods use mathematical analysis to
determine the performance of an algorithm. Simulation methods determine
performance     by  imitating  the  scheduling      algorithm    on    a  "representative"
sample of processes and computing the resulting performance. However,
simulation can at best provide an approximation of actual system performance.
The  only  reliable    technique  for  evaluating       a  scheduling     algorithm      is  to
implement the algorithm on an actual system and monitor its performance
in a "real-world" environment.
Practice Exercises
6.1  A CPU-scheduling algorithm determines an order for the execution
     of its scheduled processes. Given n processes to be scheduled on one
     processor, how many different schedules are possible? Give a formula
     in terms of n.



306  Chapter 6  CPU Scheduling
     6.2  Explain the difference between preemptive and nonpreemptive schedul-
          ing.
     6.3  Suppose that the following processes arrive for execution at the times
          indicated.  Each   process  will  run    for  the  amount  of  time  listed.  In
          answering the questions, use nonpreemptive scheduling, and base all
          decisions on the information you have at the time the decision must be
          made.
                             Process  Arrival Time           Burst Time
                             P1               0.0            8
                             P2               0.4            4
                             P3               1.0            1
          a.    What is the average turnaround time for these processes with the
                FCFS scheduling algorithm?
          b.    What is the average turnaround time for these processes with the
                SJF scheduling algorithm?
          c.    The SJF algorithm is supposed to improve performance, but notice
                that we chose to run process P1 at time 0 because we did not know
                that two shorter processes would arrive soon. Compute what the
                average turnaround time will be if the CPU is left idle for the first
                1 unit and then SJF scheduling is used. Remember that processes
                P1 and P2 are waiting during this idle time, so their waiting time
                may increase. This algorithm could be called future-knowledge
                scheduling.
     6.4  What advantage is there in having different time-quantum sizes at
          different levels of a multilevel queueing system?
     6.5  Many CPU-scheduling algorithms are parameterized. For example, the
          RR algorithm requires a parameter to indicate the time slice. Multilevel
          feedback queues require parameters to define the number of queues, the
          scheduling algorithm for each queue, the criteria used to move processes
          between queues, and so on.
                These algorithms are thus really sets of algorithms (for example, the
          set of RR algorithms for all time slices, and so on). One set of algorithms
          may include another (for example, the FCFS algorithm is the RR algorithm
          with an infinite time quantum). What (if any) relation holds between the
          following pairs of algorithm sets?
          a.    Priority and SJF
          b.    Multilevel feedback queues and FCFS
          c.    Priority and FCFS
          d.    RR and SJF
     6.6  Suppose that a scheduling algorithm (at the level of short-term CPU
          scheduling) favors those processes that have used the least processor



                                                                      Exercises         307
           time  in   the  recent  past.  Why  will  this  algorithm  favor  I/O-bound
           programs and yet not permanently starve CPU-bound programs?
6.7        Distinguish between PCS and SCS scheduling.
6.8        Assume that an operating system maps user-level threads to the kernel
           using the many-to-many model and that the mapping is done through
           the use of LWPs. Furthermore, the system allows program developers to
           create real-time threads. Is it necessary to bind a real-time thread to an
           LWP?
6.9        The traditional UNIX scheduler enforces an inverse relationship between
           priority numbers and priorities: the higher the number, the lower the
           priority. The scheduler recalculates process priorities once per second
           using the following function:
                 Priority = (recent CPU usage / 2) + base
           where base = 60 and recent CPU usage refers to a value indicating how
           often a process has used the CPU since priorities were last recalculated.
           Assume that recent CPU usage is 40 for process P1, 18 for process P2,
           and 10 for process P3. What will be the new priorities for these three
           processes when priorities are recalculated? Based on this information,
           does the traditional UNIX scheduler raise or lower the relative priority
           of a CPU-bound process?
Exercises
6.10       Why is it important for the scheduler to distinguish I/O-bound programs
           from CPU-bound programs?
6.11       Discuss how the following pairs of scheduling criteria conflict in certain
           settings.
           a.    CPU utilization and response time
           b.    Average turnaround time and maximum waiting time
           c.    I/O device utilization and CPU utilization
6.12       One technique for implementing lottery scheduling works by assigning
           processes lottery tickets, which are used for allocating CPU time. When-
           ever a scheduling decision has to be made, a lottery ticket is chosen
           at random, and the process holding that ticket gets the CPU. The BTV
           operating system implements lottery scheduling by holding a lottery
           50 times each second, with each lottery winner getting 20 milliseconds
           of CPU time (20 milliseconds × 50 = 1 second). Describe how the BTV
           scheduler can ensure that higher-priority threads receive more attention
           from the CPU than lower-priority threads.
6.13       In Chapter 5, we discussed possible race conditions on various kernel
           data structures. Most scheduling algorithms maintain a run queue,
           which lists processes eligible to run on a processor. On multicore systems,
           there are two general options: (1) each processing core has its own run



308  Chapter 6    CPU Scheduling
           queue, or (2) a single run queue is shared by all processing cores. What
           are the advantages and disadvantages of each of these approaches?
     6.14  Consider the exponential average formula used to predict the length of
           the next CPU burst. What are the implications of assigning the following
           values to the parameters used by the algorithm?
           a.      = 0 and 0 = 100 milliseconds
           b.      = 0.99 and 0 = 10 milliseconds
     6.15  A variation of the round-robin scheduler is the regressive round-robin
           scheduler. This scheduler assigns each process a time quantum and a
           priority. The initial value of a time quantum is 50 milliseconds. However,
           every time a process has been allocated the CPU and uses its entire time
           quantum (does not block for I/O), 10 milliseconds is added to its time
           quantum, and its priority level is boosted. (The time quantum for a
           process can be increased to a maximum of 100 milliseconds.) When a
           process blocks before using its entire time quantum, its time quantum is
           reduced by 5 milliseconds, but its priority remains the same. What type
           of process (CPU-bound or I/O-bound) does the regressive round-robin
           scheduler favor? Explain.
     6.16  Consider the following set of processes, with the length of the CPU burst
           given in milliseconds:
                                 Process      Burst Time       Priority
                                   P1           2                   2
                                   P2           1                   1
                                   P3           8                   4
                                   P4           4                   2
                                   P5           5                   3
           The processes are assumed to have arrived in the order P1, P2, P3, P4, P5,
           all at time 0.
           a.     Draw     four  Gantt  charts  that  illustrate    the  execution  of  these
                  processes using the following scheduling algorithms: FCFS, SJF,
                  nonpreemptive priority (a larger priority number implies a higher
                  priority), and RR (quantum = 2).
           b.     What is the turnaround time of          each    process  for  each    of  the
                  scheduling algorithms in part a?
           c.     What is the waiting time of each process for each of these schedul-
                  ing algorithms?
           d.     Which of the algorithms results in the minimum average waiting
                  time (over all processes)?
     6.17  The following processes are being scheduled using a preemptive, round-
           robin  scheduling     algorithm.     Each  process   is  assigned    a   numerical
           priority, with a higher number indicating a higher relative priority.
           In addition to the processes listed below, the system also has an idle



                                                             Exercises            309
      task (which consumes no CPU resources and is identified as Pidle ). This
      task has priority 0 and is scheduled whenever the system has no other
      available processes to run. The length of a time quantum is 10 units.
      If a process is preempted by a higher-priority process, the preempted
      process is placed at the end of the queue.
                    Thread    Priority  Burst       Arrival
                    P1        40             20       0
                    P2        30             25       25
                    P3        30             25       30
                    P4        35             15       60
                    P5              5        10     100
                    P6        10             10     105
      a.  Show the scheduling order of the processes using a Gantt chart.
      b.  What is the turnaround time for each process?
      c.  What is the waiting time for each process?
      d.  What is the CPU utilization rate?
6.18  The nice command is used to set the nice value of a process on Linux,
      as well as on other UNIX systems. Explain why some systems may allow
      any user to assign a process a nice value >= 0 yet allow only the root
      user to assign nice values < 0.
6.19  Which of the following scheduling algorithms could result in starvation?
      a.  First-come, first-served
      b.  Shortest job first
      c.  Round robin
      d.  Priority
6.20  Consider a variant of the RR scheduling algorithm in which the entries
      in the ready queue are pointers to the PCBs.
      a.  What would be the effect of putting two pointers to the same
          process in the ready queue?
      b.  What would be two major advantages and two disadvantages of
          this scheme?
      c.  How would you modify the basic RR algorithm to achieve the same
          effect without the duplicate pointers?
6.21  Consider a system running ten I/O-bound tasks and one CPU-bound
      task. Assume that the I/O-bound tasks issue an I/O operation once for
      every millisecond of CPU computing and that each I/O operation takes
      10 milliseconds to complete. Also assume that the context-switching
      overhead is 0.1 millisecond and that all processes are long-running tasks.
      Describe the CPU utilization for a round-robin scheduler when:



310  Chapter 6  CPU Scheduling
           a.   The time quantum is 1 millisecond
           b.   The time quantum is 10 milliseconds
     6.22  Consider a system implementing multilevel queue scheduling. What
           strategy can a computer user employ to maximize the amount of CPU
           time allocated to the user's process?
     6.23  Consider a preemptive priority scheduling algorithm based on dynami-
           cally changing priorities. Larger priority numbers imply higher priority.
           When a process is waiting for the CPU (in the ready queue, but not
           running), its priority changes at a rate . When it is running, its priority
           changes at a rate . All processes are given a priority of 0 when they
           enter the ready queue. The parameters  and  can be set to give many
           different scheduling algorithms.
           a.   What is the algorithm that results from       >    > 0?
           b.   What is the algorithm that results from       <    < 0?
     6.24  Explain the differences in how much the following scheduling algo-
           rithms discriminate in favor of short processes:
           a.   FCFS
           b.   RR
           c.   Multilevel feedback queues
     6.25  Using  the  Windows    scheduling      algorithm,  determine  the  numeric
           priority of each of the following threads.
           a.   A thread in the REALTIME PRIORITY CLASS with a relative priority
                of NORMAL
           b.   A thread in the ABOVE NORMAL PRIORITY CLASS with a relative
                priority of HIGHEST
           c.   A thread in the BELOW NORMAL PRIORITY CLASS with a relative
                priority of ABOVE NORMAL
     6.26  Assuming that no threads belong to the REALTIME PRIORITY CLASS and
           that none may be assigned a TIME CRITICAL priority, what combination
           of priority class and priority corresponds to the highest possible relative
           priority in Windows scheduling?
     6.27  Consider the scheduling algorithm in the Solaris operating system for
           time-sharing threads.
           a.   What is the time quantum (in milliseconds) for a thread with
                priority 15? With priority 40?
           b.   Assume that a thread with priority 50 has used its entire time
                quantum without blocking. What new priority will the scheduler
                assign this thread?
           c.   Assume that a thread with priority 20 blocks for I/O before its time
                quantum has expired. What new priority will the scheduler assign
                this thread?



                                                   Bibliographical Notes              311
6.28  Assume that two tasks A and B are running on a Linux system. The nice
      values of Aand B are -5 and +5, respectively. Using the CFS scheduler as
      a guide, describe how the respective values of vruntime vary between
      the two processes given each of the following scenarios:
      ·      Both A and B are CPU-bound.
      ·      A is I/O-bound, and B is CPU-bound.
      ·      A is CPU-bound, and B is I/O-bound.
6.29  Discuss   ways     in  which  the  priority  inversion  problem  could          be
      addressed in a real-time system. Also discuss whether the solutions
      could be implemented within the context of a proportional share sched-
      uler.
6.30  Under     what  circumstances  is  rate-monotonic   scheduling   inferior       to
      earliest-deadline-first scheduling in meeting the deadlines associated
      with processes?
6.31  Consider two processes, P1 and P2, where p1 = 50, t1 = 25, p2 = 75, and
      t2 = 30.
      a.     Can  these  two  processes   be   scheduled  using  rate-monotonic
             scheduling? Illustrate your answer using a Gantt chart such as
             the ones in Figure 6.16­Figure 6.19.
      b.     Illustrate the scheduling of these two processes using earliest-
             deadline-first (EDF) scheduling.
6.32  Explain why interrupt and dispatch latency times must be bounded in
      a hard real-time system.
Bibliographical Notes
Feedback queues were originally implemented on the CTSS system described in
[Corbato et al. (1962)]. This feedback queue scheduling system was analyzed by
[Schrage (1967)]. The preemptive priority scheduling algorithm of Exercise 6.23
was suggested by [Kleinrock (1975)]. The scheduling algorithms for hard real-
time systems, such as rate monotonic scheduling and earliest-deadline-first
scheduling, are presented in [Liu and Layland (1973)].
      [Anderson et al. (1989)], [Lewis and Berg (1998)], and [Philbin et al. (1996)]
discuss thread scheduling. Multicore scheduling is examined in [McNairy and
Bhatia (2005)] and [Kongetira et al. (2005)].
      [Fisher (1981)], [Hall et al. (1996)], and [Lowney et al. (1993)] describe
scheduling techniques that take into account information regarding process
execution times from previous runs.
      Fair-share schedulers are covered by [Henry (1984)], [Woodside (1986)],
and [Kay and Lauder (1988)].
      Scheduling policies used in the UNIX V operating system are described
by [Bach (1987)]; those for UNIX FreeBSD 5.2 are presented by [McKusick and
Neville-Neil (2005)]; and those for the Mach operating system are discussed
by [Black (1990)]. [Love (2010)] and [Mauerer (2008)] cover scheduling in



312  Chapter 6  CPU Scheduling
     Linux. [Faggioli et al. (2009)] discuss adding an EDF scheduler to the Linux
     kernel. Details of the ULE scheduler can be found in [Roberson (2003)]. Solaris
     scheduling is described by [Mauro and McDougall (2007)]. [Russinovich and
     Solomon (2009)] discusses scheduling in Windows internals. [Butenhof (1997)]
     and [Lewis and Berg (1998)] describe scheduling in Pthreads systems. [Siddha
     et al. (2007)] discuss scheduling challenges on multicore systems.
Bibliography
     [Anderson et al. (1989)]      T.  E.  Anderson,  E.      D.  Lazowska,  and  H.   M.  Levy,
     "The     Performance          Implications  of  Thread   Management     Alternatives     for
     Shared-Memory Multiprocessors", IEEE Transactions on Computers, Volume 38,
     Number 12 (1989), pages 1631­1644.
     [Bach (1987)]    M. J. Bach, The Design of the UNIX Operating System, Prentice Hall
     (1987).
     [Black (1990)]     D. L. Black, "Scheduling Support for Concurrency and Parallelism
     in the Mach Operating System", IEEE Computer, Volume 23, Number 5 (1990),
     pages 35­43.
     [Butenhof (1997)]         D.  Butenhof,     Programming  with  POSIX    Threads,  Addison-
     Wesley (1997).
     [Corbato et al. (1962)]       F. J. Corbato, M. Merwin-Daggett, and R. C. Daley, "An
     Experimental Time-Sharing System", Proceedings of the AFIPS Fall Joint Computer
     Conference (1962), pages 335­344.
     [Faggioli et al. (2009)]      D. Faggioli, F. Checconi, M. Trimarchi, and C. Scordino,
     "An EDF scheduling class for the Linux kernel", Proceedings of the 11th Real-Time
     Linux Workshop (2009).
     [Fisher (1981)]       J. A. Fisher, "Trace Scheduling: A Technique for Global Microcode
     Compaction", IEEE Transactions on Computers, Volume 30, Number 7 (1981),
     pages 478­490.
     [Hall et al. (1996)]      L. Hall, D. Shmoys, and J. Wein, "Scheduling To Minimize
     Average Completion Time: Off-line and On-line Algorithms", SODA: ACM-
     SIAM Symposium on Discrete Algorithms (1996).
     [Henry (1984)]        G. Henry, "The Fair Share Scheduler", AT&T Bell Laboratories
     Technical Journal (1984).
     [Kay and Lauder (1988)]       J. Kay and P. Lauder, "A Fair Share Scheduler", Com-
     munications of the ACM, Volume 31, Number 1 (1988), pages 44­55.
     [Kleinrock (1975)]        L. Kleinrock, Queueing Systems, Volume II: Computer Applica-
     tions, Wiley-Interscience (1975).
     [Kongetira et al. (2005)]     P. Kongetira, K. Aingaran, and K. Olukotun, "Niagara:
     A 32-Way Multithreaded SPARC Processor", IEEE Micro Magazine, Volume 25,
     Number 2 (2005), pages 21­29.



                                                              Bibliography              313
[Lewis and Berg (1998)]      B. Lewis and D. Berg, Multithreaded Programming with
Pthreads, Sun Microsystems Press (1998).
[Liu and Layland (1973)]     C. L. Liu and J. W. Layland, "Scheduling Algorithms
for Multiprogramming in a Hard Real-Time Environment", Communications of
the ACM, Volume 20, Number 1 (1973), pages 46­61.
[Love (2010)]     R. Love, Linux Kernel Development, Third Edition, Developer's
Library (2010).
[Lowney et al. (1993)]       P. G. Lowney, S. M. Freudenberger, T. J. Karzes, W. D.
Lichtenstein, R. P. Nix, J. S. O'Donnell, and J. C. Ruttenberg, "The Multiflow
Trace Scheduling Compiler", Journal of Supercomputing, Volume 7, Number 1-2
(1993), pages 51­142.
[Mauerer (2008)]        W. Mauerer, Professional Linux Kernel Architecture, John Wiley
and Sons (2008).
[Mauro and McDougall (2007)]            J. Mauro and R. McDougall, Solaris Internals:
Core Kernel Architecture, Prentice Hall (2007).
[McKusick and Neville-Neil (2005)]      M. K. McKusick and G. V. Neville-Neil,
The Design and Implementation of the FreeBSD UNIX Operating System, Addison
Wesley (2005).
[McNairy and Bhatia (2005)]    C. McNairy and R. Bhatia, "Montecito: A Dual­
Core, Dual-Threaded Itanium Processor", IEEE Micro Magazine, Volume 25,
Number 2 (2005), pages 10­20.
[Philbin et al. (1996)]      J. Philbin, J. Edler, O. J. Anshus, C. C. Douglas, and K. Li,
"Thread Scheduling for Cache Locality", Architectural Support for Programming
Languages and Operating Systems (1996), pages 60­71.
[Roberson (2003)]        J.  Roberson,  "ULE:  A  Modern  Scheduler  For  FreeBSD",
Proceedings of the USENIX BSDCon Conference (2003), pages 17­28.
[Russinovich and Solomon (2009)]        M. E. Russinovich and D. A. Solomon, Win-
dows Internals: Including Windows Server 2008 and Windows Vista, Fifth Edition,
Microsoft Press (2009).
[Schrage (1967)]   L. E. Schrage, "The Queue M/G/I with Feedback to Lower
Priority Queues", Management Science, Volume 13, (1967), pages 466­474.
[Siddha et al. (2007)]       S. Siddha, V. Pallipadi, and A. Mallick, "Process Schedul-
ing Challenges in the Era of Multi-Core Processors", Intel Technology Journal,
Volume 11, Number 4 (2007).
[Woodside (1986)]        C.  Woodside,  "Controllability  of  Computer  Performance
Tradeoffs Obtained Using Controlled-Share Queue Schedulers", IEEE Transac-
tions on Software Engineering, Volume SE-12, Number 10 (1986), pages 1041­1048.



