Summary
      The basic hardware elements involved in I/O are buses, device controllers, and
      the devices themselves. The work of moving data between devices and main
      memory is performed by the CPU as programmed I/O or is offloaded to a DMA
      controller. The kernel module that controls a device is a device driver. The
      system-call interface provided to applications is designed to handle several
      basic  categories  of  hardware,  including  block  devices,  character  devices,
      memory-mapped files, network sockets, and programmed interval timers. The
      system calls usually block the processes that issue them, but nonblocking and
      asynchronous calls are used by the kernel itself and by applications that must
      not sleep while waiting for an I/O operation to complete.
         The kernel's I/O subsystem provides numerous services. Among these
      are I/O scheduling, buffering, caching, spooling, device reservation, and error
      handling. Another service, name translation, makes the connections between
      hardware devices and the symbolic file names used by applications. It involves
      several levels of mapping that translate from character-string names, to specific
      device drivers and device addresses, and then to physical addresses of I/O ports
      or bus controllers. This mapping may occur within the file-system name space,
      as it does in UNIX, or in a separate device name space, as it does in MS-DOS.
         STREAMS is an implementation and methodology that provides a frame-
      work for a modular and incremental approach to writing device drivers and



                                                                     Exercises            619
network protocols. Through streams, drivers can be stacked, with data passing
through them sequentially and bidirectionally for processing.
I/O system calls are costly in terms of CPU consumption because of the
many layers of software between a physical device and an application. These
layers imply overhead from several sources: context switching to cross the
kernel's protection boundary, signal and interrupt handling to service the I/O
devices, and the load on the CPU and memory system to copy data between
kernel buffers and application space.
Practice Exercises
13.1       State three advantages of placing functionality in a device controller,
           rather than in the kernel. State three disadvantages.
13.2       The example of handshaking in Section 13.2 used two bits: a busy bit
           and a command-ready bit. Is it possible to implement this handshaking
           with only one bit? If it is, describe the protocol. If it is not, explain why
           one bit is insufficient.
13.3       Why might a system use interrupt-driven I/O to manage a single serial
           port and polling I/O to manage a front-end processor, such as a terminal
           concentrator?
13.4       Polling for an I/O completion can waste a large number of CPU cycles
           if the processor iterates a busy-waiting loop many times before the I/O
           completes. But if the I/O device is ready for service, polling can be much
           more efficient than is catching and dispatching an interrupt. Describe
           a hybrid strategy that combines polling, sleeping, and interrupts for
           I/O device service. For each of these three strategies (pure polling, pure
           interrupts, hybrid), describe a computing environment in which that
           strategy is more efficient than is either of the others.
13.5       How does DMA increase system concurrency? How does it complicate
           hardware design?
13.6       Why is it important to scale up system-bus and device speeds as CPU
           speed increases?
13.7       Distinguish between a STREAMS driver and a STREAMS module.
Exercises
13.8       When multiple interrupts from different devices appear at about the
           same time, a priority scheme could be used to determine the order in
           which the interrupts would be serviced. Discuss what issues need to
           be considered in assigning priorities to different interrupts.
13.9       What are the advantages and disadvantages of supporting memory-
           mapped I/O to device control registers?



620  Chapter 13   I/O Systems
     13.10  Consider the following I/O scenarios on a single-user PC:
            a.    A mouse used with a graphical user interface
            b.    A tape drive on a multitasking operating system (with no device
                  preallocation available)
            c.    A disk drive containing user files
            d.    A graphics card with direct bus connection, accessible through
                  memory-mapped I/O
            For each of these scenarios, would you design the operating system
            to use buffering, spooling, caching, or a combination? Would you use
            polled I/O or interrupt-driven I/O? Give reasons for your choices.
     13.11  In most multiprogrammed systems, user programs access memory
            through virtual addresses, while the operating system uses raw phys-
            ical addresses to access memory. What are the implications of this
            design for the initiation of I/O operations by the user program and
            their execution by the operating system?
     13.12  What are the various kinds of performance overhead associated with
            servicing an interrupt?
     13.13  Describe three circumstances under which blocking I/O should be used.
            Describe three circumstances under which nonblocking I/O should be
            used. Why not just implement nonblocking I/O and have processes
            busy-wait until their devices are ready?
     13.14  Typically, at the completion of a device I/O, a single interrupt is raised
            and appropriately handled by the host processor. In certain settings,
            however, the code that is to be executed at the completion of the
            I/O can be broken into two separate pieces. The first piece executes
            immediately after the I/O completes and schedules a second interrupt
            for the remaining piece of code to be executed at a later time. What is
            the purpose of using this strategy in the design of interrupt handlers?
     13.15  Some DMA controllers support direct virtual memory access, where
            the targets of I/O operations are specified as virtual addresses and
            a translation from virtual to physical address is performed during
            the DMA. How does this design complicate the design of the DMA
            controller? What are the advantages of providing such functionality?
     13.16  UNIX  coordinates  the   activities  of   the  kernel   I/O  components     by
            manipulating  shared     in-kernel   data  structures,  whereas  Windows
            uses object-oriented message passing between kernel I/O components.
            Discuss three pros and three cons of each approach.
     13.17  Write (in pseudocode) an implementation of virtual clocks, including
            the queueing and management of timer requests for the kernel and
            applications. Assume that the hardware provides three timer channels.
     13.18  Discuss the advantages and disadvantages of guaranteeing reliable
            transfer of data between modules in the STREAMS abstraction.



                                                             Bibliography             621
Bibliographical Notes
[Vahalia (1996)] provides a good overview of I/O and networking in UNIX.
[McKusick and Neville-Neil (2005)] detail the I/O structures and methods
employed in FreeBSD. The use and programming of the various interprocess-
communication and network protocols in UNIX are explored in [Stevens (1992)].
[Hart (2005)] covers Windows programming.
[Intel (2011)] provides a good source for Intel processors. [Rago (1993)]
provides a good discussion of STREAMS. [Hennessy and Patterson (2012)]
describe multiprocessor systems and cache-consistency issues.
Bibliography
[Hart (2005)]     J. M. Hart, Windows System Programming, Third Edition, Addison-
Wesley (2005).
[Hennessy and Patterson (2012)]     J. Hennessy and D. Patterson, Computer Archi-
tecture: A Quantitative Approach, Fifth Edition, Morgan Kaufmann (2012).
[Intel (2011)]    Intel 64 and IA-32 Architectures Software Developer's Manual, Com-
bined Volumes: 1, 2A, 2B, 3A and 3B. Intel Corporation (2011).
[McKusick and Neville-Neil (2005)]     M. K. McKusick and G. V. Neville-Neil,
The Design and Implementation of the FreeBSD UNIX Operating System, Addison
Wesley (2005).
[Rago (1993)]     S. Rago, UNIX System V Network Programming, Addison-Wesley
(1993).
[Stevens (1992)]  R. Stevens, Advanced Programming in the UNIX Environment,
Addison-Wesley (1992).
[Vahalia (1996)]  U.  Vahalia,   Unix  Internals:  The  New  Frontiers,  Prentice  Hall
(1996).






            Part Five