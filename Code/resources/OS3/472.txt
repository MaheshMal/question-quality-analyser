Summary
      It is desirable to be able to execute a process whose logical address space is
      larger than the available physical address space. Virtual memory is a technique
      that enables us to map a large logical address space onto a smaller physical
      memory. Virtual memory allows us to run extremely large processes and to
      raise the degree of multiprogramming, increasing CPU utilization. Further, it
      frees application programmers from worrying about memory availability. In
      addition, with virtual memory, several processes can share system libraries
      and memory. With virtual memory, we can also use an efficient type of process
      creation known as copy-on-write, wherein parent and child processes share
      actual pages of memory.
      Virtual    memory         is  commonly     implemented  by  demand   paging.  Pure
      demand paging never brings in a page until that page is referenced. The first
      reference causes a page fault to the operating system. The operating-system
      kernel consults an internal table to determine where the page is located on the
      backing store. It then finds a free frame and reads the page in from the backing
      store. The page table is updated to reflect this change, and the instruction that
      caused the page fault is restarted. This approach allows a process to run even
      though its entire memory image is not in main memory at once. As long as the
      page-fault rate is reasonably low, performance is acceptable.
      We can use demand paging to reduce the number of frames allocated to
      a process. This arrangement can increase the degree of multiprogramming
      (allowing more processes to be available for execution at one time) and --in
      theory, at least--the CPU utilization of the system. It also allows processes
      to be run even though their memory requirements exceed the total available
      physical memory. Such processes run in virtual memory.
      If total memory requirements exceed the capacity of physical memory,
      then it may be necessary to replace pages from memory to free frames for
      new pages. Various page-replacement algorithms are used. FIFO page replace-
      ment is easy to program but suffers from Belady's anomaly. Optimal page
      replacement requires future knowledge. LRU replacement is an approxima-
      tion of optimal page replacement, but even it may be difficult to implement.
      Most page-replacement algorithms, such as the second-chance algorithm, are
      approximations of LRU replacement.
      In addition to a page-replacement algorithm, a frame-allocation policy
      is needed. Allocation can be fixed, suggesting local page replacement, or
      dynamic, suggesting global replacement. The working-set model assumes that
      processes execute in localities. The working set is the set of pages in the current
      locality. Accordingly, each process should be allocated enough frames for its
      current working set. If a process does not have enough memory for its working
      set, it will thrash. Providing enough frames to each process to avoid thrashing
      may require process swapping and scheduling.
      Most operating systems provide features for memory mapping files, thus
      allowing   file  I/O  to  be  treated  as  routine  memory  access.  The  Win32       API
      implements shared memory through memory mapping of files.



                                                                  Practice Exercises   449
          Kernel processes typically require memory to be allocated using pages
that are physically contiguous. The buddy system allocates memory to kernel
processes in units sized according to a power of 2, which often results in
fragmentation. Slab allocators assign kernel data structures to caches associated
with slabs, which are made up of one or more physically contiguous pages.
With slab allocation, no memory is wasted due to fragmentation, and memory
requests can be satisfied quickly.
          In addition to requiring us to solve the major problems of page replacement
and frame allocation, the proper design of a paging system requires that
we consider prepaging, page size, TLB reach, inverted page tables, program
structure, I/O interlock and page locking, and other issues.
Practice  Exercises
9.1       Under what circumstances do page faults occur? Describe the actions
          taken by the operating system when a page fault occurs.
9.2       Assume that you have a page-reference string for a process with m
          frames (initially all empty). The page-reference string has length p, and
          n distinct page numbers occur in it. Answer these questions for any
          page-replacement algorithms:
          a.  What is a lower bound on the number of page faults?
          b.  What is an upper bound on the number of page faults?
9.3       Consider the page table shown in Figure 9.30 for a system with 12-bit
          virtual and physical addresses and with 256-byte pages. The list of free
          page frames is D, E, F (that is, D is at the head of the list, E is second,
          and F is last).
                           Page               Page Frame
                           0                  ­
                           1                  2
                           2                  C
                           3                  A
                           4                  ­
                           5                  4
                           6                  3
                           7                  ­
                           8                  B
                           9                  0
                           Figure 9.30  Page  table for Exercise  9.3.



450  Chapter 9  Virtual Memory
          Convert the following virtual addresses to their equivalent physical
          addresses in hexadecimal. All numbers are given in hexadecimal. (A
          dash for a page frame indicates that the page is not in memory.)
          ·     9EF
          ·     111
          ·     700
          ·     0FF
     9.4  Consider the following page-replacement algorithms. Rank these algo-
          rithms on a five-point scale from "bad" to "perfect" according to their
          page-fault rate. Separate those algorithms that suffer from Belady's
          anomaly from those that do not.
          a.    LRU replacement
          b.    FIFO replacement
          c.    Optimal replacement
          d.    Second-chance replacement
     9.5  Discuss the hardware support required to support demand paging.
     9.6  An operating system supports a paged virtual memory. The central
          processor has a cycle time of 1 microsecond. It costs an additional 1
          microsecond to access a page other than the current one. Pages have 1,000
          words, and the paging device is a drum that rotates at 3,000 revolutions
          per minute and transfers 1 million words per second. The following
          statistical measurements were obtained from the system:
          ·     One percent of all instructions executed accessed a page other than
                the current page.
          ·     Of the instructions that accessed another page, 80 percent accessed
                a page already in memory.
          ·     When a new page was required, the replaced page was modified 50
                percent of the time.
          Calculate the effective instruction time on this system, assuming that the
          system is running one process only and that the processor is idle during
          drum transfers.
     9.7  Consider the two-dimensional array A:
                int A[][] = new int[100][100];
          where A[0][0] is at location 200 in a paged memory system with pages
          of size 200. A small process that manipulates the matrix resides in page
          0 (locations 0 to 199). Thus, every instruction fetch will be from page 0.
          For three page frames, how many page faults are generated by the
          following array-initialization loops? Use LRU replacement, and assume



                                                               Practice Exercises       451
      that page frame 1 contains the process and the other two are initially
      empty.
      a.   for   (int  j   =  0;    j  <  100;      j++)
                for  (int     i  =  0;    i  <  100;    i++)
                     A[i][j]     =  0;
      b.   for   (int  i   =  0;    i  <  100;      i++)
                for  (int     j  =  0;    j  <  100;    j++)
                     A[i][j]     =  0;
9.8   Consider the following page reference string:
                     1, 2, 3, 4, 2, 1, 5, 6, 2, 1, 2, 3, 7, 6, 3, 2, 1, 2, 3, 6.
      How many page faults would occur for the following replacement
      algorithms, assuming one, two, three, four, five, six, and seven frames?
      Remember that all frames are initially empty, so your first unique pages
      will cost one fault each.
      ·    LRU replacement
      ·    FIFO replacement
      ·    Optimal replacement
9.9   Suppose that you want to use a paging algorithm that requires a reference
      bit (such as second-chance replacement or working-set model), but
      the hardware does not provide one. Sketch how you could simulate a
      reference bit even if one were not provided by the hardware, or explain
      why it is not possible to do so. If it is possible, calculate what the cost
      would be.
9.10  You have devised a new page-replacement algorithm that you think may
      be optimal. In some contorted test cases, Belady's anomaly occurs. Is the
      new algorithm optimal? Explain your answer.
9.11  Segmentation is similar to paging but uses variable-sized "pages." Define
      two  segment-replacement          algorithms,       one  based  on  the     FIFO  page-
      replacement scheme and the other on the LRU page-replacement scheme.
      Remember that since segments are not the same size, the segment that
      is chosen for replacement may be too small to leave enough consecutive
      locations for the needed segment. Consider strategies for systems where
      segments cannot be relocated and strategies for systems where they can.
9.12  Consider a demand-paged computer system where the degree of mul-
      tiprogramming    is  currently         fixed  at  four.  The  system        was  recently
      measured to determine utilization of the CPU and the paging disk. Three
      alternative results are shown below. For each case, what is happening?
      Can the degree of multiprogramming be increased to increase the CPU
      utilization? Is the paging helping?
      a.   CPU utilization 13 percent; disk utilization 97 percent
      b.   CPU utilization 87 percent; disk utilization 3 percent
      c.   CPU utilization 13 percent; disk utilization 3 percent



452  Chapter 9  Virtual Memory
     9.13  We have an operating system for a machine that uses base and limit
           registers, but we have modified the machine to provide a page table.
           Can the page tables be set up to simulate base and limit registers? How
           can they be, or why can they not be?
Exercises
     9.14  Assume that a program has just referenced an address in virtual memory.
           Describe a scenario in which each of the following can occur. (If no such
           scenario can occur, explain why.)
           ·    TLB miss with no page fault
           ·    TLB miss and page fault
           ·    TLB hit and no page fault
           ·    TLB hit and page fault
     9.15  A simplified view of thread states is Ready, Running, and Blocked, where
           a thread is either ready and waiting to be scheduled, is running on the
           processor, or is blocked (for example, waiting for I/O). This is illustrated
           in Figure 9.31. Assuming a thread is in the Running state, answer the
           following questions, and explain your answer:
           a.   Will the thread change state if it incurs a page fault? If so, to what
                state will it change?
           b.   Will the thread change state if it generates a TLB miss that is resolved
                in the page table? If so, to what state will it change?
           c.   Will the thread change state if an address reference is resolved in
                the page table? If so, to what state will it change?
     9.16  Consider a system that uses pure demand paging.
           a.   When a process first starts execution, how would you characterize
                the page-fault rate?
           b.   Once the working set for a process is loaded into memory, how
                would you characterize the page-fault rate?
                                           Ready
                Blocked                           Running
                Figure 9.31     Thread state diagram for Exercise 9.15.



                                                             Exercises              453
      c.  Assume that a process changes its locality and the size of the new
          working set is too large to be stored in available free memory.
          Identify some options system designers could choose from to
          handle this situation.
9.17  What is the copy-on-write feature, and under what circumstances is its
      use beneficial? What hardware support is required to implement this
      feature?
9.18  A certain computer provides its users with a virtual memory space of
      232 bytes. The computer has 222 bytes of physical memory. The virtual
      memory is implemented by paging, and the page size is 4,096 bytes.
      A user process generates the virtual address 11123456. Explain how
      the system establishes the corresponding physical location. Distinguish
      between software and hardware operations.
9.19  Assume that we have a demand-paged memory. The page table is held in
      registers. It takes 8 milliseconds to service a page fault if an empty frame
      is available or if the replaced page is not modified and 20 milliseconds if
      the replaced page is modified. Memory-access time is 100 nanoseconds.
          Assume that the page to be replaced is modified 70 percent of the
      time. What is the maximum acceptable page-fault rate for an effective
      access time of no more than 200 nanoseconds?
9.20  When a page fault occurs, the process requesting the page must block
      while waiting for the page to be brought from disk into physical memory.
      Assume that there exists a process with five user-level threads and that
      the mapping of user threads to kernel threads is one to one. If one user
      thread incurs a page fault while accessing its stack, would the other
      user threads belonging to the same process also be affected by the page
      fault--that is, would they also have to wait for the faulting page to be
      brought into memory? Explain.
9.21  Consider the following page reference string:
                7, 2, 3, 1, 2, 5, 3, 4, 6, 7, 7, 1, 0, 5, 4, 6, 2, 3, 0 , 1.
      Assuming demand paging with three frames, how many page faults
      would occur for the following replacement algorithms?
      ·   LRU replacement
      ·   FIFO replacement
      ·   Optimal replacement
9.22  The page table shown in Figure 9.32 is for a system with 16-bit virtual
      and physical addresses and with 4,096-byte pages. The reference bit is
      set to 1 when the page has been referenced. Periodically, a thread zeroes
      out all values of the reference bit. A dash for a page frame indicates
      the page is not in memory. The page-replacement algorithm is localized
      LRU, and all numbers are provided in decimal.
      a.  Convert the following virtual addresses (in hexadecimal) to the
          equivalent physical addresses. You may provide answers in either



454  Chapter 9  Virtual Memory
                    Page            Page Frame           Reference   Bit
                    0                    9                   0
                    1                    1                   0
                    2                    14                  0
                    3                    10                  0
                    4                    ­                   0
                    5                    13                  0
                    6                    8                   0
                    7                    15                  0
                    8                    ­                   0
                    9                    0                   0
                    10                   5                   0
                    11                   4                   0
                    12                   ­                   0
                    13                   ­                   0
                    14                   3                   0
                    15                   2                   0
                        Figure 9.32  Page table for Exercise 9.22.
                hexadecimal or decimal. Also set the reference bit for the appro-
                priate entry in the page table.
                ·   0xE12C
                ·   0x3A9D
                ·   0xA9D9
                ·   0x7001
                ·   0xACA1
           b.   Using the above addresses as a guide, provide an example of a
                logical address (in hexadecimal) that results in a page fault.
           c.   From what set of page frames will the LRU page-replacement
                algorithm choose in resolving a page fault?
     9.23  Assume that you are monitoring the rate at which the pointer in the
           clock algorithm moves. (The pointer indicates the candidate page for
           replacement.) What can you say about the system if you notice the
           following behavior:
           a.   Pointer is moving fast.
           b.   Pointer is moving slow.
     9.24  Discuss  situations  in  which    the  least  frequently  used  (LFU)  page-
           replacement algorithm generates fewer page faults than the least recently
           used (LRU) page-replacement algorithm. Also discuss under what cir-
           cumstances the opposite holds.
     9.25  Discuss  situations  in  which    the  most   frequently  used  (MFU)  page-
           replacement algorithm generates fewer page faults than the least recently
           used (LRU) page-replacement algorithm. Also discuss under what cir-
           cumstances the opposite holds.



                                                        Exercises                    455
9.26  The VAX/VMS system uses a FIFO replacement algorithm for resident
      pages and a free-frame pool of recently used pages. Assume that the
      free-frame pool is managed using the LRU replacement policy. Answer
      the following questions:
      a.  If a page fault occurs and the page does not exist in the free-frame
          pool, how is free space generated for the newly requested page?
      b.  If a page fault occurs and the page exists in the free-frame pool,
          how is the resident page set and the free-frame pool managed to
          make space for the requested page?
      c.  What does the system degenerate to if the number of resident pages
          is set to one?
      d.  What does the system degenerate to if the number of pages in the
          free-frame pool is zero?
9.27  Consider a demand-paging system with the following time-measured
      utilizations:
                          CPU utilization     20%
                          Paging disk         97.7%
                          Other I/O devices         5%
      For each of the following, indicate whether it will (or is likely to) improve
      CPU utilization. Explain your answers.
      a.  Install a faster CPU.
      b.  Install a bigger paging disk.
      c.  Increase the degree of multiprogramming.
      d.  Decrease the degree of multiprogramming.
      e.  Install more main memory.
      f.  Install a faster hard disk or multiple controllers with multiple hard
          disks.
      g.  Add prepaging to the page-fetch algorithms.
      h.  Increase the page size.
9.28  Suppose that a machine provides instructions that can access memory
      locations using the one-level indirect addressing scheme. What sequence
      of page faults is incurred when all of the pages of a program are
      currently nonresident and the first instruction of the program is an
      indirect memory-load operation? What happens when the operating
      system is using a per-process frame allocation technique and only two
      pages are allocated to this process?
9.29  Suppose that your replacement policy (in a paged system) is to examine
      each page regularly and to discard that page if it has not been used since
      the last examination. What would you gain and what would you lose
      by using this policy rather than LRU or second-chance replacement?



456  Chapter 9  Virtual Memory
     9.30  A page-replacement algorithm should minimize the number of page
           faults. We can achieve this minimization by distributing heavily used
           pages evenly over all of memory, rather than having them compete for
           a small number of page frames. We can associate with each page frame
           a counter of the number of pages associated with that frame. Then,
           to replace a page, we can search for the page frame with the smallest
           counter.
           a.   Define a page-replacement algorithm using this basic idea. Specif-
                ically address these problems:
                i.    What is the initial value of the counters?
                ii.   When are counters increased?
                iii.  When are counters decreased?
                iv.   How is the page to be replaced selected?
           b.   How many page faults occur for your algorithm for the following
                reference string with four page frames?
                      1, 2, 3, 4, 5, 3, 4, 1, 6, 7, 8, 7, 8, 9, 7, 8, 9, 5, 4, 5, 4, 2.
           c.   What is the minimum number of page faults for an optimal page-
                replacement strategy for the reference string in part b with four
                page frames?
     9.31  Consider a demand-paging system with a paging disk that has an
           average access and transfer time of 20 milliseconds. Addresses are
           translated through a page table in main memory, with an access time of 1
           microsecond per memory access. Thus, each memory reference through
           the page table takes two accesses. To improve this time, we have added
           an associative memory that reduces access time to one memory reference
           if the page-table entry is in the associative memory.
           Assume that 80 percent of the accesses are in the associative memory
           and that, of those remaining, 10 percent (or 2 percent of the total) cause
           page faults. What is the effective memory access time?
     9.32  What is the cause of thrashing? How does the system detect thrashing?
           Once it detects thrashing, what can the system do to eliminate this
           problem?
     9.33  Is it possible for a process to have two working sets, one representing
           data and another representing code? Explain.
     9.34  Consider the parameter        used to define the working-set window in the
           working-set model. When         is set to a small value, what is the effect
           on the page-fault frequency and the number of active (nonsuspended)
           processes currently executing in the system? What is the effect when
           is set to a very high value?
     9.35  In a 1,024-KB segment, memory is allocated using the buddy system.
           Using Figure 9.26 as a guide, draw a tree illustrating how the following
           memory requests are allocated:
           ·    Request 6-KB



                                                  Programming Problems             457
      ·  Request 250 bytes
      ·  Request 900 bytes
      ·  Request 1,500 bytes
      ·  Request 7-KB
      Next, modify the tree for the following releases of memory. Perform
      coalescing whenever possible:
      ·  Release 250 bytes
      ·  Release 900 bytes
      ·  Release 1,500 bytes
9.36  A system provides support for user-level and kernel-level threads. The
      mapping in this system is one to one (there is a corresponding kernel
      thread for each user thread). Does a multithreaded process consist of (a)
      a working set for the entire process or (b) a working set for each thread?
      Explain
9.37  The slab-allocation algorithm uses a separate cache for each different
      object type. Assuming there is one cache per object type, explain why
      this scheme doesn't scale well with multiple CPUs. What could be done
      to address this scalability issue?
9.38  Consider a system that allocates pages of different sizes to its processes.
      What are the advantages of such a paging scheme? What modifications
      to the virtual memory system provide this functionality?
Programming Problems
9.39  Write a program that implements the FIFO, LRU, and optimal page-
      replacement  algorithms  presented      in  this  chapter.  First,  generate  a
      random page-reference string where page numbers range from 0 to 9.
      Apply the random page-reference string to each algorithm, and record
      the number of page faults incurred by each algorithm. Implement the
      replacement algorithms so that the number of page frames can vary from
      1 to 7. Assume that demand paging is used.
9.40  Repeat Exercise 3.22, this time using Windows shared memory. In partic-
      ular, using the producer--consumer strategy, design two programs that
      communicate with shared memory using the Windows API as outlined
      in Section 9.7.2. The producer will generate the numbers specified in
      the Collatz conjecture and write them to a shared memory object. The
      consumer will then read and output the sequence of numbers from
      shared memory.
         In this instance, the producer will be passed an integer parameter
      on the command line specifying how many numbers to produce (for
      example, providing 5 on the command line means the producer process
      will generate the first five numbers).



458  Chapter 9  Virtual Memory
Programming Projects
     Designing a Virtual Memory Manager
     This project consists of writing a program that translates logical to physical
     addresses for a virtual address space of size 216 = 65,536 bytes. Your program
     will read from a file containing logical addresses and, using a TLB as well as
     a page table, will translate each logical address to its corresponding physical
     address and output the value of the byte stored at the translated physical
     address. The goal behind this project is to simulate the steps involved in
     translating logical to physical addresses.
     Specifics
     Your program will read a file containing several 32-bit integer numbers that
     represent logical addresses. However, you need only be concerned with 16-bit
     addresses, so you must mask the rightmost 16 bits of each logical address.
     These 16 bits are divided into (1) an 8-bit page number and (2) 8-bit page offset.
     Hence, the addresses are structured as shown in Figure 9.33.
        Other specifics include the following:
     ·  28 entries in the page table
     ·  Page size of 28 bytes
     ·  16 entries in the TLB
     ·  Frame size of 28 bytes
     ·  256 frames
     ·  Physical memory of 65,536 bytes (256 frames × 256-byte frame size)
        Additionally, your program need only be concerned with reading logical
     addresses and translating them to their corresponding physical addresses. You
     do not need to support writing to the logical address space.
     Address Translation
     Your program will translate logical to physical addresses using a TLB and page
     table as outlined in Section 8.5. First, the page number is extracted from the
     logical address, and the TLB is consulted. In the case of a TLB-hit, the frame
     number is obtained from the TLB. In the case of a TLB-miss, the page table
     must be consulted. In the latter case, either the frame number is obtained
                                                   page          offset
                                                   number
                    31                      16 15          8  7          0
                               Figure 9.33  Address structure.



                                                     Programming Projects                 459
page    offset
number                   page       frame
                         number  number
                     0
                     1
                     2
                     .                                                     0    frame 0
                     .
                     .                     TLB hit                         1    frame 1
                     .                                                     2    frame 2
                     15                             frame                  .
                                                            offset         .
                                                    number                 .
                               TLB
                                                                           .
                         0     page 0                                      255  frame 255
                         1     page 1                                           physical
                         2     page 2                                           memory
                         .
                         .
                         .
        TLB miss         .
                         255  page 255
                               page
                               table
        Figure 9.34      A representation of the address-translation process.
from the page table or a page fault occurs. A visual representation of the
address-translation process appears in Figure 9.34.
Handling Page Faults
Your program will implement demand paging as described in Section 9.2. The
backing store is represented by the file BACKING STORE.bin, a binary file of size
65,536 bytes. When a page fault occurs, you will read in a 256-byte page from the
file BACKING STORE and store it in an available page frame in physical memory.
For example, if a logical address with page number 15 resulted in a page fault,
your program would read in page 15 from BACKING STORE (remember that
pages begin at 0 and are 256 bytes in size) and store it in a page frame in
physical memory. Once this frame is stored (and the page table and TLB are
updated), subsequent accesses to page 15 will be resolved by either the TLB or
the page table.
You will need to treat BACKING STORE.bin as a random-access file so that
you can randomly seek to certain positions of the file for reading. We suggest
using the standard C library functions for performing I/O, including fopen(),
fread(), fseek(), and fclose().
The     size     of  physical    memory    is  the  same    as  the  size  of   the  virtual
address space--65,536 bytes--so you do not need to be concerned about
page replacements during a page fault. Later, we describe a modification
to this project using a smaller amount of physical memory; at that point, a
page-replacement strategy will be required.



460  Chapter 9   Virtual Memory
     Test File
     We provide the file addresses.txt, which contains integer values represent-
     ing logical addresses ranging from 0 - 65535 (the size of the virtual address
     space). Your program will open this file, read each logical address and translate
     it to its corresponding physical address, and output the value of the signed byte
     at the physical address.
     How to Begin
     First, write a simple program that extracts the page number and offset (based
     on Figure 9.33) from the following integer numbers:
         1, 256, 32768, 32769, 128, 65534, 33153
     Perhaps the easiest way to do this is by using the operators for bit-masking
     and bit-shifting. Once you can correctly establish the page number and offset
     from an integer number, you are ready to begin.
         Initially, we suggest that you bypass the TLB and use only a page table. You
     can integrate the TLB once your page table is working properly. Remember,
     address translation can work without a TLB; the TLB just makes it faster. When
     you are ready to implement the TLB, recall that it has only 16 entries, so you
     will need to use a replacement strategy when you update a full TLB. You may
     use either a FIFO or an LRU policy for updating your TLB.
     How to Run Your Program
     Your program should run as follows:
         ./a.out addresses.txt
     Your program will read in the file addresses.txt, which contains 1,000 logical
     addresses ranging from 0 to 65535. Your program is to translate each logical
     address to a physical address and determine the contents of the signed byte
     stored at the correct physical address. (Recall that in the C language, the char
     data type occupies a byte of storage, so we suggest using char values.)
         Your program is to output the following values:
     1.  The logical address being translated (the integer value being read from
         addresses.txt).
     2.  The corresponding physical address (what your program translates the
         logical address to).
     3.  The signed byte value stored at the translated physical address.
         We also provide the file correct.txt, which contains the correct output
     values for the file addresses.txt. You should use this file to determine if your
     program is correctly translating logical to physical addresses.
     Statistics
     After completion, your program is to report the following statistics:



                                                  Bibliographical Notes          461
1.  Page-fault rate --The percentage of address references that resulted in
    page faults.
2.  TLB hit rate --The percentage of address references that were resolved in
    the TLB.
    Since the logical addresses in addresses.txt were generated randomly
and do not reflect any memory access locality, do not expect to have a high TLB
hit rate.
Modifications
This project assumes that physical memory is the same size as the virtual
address space. In practice, physical memory is typically much smaller than a
virtual address space. A suggested modification is to use a smaller physical
address space. We recommend using 128 page frames rather than 256. This
change will require modifying your program so that it keeps track of free page
frames as well as implementing a page-replacement policy using either FIFO
or LRU (Section 9.4).
Bibliographical Notes
Demand paging was first used in the Atlas system, implemented on the
Manchester University MUSE computer around 1960 ([Kilburn et al. (1961)]).
Another early demand-paging system was MULTICS, implemented on the GE
645 system ([Organick (1972)]). Virtual memory was added to Unix in 1979
[Babaoglu and Joy (1981)]
    [Belady et al. (1969)] were the first researchers to observe that the FIFO
replacement strategy may produce the anomaly that bears Belady's name.
[Mattson et al. (1970)] demonstrated that stack algorithms are not subject to
Belady's anomaly.
    The    optimal  replacement  algorithm   was  presented  by     [Belady  (1966)]
and was proved to be optimal by [Mattson et al. (1970)]. Belady's optimal
algorithm is for a fixed allocation; [Prieve and Fabry (1976)] presented an
optimal algorithm for situations in which the allocation can vary.
    The enhanced clock algorithm was discussed by [Carr and Hennessy
(1981)].
    The working-set model was developed by [Denning (1968)]. Discussions
concerning the working-set model were presented by [Denning (1980)].
    The scheme for monitoring the page-fault rate was developed by [Wulf
(1969)],   who  successfully  applied  this  technique  to  the  Burroughs   B5500
computer system.
    Buddy system memory allocators were described in [Knowlton (1965)],
[Peterson and Norman (1977)], and [Purdom, Jr. and Stigler (1970)]. [Bonwick
(1994)] discussed the slab allocator, and [Bonwick and Adams (2001)] extended
the discussion to multiple processors. Other memory-fitting algorithms can be
found in [Stephenson (1983)], [Bays (1977)], and [Brent (1989)]. A survey of
memory-allocation strategies can be found in [Wilson et al. (1995)].
    [Solomon and Russinovich (2000)] and [Russinovich and Solomon (2005)]
described how Windows implements virtual memory. [McDougall and Mauro



462  Chapter 9    Virtual Memory
     (2007)] discussed virtual memory in Solaris. Virtual memory techniques in
     Linux   and    FreeBSD    were  described  by    [Love    (2010)]  and  [McKusick    and
     Neville-Neil    (2005)],  respectively.  [Ganapathy       and  Schimmel     (1998)]  and
     [Navarro et al. (2002)] discussed operating system support for multiple page
     sizes.
Bibliography
     [Babaoglu and Joy (1981)]       O. Babaoglu and W. Joy, "Converting a Swap-Based
     System to Do Paging in an Architecture Lacking Page-Reference Bits", Pro-
     ceedings of the ACM Symposium on Operating Systems Principles (1981), pages
     78­86.
     [Bays (1977)]    C. Bays, "A Comparison of Next-Fit, First-Fit and Best-Fit", Com-
     munications of the ACM, Volume 20, Number 3 (1977), pages 191­192.
     [Belady (1966)]     L. A. Belady, "A Study of Replacement Algorithms for a Virtu-
     al-Storage Computer", IBM Systems Journal, Volume 5, Number 2 (1966), pages
     78­101.
     [Belady et al. (1969)]    L. A. Belady, R. A. Nelson, and G. S. Shedler, "An Anomaly
     in      Space-Time  Characteristics  of    Certain  Programs       Running  in  a  Paging
     Machine", Communications of the ACM, Volume 12, Number 6 (1969), pages
     349­353.
     [Bonwick (1994)]        J. Bonwick, "The Slab Allocator: An Object-Caching Kernel
     Memory Allocator", USENIX Summer (1994), pages 87­98.
     [Bonwick and Adams (2001)]      J. Bonwick and J. Adams, "Magazines and Vmem:
     Extending the Slab Allocator to Many CPUs and Arbitrary Resources", Proceed-
     ings of the 2001 USENIX Annual Technical Conference (2001).
     [Brent (1989)]    R. Brent, "Efficient Implementation of the First-Fit Strategy for
     Dynamic Storage Allocation", ACM Transactions on Programming Languages and
     Systems, Volume 11, Number 3 (1989), pages 388­403.
     [Carr and Hennessy (1981)]      W.   R.    Carr  and  J.  L.  Hennessy,     "WSClock -- A
     Simple and Effective Algorithm for Virtual Memory Management", Proceedings
     of the ACM Symposium on Operating Systems Principles (1981), pages 87­95.
     [Denning (1968)]        P. J. Denning, "The Working Set Model for Program Behavior",
     Communications of the ACM, Volume 11, Number 5 (1968), pages 323­333.
     [Denning (1980)]        P. J. Denning, "Working Sets Past and Present", IEEE Transac-
     tions on Software Engineering, Volume SE-6, Number 1 (1980), pages 64­84.
     [Ganapathy and Schimmel (1998)]            N. Ganapathy and C. Schimmel, "General
     Purpose Operating System Support for Multiple Page Sizes", Proceedings of the
     USENIX Technical Conference (1998).
     [Kilburn et al. (1961)]    T. Kilburn, D. J. Howarth, R. B. Payne, and F. H. Sumner,
     "The Manchester University Atlas Operating System, Part I: Internal Organiza-
     tion", Computer Journal, Volume 4, Number 3 (1961), pages 222­225.



                                                                   Bibliography          463
[Knowlton (1965)]        K. C. Knowlton, "A Fast Storage Allocator", Communications
of the ACM, Volume 8, Number 10 (1965), pages 623­624.
[Love (2010)]   R. Love, Linux Kernel Development, Third Edition, Developer's
Library (2010).
[Mattson et al. (1970)]      R. L. Mattson, J. Gecsei, D. R. Slutz, and I. L. Traiger,
"Evaluation Techniques for Storage Hierarchies", IBM Systems Journal, Volume
9, Number 2 (1970), pages 78­117.
[McDougall and Mauro (2007)]             R. McDougall and J. Mauro, Solaris Internals,
Second Edition, Prentice Hall (2007).
[McKusick and Neville-Neil (2005)]          M. K. McKusick and G. V. Neville-Neil,
The Design and Implementation of the FreeBSD UNIX Operating System, Addison
Wesley (2005).
[Navarro et al. (2002)]      J. Navarro, S. Lyer, P. Druschel, and A. Cox, "Practical,
Transparent    Operating         System  Support     for  Superpages",  Proceedings  of  the
USENIX Symposium on Operating Systems Design and Implementation (2002).
[Organick (1972)]        E.  I.  Organick,  The  Multics  System:  An   Examination  of  Its
Structure, MIT Press (1972).
[Peterson and Norman (1977)]      J. L. Peterson and T. A. Norman, "Buddy Sys-
tems", Communications of the ACM, Volume 20, Number 6 (1977), pages 421­431.
[Prieve and Fabry (1976)]        B. G. Prieve and R. S. Fabry, "VMIN -- An Optimal
Variable  Space    Page-Replacement         Algorithm",   Communications    of  the  ACM,
Volume 19, Number 5 (1976), pages 295­297.
[Purdom, Jr. and Stigler (1970)]         P. W. Purdom, Jr. and S. M. Stigler, "Statistical
Properties of the Buddy System", J. ACM, Volume 17, Number 4 (1970), pages
683­697.
[Russinovich and Solomon (2005)]            M.   E.  Russinovich   and  D.  A.  Solomon,
Microsoft Windows Internals, Fourth Edition, Microsoft Press (2005).
[Solomon and Russinovich (2000)]            D. A. Solomon and M. E. Russinovich, Inside
Microsoft Windows 2000, Third Edition, Microsoft Press (2000).
[Stephenson (1983)]          C. J. Stephenson, "Fast Fits: A New Method for Dynamic
Storage Allocation", Proceedings of the Ninth Symposium on Operating Systems
Principles (1983), pages 30­32.
[Wilson et al. (1995)]       P. R. Wilson, M. S. Johnstone, M. Neely, and D. Boles,
"Dynamic Storage Allocation: A Survey and Critical Review", Proceedings of the
International Workshop on Memory Management (1995), pages 1­116.
[Wulf (1969)]   W. A. Wulf, "Performance Monitors for Multiprogramming Sys-
tems", Proceedings of the ACM Symposium on Operating Systems Principles (1969),
pages 175­181.






                 Part Four
Storage
Management
Since main memory is usually too small to accommodate all the data and
programs permanently, the computer system must provide secondary
storage to back up main memory. Modern computer systems use disks
as the primary on-line storage medium for information (both programs
and data). The file system provides the mechanism for on-line storage
of and access to both data and programs residing on the disks. A file
is a collection of related information defined by its creator. The files are
mapped by the operating system onto physical devices. Files are normally
organized into directories for ease of use.
     The devices that attach to a computer vary in many aspects. Some
devices transfer a character or a block of characters at a time. Some
can  be   accessed  only  sequentially,  others   randomly.  Some   transfer
data synchronously, others asynchronously. Some are dedicated, some
shared. They can be read-only or read ­ write. They vary greatly in speed.
In  many  ways,  they  are  also  the    slowest  major  component  of        the
computer.
     Because of all this device variation, the operating system needs to
provide a wide range of functionality to applications, to allow them to
control all aspects of the devices. One key goal of an operating system's
I/O subsystem is to provide the simplest interface possible to the rest of
the system. Because devices are a performance bottleneck, another key
is to optimize I/O for maximum concurrency.



