Summary
      Given a collection of cooperating sequential processes that share data, mutual
      exclusion must be provided to ensure that a critical section of code is used by
      only one process or thread at a time. Typically, computer hardware provides
      several operations that ensure mutual exclusion. However, such hardware-
      based solutions are too complicated for most developers to use. Mutex locks
      and semaphores overcome this obstacle. Both tools can be used to solve various
      synchronization problems and can be implemented efficiently, especially if
      hardware support for atomic operations is available.
           Various synchronization problems (such as the bounded-buffer problem,
      the readers­writers problem, and the dining-philosophers problem) are impor-
      tant mainly because they are examples of a large class of concurrency-control
      problems. These problems are used to test nearly every newly proposed
      synchronization scheme.
           The operating system must provide the means to guard against timing
      errors, and several language constructs have been proposed to deal with
      these problems. Monitors provide a synchronization mechanism for sharing
      abstract data types. A condition variable provides a method by which a monitor
      function can block its execution until it is signaled to continue.
           Operating systems also provide support for synchronization. For example,
      Windows, Linux, and Solaris provide mechanisms such as semaphores, mutex
      locks, spinlocks, and condition variables to control access to shared data. The
      Pthreads API provides support for mutex locks and semaphores, as well as
      condition variables.
           Several alternative approaches focus on synchronization for multicore
      systems. One approach uses transactional memory, which may address syn-
      chronization issues using either software or hardware techniques. Another
      approach uses the compiler extensions offered by OpenMP. Finally, func-
      tional programming languages address synchronization issues by disallowing
      mutability.
Practice   Exercises
      5.1  In Section 5.4, we mentioned that disabling interrupts frequently can
           affect the system's clock. Explain why this can occur and how such
           effects can be minimized.
      5.2  Explain why Windows, Linux, and Solaris implement multiple locking
           mechanisms. Describe the circumstances under which they use spin-
           locks, mutex locks, semaphores, adaptive mutex locks, and condition
           variables. In each case, explain why the mechanism is needed.



                                                                     Exercises         243
5.3        What is the meaning of the term busy waiting? What other kinds of
           waiting are there in an operating system? Can busy waiting be avoided
           altogether? Explain your answer.
5.4        Explain why spinlocks are not appropriate for single-processor systems
           yet are often used in multiprocessor systems.
5.5        Show that, if the wait() and signal() semaphore operations are not
           executed atomically, then mutual exclusion may be violated.
5.6        Illustrate how a binary semaphore can be used to implement mutual
           exclusion among n processes.
Exercises
5.7        Race conditions are possible in many computer systems. Consider a
           banking system that maintains an account balance with two functions:
           deposit(amount) and withdraw(amount). These two functions are
           passed the amount that is to be deposited or withdrawn from the bank
           account balance. Assume that a husband and wife share a bank account.
           Concurrently, the husband calls the withdraw() function and the wife
           calls deposit(). Describe how a race condition is possible and what
           might be done to prevent the race condition from occurring.
5.8        The first known correct software solution to the critical-section problem
           for two processes was developed by Dekker. The two processes, P0 and
           P1, share the following variables:
                       boolean flag[2];        /*  initially     false     */
                       int  turn;
           The structure of process Pi (i == 0 or 1) is shown in Figure 5.21. The
           other process is Pj (j == 1 or 0). Prove that the algorithm satisfies all
           three requirements for the critical-section problem.
5.9        The first known correct software solution to the critical-section problem
           for n processes with a lower bound on waiting of n - 1 turns was
           presented by Eisenberg and McGuire. The processes share the following
           variables:
                       enum pstate {idle,          want   in,    in  cs};
                       pstate flag[n];
                       int  turn;
           All the elements of flag are initially idle. The initial value of turn is
           immaterial (between 0 and n-1). The structure of process Pi is shown in
           Figure 5.22. Prove that the algorithm satisfies all three requirements for
           the critical-section problem.
5.10       Explain why implementing synchronization primitives by disabling
           interrupts is not appropriate in a single-processor system if the syn-
           chronization primitives are to be used in user-level programs.



244  Chapter 5  Process Synchronization
                       do      {
                             flag[i]     =   true;
                             while (flag[j]) {
                                  if (turn == j) {
                                      flag[i]     =  false;
                                      while  (turn    ==    j)
                                         ;   /*  do  nothing    */
                                      flag[i]     =  true;
                                  }
                             }
                                  /*  critical       section    */
                             turn     =  j;
                             flag[i] = false;
                                  /*  remainder      section    */
                       }   while      (true);
                Figure 5.21     The structure of process Pi in Dekker's  algorithm.
     5.11  Explain why interrupts are not appropriate for implementing synchro-
           nization primitives in multiprocessor systems.
     5.12  The Linux kernel has a policy that a process cannot hold a spinlock while
           attempting to acquire a semaphore. Explain why this policy is in place.
     5.13  Describe two kernel data structures in which race conditions are possible.
           Be sure to include a description of how a race condition can occur.
     5.14  Describe how the compare and swap() instruction can be used to pro-
           vide mutual exclusion that satisfies the bounded-waiting requirement.
     5.15  Consider how to implement a mutex lock using an atomic hardware
           instruction. Assume that the following structure defining the mutex
           lock is available:
                                         typedef struct {
                                                 int available;
                                         } lock;
           (available     ==      0) indicates that the lock is available, and a value of 1
           indicates that the lock is unavailable. Using this struct, illustrate how
           the following functions can be implemented using the test and set()
           and compare and swap() instructions:
           ·    void  acquire(lock           *mutex)
           ·    void  release(lock           *mutex)
           Be sure to include any initialization that may be necessary.



                                                                                   Exercises   245
      do  {
          while (true) {
             flag[i] = want in;
             j = turn;
             while (j != i) {
                   if  (flag[j]          !=  idle)      {
                       j   =  turn;
                   else
                       j   =  (j     +  1)   %  n;
             }
             flag[i] = in cs;
             j = 0;
             while (          (j  <     n)  &&  (j   ==     i     ||  flag[j]  !=  in cs))
                   j++;
             if     (  (j     >=  n)    &&   (turn      ==     i  ||  flag[turn]   ==  idle))
                   break;
          }
             /*     critical         section     */
          j  =  (turn      +  1)     %   n;
          while       (flag[j]       ==     idle)
             j   =     (j  +  1)     %  n;
          turn     =   j;
          flag[i] = idle;
             /*     remainder           section     */
      }   while    (true);
      Figure 5.22      The structure of process Pi in Eisenberg and McGuire's algorithm.
5.16     The implementation of mutex locks provided in Section 5.5 suffers from
         busy waiting. Describe what changes would be necessary so that a
         process waiting to acquire a mutex lock would be blocked and placed
         into a waiting queue until the lock became available.
5.17     Assume that a system has multiple processing cores. For each of the
         following scenarios, describe which is a better locking mechanism--a
         spinlock or a mutex lock where waiting processes sleep while waiting
         for the lock to become available:
          ·  The lock is to be held for a short duration.
          ·  The lock is to be held for a long duration.
          ·  A thread may be put to sleep while holding the lock.



246  Chapter  5  Process Synchronization
              #define MAX PROCESSES 255
              int number of processes = 0;
              /*  the    implementation       of  fork()  calls  this      function   */
              int allocate process() {
              int new pid;
                  if   (number  of    processes   ==  MAX PROCESSES)
                       return   -1;
                  else   {
                       /*   allocate  necessary       process    resources     */
                       ++number of processes;
                       return   new   pid;
                  }
              }
              /*  the    implementation       of  exit()  calls  this      function   */
              void release process() {
                     /* release process resources */
                     --number of processes;
              }
                         Figure 5.23  Allocating and releasing processes.
     5.18  Assume that a context switch takes T time. Suggest an upper bound
           (in terms of T) for holding a spinlock. If the spinlock is held for any
           longer, a mutex lock (where waiting threads are put to sleep) is a better
           alternative.
     5.19  A  multithreaded     web   server  wishes  to   keep  track     of  the  number
           of requests it services (known as hits). Consider the two following
           strategies to prevent a race condition on the variable hits. The first
           strategy is to use a basic mutex lock when updating hits:
                  int    hits;
                  mutex lock hit lock;
                  hit lock.acquire();
                  hits++;
                  hit lock.release();
           A second strategy is to use an atomic integer:
                  atomic t hits;
                  atomic inc(&hits);
           Explain which of these two strategies is more efficient.
     5.20  Consider the code example for allocating and releasing processes shown
           in Figure 5.23.



                                                                         Exercises       247
      a.     Identify the race condition(s).
      b.     Assume you have a mutex lock named mutex with the operations
             acquire() and release(). Indicate where the locking needs to
             be placed to prevent the race condition(s).
      c.     Could we replace the integer variable
                    int     number of processes            =  0
             with the atomic integer
                    atomic t       number of processes            =   0
             to prevent the race condition(s)?
5.21  Servers can be designed to limit the number of open connections. For
      example, a server may wish to have only N socket connections at any
      point    in   time.  As  soon    as  N  connections  are    made,    the  server   will
      not accept another incoming connection until an existing connection
      is released. Explain how semaphores can be used by a server to limit the
      number of concurrent connections.
5.22  Windows Vista provides a lightweight synchronization tool called slim
      reader­writer locks. Whereas most implementations of reader­writer
      locks favor either readers or writers, or perhaps order waiting threads
      using a FIFO policy, slim reader­writer locks favor neither readers nor
      writers, nor are waiting threads ordered in a FIFO queue. Explain the
      benefits of providing such a synchronization tool.
5.23  Show how to implement the wait() and signal() semaphore oper-
      ations    in  multiprocessor         environments    using  the    test and set()
      instruction. The solution should exhibit minimal busy waiting.
5.24  Exercise 4.26 requires the parent thread to wait for the child thread to
      finish its execution before printing out the computed values. If we let the
      parent thread access the Fibonacci numbers as soon as they have been
      computed by the child thread --rather than waiting for the child thread
      to terminate--what changes would be necessary to the solution for this
      exercise? Implement your modified solution.
5.25  Demonstrate       that   monitors    and  semaphores       are  equivalent    insofar
      as  they     can  be  used   to  implement  solutions       to  the  same   types  of
      synchronization problems.
5.26  Design an algorithm for a bounded-buffer monitor in which the buffers
      (portions) are embedded within the monitor itself.
5.27  The strict mutual exclusion within a monitor makes the bounded-buffer
      monitor of Exercise 5.26 mainly suitable for small portions.
      a.     Explain why this is true.
      b.     Design a new scheme that is suitable for larger portions.
5.28  Discuss the tradeoff between fairness and throughput of operations
      in  the   readers ­ writers    problem.   Propose    a  method       for  solving  the
      readers­writers problem without causing starvation.



248  Chapter 5  Process Synchronization
     5.29  How does the signal() operation associated with monitors differ from
           the corresponding operation defined for semaphores?
     5.30  Suppose the signal() statement can appear only as the last statement
           in a monitor function. Suggest how the implementation described in
           Section 5.8 can be simplified in this situation.
     5.31  Consider a system consisting of processes P1, P2, ..., Pn, each of which has
           a unique priority number. Write a monitor that allocates three identical
           printers to these processes, using the priority numbers for deciding the
           order of allocation.
     5.32  A file is to be shared among different processes, each of which has
           a unique number. The file can be accessed simultaneously by several
           processes, subject to the following constraint: the sum of all unique
           numbers associated with all the processes currently accessing the file
           must be less than n. Write a monitor to coordinate access to the file.
     5.33  When a signal is performed on a condition inside a monitor, the signaling
           process can either continue its execution or transfer control to the process
           that is signaled. How would the solution to the preceding exercise differ
           with these two different ways in which signaling can be performed?
     5.34  Suppose we replace the wait() and signal() operations of moni-
           tors with a single construct await(B), where B is a general Boolean
           expression that causes the process executing it to wait until B becomes
           true.
           a.     Write a monitor using this scheme to implement the readers­
                  writers problem.
           b.     Explain why, in general, this construct cannot be implemented
                  efficiently.
           c.     What restrictions need to be put on the await statement so that it
                  can be implemented efficiently? (Hint: Restrict the generality of B;
                  see [Kessels (1977)].)
     5.35  Design an algorithm for a monitor that implements an alarm clock that
           enables a calling program to delay itself for a specified number of time
           units (ticks). You may assume the existence of a real hardware clock that
           invokes a function tick() in your monitor at regular intervals.
Programming Problems
     5.36  Programming Exercise 3.20 required you to design a PID manager that
           allocated  a  unique     process  identifier  to  each  process.  Exercise  4.20
           required you to modify your solution to Exercise 3.20 by writing a
           program that created a number of threads that requested and released
           process    identifiers.  Now   modify  your   solution  to  Exercise  4.20    by
           ensuring that the data structure used to represent the availability of
           process identifiers is safe from race conditions. Use Pthreads mutex
           locks, described in Section 5.9.4.



                                                     Programming Problems          249
5.37  Assume that a finite number of resources of a single resource type must
      be managed. Processes may ask for a number of these resources and will
      return them once finished. As an example, many commercial software
      packages provide a given number of licenses, indicating the number of
      applications that may run concurrently. When the application is started,
      the license count is decremented. When the application is terminated, the
      license count is incremented. If all licenses are in use, requests to start
      the application are denied. Such requests will only be granted when
      an existing license holder terminates the application and a license is
      returned.
          The following program segment is used to manage a finite number of
      instances of an available resource. The maximum number of resources
      and the number of available resources are declared as follows:
                 #define     MAX  RESOURCES   5
                 int  available resources         =  MAX RESOURCES;
      When a process wishes to obtain a number of resources, it invokes the
      decrease count() function:
          /*  decrease       available  resources    by      count  resources   */
          /*  return     0   if   sufficient  resources      available,     */
          /*  otherwise      return  -1  */
          int decrease count(int count) {
              if (available resources < count)
                    return   -1;
              else    {
                    available resources       -=  count;
                    return   0;
              }
          }
      When a process wants to return a number of resources, it              calls  the
      increase count() function:
                 /*  increase     available resources        by  count  */
                 int increase count(int count) {
                     available resources      +=     count;
                     return  0;
                 }
      The preceding program segment produces a race condition. Do the
      following:
      a.      Identify the data involved in the race condition.
      b.      Identify the location (or locations) in the code where the race
              condition occurs.



250  Chapter 5  Process Synchronization
           c.   Using a semaphore or mutex lock, fix the race condition. It is
                permissible to modify the decrease count() function so that the
                calling process is blocked until sufficient resources are available.
     5.38  The  decrease   count()     function  in  the  previous  exercise  currently
           returns 0 if sufficient resources are available and -1 otherwise. This
           leads to awkward programming for a process that wishes to obtain a
           number of resources:
                    while  (decrease count(count)         ==  -1)
                       ;
           Rewrite   the   resource-manager  code    segment  using  a  monitor       and
           condition variables so that the decrease count() function suspends
           the process until sufficient resources are available. This will allow a
           process to invoke decrease count() by simply calling
                    decrease count(count);
           The process will return from this function call only when sufficient
           resources are available.
     5.39  Exercise 4.22 asked you to design a multithreaded program that esti-
           mated  using the Monte Carlo technique. In that exercise, you were
           asked to create a single thread that generated random points, storing
           the result in a global variable. Once that thread exited, the parent thread
           performed the calcuation that estimated the value of . Modify that
           program so that you create several threads, each of which generates
           random points and determines if the points fall within the circle. Each
           thread will have to update the global count of all points that fall within
           the circle. Protect against race conditions on updates to the shared global
           variable by using mutex locks.
     5.40  Exercise  4.23  asked  you  to   design   a  program  using  OpenMP        that
           estimated  using the Monte Carlo technique. Examine your solution to
           that program looking for any possible race conditions. If you identify a
           race condition, protect against it using the strategy outlined in Section
           5.10.2.
     5.41  A barrier is a tool for synchronizing the activity of a number of threads.
           When a thread reaches a barrier point, it cannot proceed until all other
           threads have reached this point as well. When the last thread reaches
           the barrier point, all threads are released and can resume concurrent
           execution.
           Assume that the barrier is initialized to N --the number of threads that
           must wait at the barrier point:
                    init(N);
           Each thread then performs some work until it reaches the barrier point:



                                                 Programming Projects                251
        /*  do  some     work   for      awhile  */
        barrier point();
        /*  do  some     work   for      awhile  */
Using synchronization tools described in this chapter, construct a barrier
that implements the following API:
·  int  init(int         n)--Initializes the barrier to the specified size.
·  int  barrier          point(void) -- Identifies   the  barrier   point.           All
   threads are released from the barrier when the last thread reaches
   this point.
The return value of each function is used to identify error conditions.
Each function will return 0 under normal operation and will return
-1 if an error occurs. A testing harness is provided in the source code
download to test your implementation of the barrier.
Programming Projects
Project 1 --The Sleeping Teaching Assistant
A university computer science department has a teaching assistant (TA) who
helps undergraduate students with their programming assignments during
regular office hours. The TA's office is rather small and has room for only one
desk with a chair and computer. There are three chairs in the hallway outside
the office where students can sit and wait if the TA is currently helping another
student. When there are no students who need help during office hours, the
TA sits at the desk and takes a nap. If a student arrives during office hours
and finds the TA sleeping, the student must awaken the TA to ask for help. If a
student arrives and finds the TA currently helping another student, the student
sits on one of the chairs in the hallway and waits. If no chairs are available, the
student will come back at a later time.
Using POSIX threads, mutex locks, and semaphores, implement a solution
that coordinates the activities of the TA and the students. Details for this
assignment are provided below.
The Students and the TA
Using Pthreads (Section 4.4.1), begin by creating n students. Each will run as a
separate thread. The TA will run as a separate thread as well. Student threads
will alternate between programming for a period of time and seeking help
from the TA. If the TA is available, they will obtain help. Otherwise, they will
either sit in a chair in the hallway or, if no chairs are available, will resume
programming and will seek help at a later time. If a student arrives and notices
that the TA is sleeping, the student must notify the TA using a semaphore. When
the TA finishes helping a student, the TA must check to see if there are students
waiting for help in the hallway. If so, the TA must help each of these students
in turn. If no students are present, the TA may return to napping.



252  Chapter 5  Process Synchronization
     Perhaps the best option for simulating students programming--as well as
     the TA providing help to a student--is to have the appropriate threads sleep
     for a random period of time.
     POSIX Synchronization
     Coverage of POSIX mutex locks and semaphores is provided in Section 5.9.4.
     Consult that section for details.
     Project 2 --The Dining Philosophers Problem
     In Section 5.7.3, we provide an outline of a solution to the dining-philosophers
     problem using monitors. This problem will require implementing a solution
     using Pthreads mutex locks and condition variables.
     The Philosophers
     Begin by creating five philosophers, each identified by a number 0 . . 4. Each
     philosopher will run as a separate thread. Thread creation using Pthreads is
     covered in Section 4.4.1. Philosophers alternate between thinking and eating.
     To simulate both activities, have the thread sleep for a random period between
     one and three seconds. When a philosopher wishes to eat, she invokes the
     function
     pickup     forks(int     philosopher  number)
     where philosopher number identifies the number of the philosopher wishing
     to eat. When a philosopher finishes eating, she invokes
     return     forks(int     philosopher  number)
     Pthreads Condition Variables
     Condition variables in Pthreads behave similarly to those described in Section
     5.8. However, in that section, condition variables are used within the context
     of a monitor, which provides a locking mechanism to ensure data integrity.
     Since Pthreads is typically used in C programs--and since C does not have
     a monitor-- we accomplish locking by associating a condition variable with
     a mutex lock. Pthreads mutex locks are covered in Section 5.9.4. We cover
     Pthreads condition variables here.
     Condition variables in Pthreads use the pthread cond t data type and
     are initialized using the pthread cond init() function. The following code
     creates and initializes a condition variable as well as its associated mutex lock:
     pthread mutex t mutex;
     pthread cond          t  cond var;
     pthread mutex init(&mutex,NULL);
     pthread cond init(&cond var,NULL);



                                                   Programming Projects              253
      The pthread cond wait() function is used for waiting on a condition
variable. The following code illustrates how a thread can wait for the condition
a  ==    b to become true using a Pthread condition variable:
         pthread mutex lock(&mutex);
         while   (a  !=    b)
                pthread cond wait(&mutex,          &cond  var);
         pthread mutex unlock(&mutex);
      The mutex lock associated with the condition variable must be locked
before the pthread cond wait() function is called, since it is used to protect
the data in the conditional clause from a possible race condition. Once this
lock is acquired, the thread can check the condition. If the condition is not true,
the thread then invokes pthread cond wait(), passing the mutex lock and
the condition variable as parameters. Calling pthread cond wait() releases
the mutex lock, thereby allowing another thread to access the shared data and
possibly update its value so that the condition clause evaluates to true. (To
protect against program errors, it is important to place the conditional clause
within a loop so that the condition is rechecked after being signaled.)
      A  thread      that  modifies       the  shared  data    can  invoke           the
pthread cond signal()          function,  thereby  signaling   one  thread  waiting
on the condition variable. This is illustrated below:
         pthread mutex lock(&mutex);
         a = b;
         pthread cond signal(&cond var);
         pthread mutex unlock(&mutex);
      It is important to note that the call to pthread cond signal() does not
release the mutex lock. It is the subsequent call to pthread mutex unlock()
that releases the mutex. Once the mutex lock is released, the signaled thread
becomes the owner of the mutex lock and returns control from the call to
pthread cond wait().
Project 3 --Producer ­ Consumer Problem
In Section 5.7.1, we presented a semaphore-based solution to the producer­
consumer problem using a bounded buffer. In this project, you will design a
programming solution to the bounded-buffer problem using the producer and
consumer processes shown in Figures 5.9 and 5.10. The solution presented in
Section 5.7.1 uses three semaphores: empty and full, which count the number
of empty and full slots in the buffer, and mutex, which is a binary (or mutual-
exclusion) semaphore that protects the actual insertion or removal of items
in the buffer. For this project, you will use standard counting semaphores for
empty and full and a mutex lock, rather than a binary semaphore, to represent
mutex. The producer and consumer--running as separate threads--will move
items to and from a buffer that is synchronized with the empty, full, and mutex
structures. You can solve this problem using either Pthreads or the Windows
API.



254  Chapter 5    Process Synchronization
                  #include     "buffer.h"
                  /*  the      buffer  */
                  buffer item buffer[BUFFER SIZE];
                  int insert item(buffer item item) {
                      /*   insert  item     into  buffer
                      return   0   if  successful,          otherwise
                      return   -1      indicating      an   error   condition      */
                  }
                  int remove item(buffer item               *item)  {
                      /*   remove  an  object     from      buffer
                      placing      it  in   item
                      return   0   if  successful,          otherwise
                      return   -1      indicating      an   error condition        */
                  }
                               Figure 5.24  Outline of buffer operations.
     The Buffer
     Internally, the buffer will consist of a fixed-size array of type buffer item
     (which will be defined using a typedef). The array of buffer item objects
     will be manipulated as a circular queue. The definition of buffer item, along
     with the size of the buffer, can be stored in a header file such as the following:
          /* buffer.h */
          typedef int buffer item;
          #define BUFFER SIZE 5
     The  buffer     will  be  manipulated       with  two  functions,     insert  item()  and
     remove item(), which are called by the producer and consumer threads,
     respectively. A skeleton outlining these functions appears in Figure 5.24.
          The insert item() and remove item() functions will synchronize the
     producer and consumer using the algorithms outlined in Figures 5.9 and
     5.10. The buffer will also require an initialization function that initializes the
     mutual-exclusion object mutex along with the empty and full semaphores.
          The main() function will initialize the buffer and create the separate
     producer   and   consumer         threads.  Once  it   has  created   the  producer   and
     consumer threads, the main() function will sleep for a period of time and,
     upon awakening, will terminate the application. The main() function will be
     passed three parameters on the command line:
     1.   How long to sleep before terminating
     2.   The number of producer threads
     3.   The number of consumer threads



                                                      Programming Projects         255
#include "buffer.h"
int    main(int argc, char *argv[]) {
   /*  1.  Get     command  line    arguments  argv[1],argv[2],argv[3]             */
   /*  2.  Initialize       buffer  */
   /*  3.  Create      producer     thread(s)  */
   /*  4.  Create      consumer     thread(s)  */
   /*  5.  Sleep   */
   /*  6.  Exit    */
}
                       Figure 5.25  Outline of skeleton program.
A skeleton for this function appears in Figure 5.25.
The Producer and Consumer Threads
The producer thread will alternate between sleeping for a random period of
time and inserting a random integer into the buffer. Random numbers will
be produced using the rand() function, which produces random integers
between 0 and RAND MAX. The consumer will also sleep for a random period
of time and, upon awakening, will attempt to remove an item from the buffer.
An outline of the producer and consumer threads appears in Figure 5.26.
   As noted earlier, you can solve this problem using either Pthreads or the
Windows API. In the following sections, we supply more information on each
of these choices.
Pthreads Thread Creation and Synchronization
Creating threads using the Pthreads API is discussed in Section 4.4.1. Coverage
of mutex locks and semaphores using Pthreads is provided in Section 5.9.4.
Refer to those sections for specific instructions on Pthreads thread creation and
synchronization.
Windows
Section 4.4.2 discusses thread creation using the Windows API. Refer to that
section for specific instructions on creating threads.
Windows Mutex Locks
Mutex locks are a type of dispatcher object, as described in Section 5.9.1. The
following illustrates how to create a mutex lock using the CreateMutex()
function:
           #include <windows.h>
           HANDLE  Mutex;
           Mutex = CreateMutex(NULL,           FALSE,   NULL);



256  Chapter  5  Process Synchronization
              #include    <stdlib.h>          /*  required     for  rand()  */
              #include    "buffer.h"
              void  *producer(void            *param)  {
                 buffer   item  item;
                 while (true) {
                    /*  sleep   for        a  random   period  of   time  */
                    sleep(...);
                    /*  generate     a        random  number   */
                    item = rand();
                    if (insert item(item))
                        fprintf("report error condition");
                    else
                        printf("producer produced %d\n",item);
              }
              void  *consumer(void            *param)  {
                 buffer   item  item;
                 while (true) {
                    /*  sleep   for        a  random   period  of   time  */
                    sleep(...);
                    if (remove item(&item))
                        fprintf("report error condition");
                    else
                        printf("consumer consumed %d\n",item);
              }
                 Figure 5.26  An outline of the producer and consumer threads.
     The first parameter refers to a security attribute for the mutex lock. By setting
     this attribute to NULL, we disallow any children of the process creating this
     mutex lock to inherit the handle of the lock. The second parameter indicates
     whether the creator of the mutex lock is the lock's initial owner. Passing a value
     of FALSE indicates that the thread creating the mutex is not the initial owner.
     (We shall soon see how mutex locks are acquired.) The third parameter allows
     us to name the mutex. However, because we provide a value of NULL, we do
     not name the mutex. If successful, CreateMutex() returns a HANDLE to the
     mutex lock; otherwise, it returns NULL.
     In Section 5.9.1, we identified dispatcher objects as being either signaled or
     nonsignaled. A signaled dispatcher object (such as a mutex lock) is available
     for ownership. Once it is acquired, it moves to the nonsignaled state. When it
     is released, it returns to signaled.
     Mutex locks are acquired by invoking the WaitForSingleObject() func-
     tion. The function is passed the HANDLE to the lock along with a flag indicating
     how long to wait. The following code demonstrates how the mutex lock created
     above can be acquired:
              WaitForSingleObject(Mutex,               INFINITE);



                                           Programming Projects                   257
The parameter value INFINITE indicates that we will wait an infinite amount
of time for the lock to become available. Other values could be used that would
allow the calling thread to time out if the lock did not become available within
a specified time. If the lock is in a signaled state, WaitForSingleObject()
returns immediately, and the lock becomes nonsignaled. A lock is released
(moves to the signaled state) by invoking ReleaseMutex()--for example, as
follows:
          ReleaseMutex(Mutex);
Windows Semaphores
Semaphores in the Windows API are dispatcher objects and thus use the same
signaling mechanism as mutex locks. Semaphores are created as follows:
          #include <windows.h>
          HANDLE     Sem;
          Sem = CreateSemaphore(NULL,  1,  5,  NULL);
The first and last parameters identify a security attribute and a name for the
semaphore, similar to what we described for mutex locks. The second and third
parameters indicate the initial value and maximum value of the semaphore. In
this instance, the initial value of the semaphore is 1, and its maximum value
is 5. If successful, CreateSemaphore() returns a HANDLE to the mutex lock;
otherwise, it returns NULL.
    Semaphores are acquired with the same WaitForSingleObject() func-
tion as mutex locks. We acquire the semaphore Sem created in this example by
using the following statement:
          WaitForSingleObject(Semaphore, INFINITE);
If the value of the semaphore is > 0, the semaphore is in the signaled state
and thus is acquired by the calling thread. Otherwise, the calling thread blocks
indefinitely--as we are specifying INFINITE--until the semaphore returns to
the signaled state.
    The equivalent of the signal() operation for Windows semaphores is the
ReleaseSemaphore() function. This function is passed three parameters:
1.  The HANDLE of the semaphore
2.  How much to increase the value of the semaphore
3.  A pointer to the previous value of the semaphore
We can use the following statement to increase Sem by 1:
          ReleaseSemaphore(Sem,  1,  NULL);
Both ReleaseSemaphore() and ReleaseMutex() return a nonzero value if
successful and 0 otherwise.



258  Chapter 5     Process Synchronization
Bibliographical Notes
     The  mutual-exclusion         problem    was  first  discussed    in  a  classic  paper  by
     [Dijkstra (1965)]. Dekker's algorithm (Exercise 5.8)--the first correct software
     solution to the two-process mutual-exclusion problem--was developed by the
     Dutch mathematician T. Dekker. This algorithm also was discussed by [Dijkstra
     (1965)]. A simpler solution to the two-process mutual-exclusion problem has
     since been presented by [Peterson (1981)] (Figure 5.2). The semaphore concept
     was suggested by [Dijkstra (1965)].
          The classic process-coordination problems that we have described are
     paradigms for a large class of concurrency-control problems. The bounded-
     buffer  problem       and  the  dining-philosophers        problem    were  suggested    in
     [Dijkstra    (1965)]  and     [Dijkstra  (1971)].  The  readers ­ writers   problem      was
     suggested by [Courtois et al. (1971)].
          The     critical-region    concept  was       suggested  by    [Hoare  (1972)]      and
     by   [Brinch-Hansen        (1972)].      The  monitor   concept       was  developed     by
     [Brinch-Hansen        (1973)].  [Hoare   (1974)]     gave  a  complete      description  of
     the monitor.
          Some details of the locking mechanisms used in Solaris were presented
     in [Mauro and McDougall (2007)]. As noted earlier, the locking mechanisms
     used by the kernel are implemented for user-level threads as well, so the same
     types of locks are available inside and outside the kernel. Details of Windows
     2000 synchronization can be found in [Solomon and Russinovich (2000)]. [Love
     (2010)] describes synchronization in the Linux kernel.
          Information on Pthreads programming can be found in [Lewis and Berg
     (1998)] and [Butenhof (1997)]. [Hart (2005)] describes thread synchronization
     using Windows. [Goetz et al. (2006)] present a detailed discussion of concur-
     rent programming in Java as well as the java.util.concurrent package.
     [Breshears (2009)] and [Pacheco (2011)] provide detailed coverage of synchro-
     nization issues in relation to parallel programming. [Lu et al. (2008)] provide a
     study of concurrency bugs in real-world applications.
          [Adl-Tabatabai et al. (2007)] discuss transactional memory. Details on using
     OpenMP can be found at http://openmp.org. Functional programming using
     Erlang and Scala is covered in [Armstrong (2007)] and [Odersky et al. ()]
     respectively.
Bibliography
     [Adl-Tabatabai et al. (2007)]        A.-R. Adl-Tabatabai, C. Kozyrakis, and B. Saha,
         "Unlocking Concurrency", Queue, Volume 4, Number 10 (2007), pages 24­33.
     [Armstrong (2007)]         J. Armstrong, Programming Erlang Software for a Concurrent
         World, The Pragmatic Bookshelf (2007).
     [Breshears (2009)]    C. Breshears, The Art of Concurrency, O'Reilly & Associates
         (2009).
     [Brinch-Hansen (1972)]          P.  Brinch-Hansen,     "Structured    Multiprogramming",
         Communications of the ACM, Volume 15, Number 7 (1972), pages 574­578.



                                                              Bibliography              259
[Brinch-Hansen (1973)]     P. Brinch-Hansen, Operating System Principles, Prentice
Hall (1973).
[Butenhof (1997)]      D.  Butenhof,  Programming  with  POSIX  Threads,  Addison-
Wesley (1997).
[Courtois et al. (1971)]   P. J. Courtois, F. Heymans, and D. L. Parnas, "Concurrent
Control with `Readers' and `Writers'", Communications of the ACM, Volume 14,
Number 10 (1971), pages 667­668.
[Dijkstra (1965)]      E. W. Dijkstra, "Cooperating Sequential Processes", Technical
report, Technological University, Eindhoven, the Netherlands (1965).
[Dijkstra (1971)]      E. W. Dijkstra, "Hierarchical Ordering of Sequential Processes",
Acta Informatica, Volume 1, Number 2 (1971), pages 115­138.
[Goetz et al. (2006)]     B. Goetz, T. Peirls, J. Bloch, J. Bowbeer, D. Holmes, and
D. Lea, Java Concurrency in Practice, Addison-Wesley (2006).
[Hart (2005)]       J. M. Hart, Windows System Programming, Third Edition, Addison-
Wesley (2005).
[Hoare (1972)]       C. A. R. Hoare, "Towards a Theory of Parallel Programming", in
[Hoare and Perrott 1972] (1972), pages 61­71.
[Hoare (1974)]       C. A. R. Hoare, "Monitors: An Operating System Structuring
Concept", Communications of the ACM, Volume 17, Number 10 (1974), pages
549­557.
[Kessels (1977)]       J. L. W. Kessels, "An Alternative to Event Queues for Synchro-
nization in Monitors", Communications of the ACM, Volume 20, Number 7 (1977),
pages 500­503.
[Lewis and Berg (1998)]    B. Lewis and D. Berg, Multithreaded Programming with
Pthreads, Sun Microsystems Press (1998).
[Love (2010)]       R. Love, Linux Kernel Development, Third Edition, Developer's
Library (2010).
[Lu et al. (2008)]     S. Lu, S. Park, E. Seo, and Y. Zhou, "Learning from mistakes: a
comprehensive study on real world concurrency bug characteristics", SIGPLAN
Notices, Volume 43, Number 3 (2008), pages 329­339.
[Mauro and McDougall (2007)]          J. Mauro and R. McDougall, Solaris Internals:
Core Kernel Architecture, Prentice Hall (2007).
[Odersky et al. ()]    M. Odersky, V. Cremet, I. Dragos, G. Dubochet, B. Emir,
S. Mcdirmid, S. Micheloud, N. Mihaylov, M. Schinz, E. Stenman, L. Spoon,
and M. Zenger.
[Pacheco (2011)]       P. S. Pacheco, An Introduction to Parallel Programming, Morgan
Kaufmann (2011).
[Peterson (1981)]      G. L. Peterson, "Myths About the Mutual Exclusion Problem",
Information Processing Letters, Volume 12, Number 3 (1981).
[Solomon and Russinovich (2000)]      D. A. Solomon and M. E. Russinovich, Inside
Microsoft Windows 2000, Third Edition, Microsoft Press (2000).



