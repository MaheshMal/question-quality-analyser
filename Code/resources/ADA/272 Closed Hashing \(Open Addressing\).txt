in closed hashing all keys are stored in the hash table itself without the use of linked lists. of course this implies that the table size m must be at least as large as the number of keys n. different strategies can be employed for collision resolution. the simplest one called linear probing checks the cell following the one where the collision occurs. if that cell is empty the new key is installed there if the next cell is already occupied the availability of that cell's immediate successor is checked and so on. note that if the end of the hash table is reached the search is wrapped to the beginning of the table i.e. it is treated as a circular array. this method is illustrated in figure . with the same word list and hash function used above to illustrate separate chaining. to search for a given key k we start by computing h k where h is the hash function used in the table construction. if the cell h k is empty the search is unsuccessful. if the cell is not empty we must compare k with the cell's occupant if they are equal we have found a matching key if they are not we compare k with a key in the next cell and continue in this manner until we encounter either a matching key a successful search or an empty cell unsuccessful search . for example if we search for the word lit in the table of figure . we will get h lit mod and since cell is empty we can stop immediately. however if we search for kid with h kid mod we will have to compare kid with are soon parted and a before we can declare the search unsuccessful. although the search and insertion operations are straightforward for this version of hashing deletion is not. for example if we simply delete the key are from the last state of the hash table in figure . we will be unable to find the key soon afterward. indeed after computing h soon the algorithm would find this location empty and report the unsuccessful search result. a simple solution keys a fool and his money are soon parted hash addresses a a fool a and fool a and fool his a and money fool his a and money fool his are a and money fool his are soon parted a and money fool his are soon figure . example of a hash table construction with linear probing. is to use lazy deletion i.e. to mark previously occupied locations by a special symbol to distinguish them from locations that have not been occupied. the mathematical analysis of linear probing is a much more difficult problem than that of separate chaining. the simplified versions of these results state that the average number of times the algorithm must access the hash table with the load factor in successful and unsuccessful searches is respectively s and u . and the accuracy of these approximations increases with larger sizes of the hash table . these numbers are surprisingly small even for densely populated tables i.e. for large percentage values of . . . . . . still as the hash table gets closer to being full the performance of linear probing deteriorates because of a phenomenon called clustering. a cluster in linear probing is a sequence of contiguously occupied cells with a possible wrapping . for example the final state of the hash table of figure . has two clusters. clusters are bad news in hashing because they make the dictionary operations less efficient. as clusters become larger the probability that a new element will be attached to a cluster increases in addition large clusters increase the probability that two clusters will coalesce after a new key's insertion causing even more clustering. several other collision resolution strategies have been suggested to alleviate this problem. one of the most important is double hashing. under this scheme we use another hash function s k to determine a fixed increment for the probing sequence to be used after a collision at location l h k l s k mod m l s k mod m ... . . to guarantee that every location in the table is probed by sequence . the increment s k and the table size m must be relatively prime i.e. their only common divisor must be . this condition is satisfied automatically if m itself is prime. some functions recommended in the literature are s k m k mod m and s k k mod for small tables and s k k mod for larger ones. . this problem was solved in by a young graduate student in mathematics named donald e. knuth. knuth went on to become one of the most important computer scientists of our time. his multivolume treatise the art of computer programming knui knuii knuiii knuiv remains the most comprehensive and influential book on algorithmics ever published. mathematical analysis of double hashing has proved to be quite difficult. some partial results and considerable practical experience with the method suggest that with good hashing functions both primary and secondary double hashing is superior to linear probing. but its performance also deteriorates when the table gets close to being full. a natural solution in such a situation is rehashing the current table is scanned and all its keys are relocated into a larger table. it is worthwhile to compare the main properties of hashing with balanced search trees its principal competitor for implementing dictionaries. asymptotic time efficiency with hashing searching insertion and deletion can be implemented to take time on the average but n time in the very unlikely worst case. for balanced search trees the average time efficiencies are log n for both the average and worst cases. ordering preservation unlike balanced search trees hashing does not assume existence of key ordering and usually does not preserve it. this makes hashing less suitable for applications that need to iterate over the keys in order or require range queries such as counting the number of keys between some lower and upper bounds. since its discovery in the s by ibm researchers hashing has found many important applications. in particular it has become a standard technique for storing a symbol table a table of a computer program's symbols generated during compilation. hashing is quite handy for such ai applications as checking whether positions generated by a chess playing computer program have already been considered. with some modifications it has also proved to be useful for storing very large dictionaries on disks this variation of hashing is called extendible hashing. since disk access is expensive compared with probes performed in the main memory it is preferable to make many more probes than disk accesses. accordingly a location computed by a hash function in extendible hashing indicates a disk address of a bucket that can hold up to b keys. when a key's bucket is identified all its keys are read into main memory and then searched for the key in question. in the next section we discuss b trees a principal alternative for storing large dictionaries. exercises . . for the input and hash function h k k mod a. construct the open hash table. b. find the largest number of key comparisons in a successful search in this table. c. find the average number of key comparisons in a successful search in this table. . for the input and hash function h k k mod a. construct the closed hash table. b. find the largest number of key comparisons in a successful search in this table. c. find the average number of key comparisons in a successful search in this table. . why is it not a good idea for a hash function to depend on just one letter say the first one of a natural language word? . find the probability of all n keys being hashed to the same cell of a hash table of size m if the hash function distributes keys evenly among all the cells of the table. . birthday paradox the birthday paradox asks how many people should be in a room so that the chances are better than even that two of them will have the same birthday month and day . find the quite unexpected answer to this problem. what implication for hashing does this result have? . answer the following questions for the separate chaining version of hashing. a. where would you insert keys if you knew that all the keys in the dictionary are distinct? which dictionary operations if any would benefit from this modification? b. we could keep keys of the same linked list sorted. which of the dictionary operations would benefit from this modification? how could we take advantage of this if all the keys stored in the entire table need to be sorted? . explain how to use hashing to check whether all elements of a list are distinct. what is the time efficiency of this application? compare its efficiency with that of the brute force algorithm section . and of the presorting based algorithm section . . . fill in the following table with the average case as the first entry and worstcase as the second entry efficiency classes for the five implementations of the adt dictionary unordered ordered binary balanced array array search tree search tree hashing search insertion deletion . we have discussed hashing in the context of techniques based on space time trade offs. but it also takes advantage of another general strategy. which one? . write a computer program that uses hashing for the following problem. given a natural language text generate a list of distinct words with the number of occurrences of each word in the text. insert appropriate counters in the program to compare the empirical efficiency of hashing with the corresponding theoretical results. p k p .. . pi ki pi ... pn kn pn t t ti ti tn tn figure . parental node of a b tree. 