quicksort is the other important sorting algorithm that is based on the divide andconquer approach. unlike mergesort which divides its input elements according to their position in the array quicksort divides them according to their value. we already encountered this idea of an array partition in section . where we discussed the selection problem. a partition is an arrangement of the array's elements so that all the elements to the left of some element a s are less than or equal to a s and all the elements to the right of a s are greater than or equal to it a . . . a s a s a s . . . a n all are a s all are a s obviously after a partition is achieved a s will be in its final position in the sorted array and we can continue sorting the two subarrays to the left and to the right of a s independently e.g. by the same method . note the difference with mergesort there the division of the problem into two subproblems is immediate and the entire work happens in combining their solutions here the entire work happens in the division stage with no work required to combine the solutions to the subproblems. here is pseudocode of quicksort call quicksort a ..n where algorithm quicksort a l ..r sorts a subarray by quicksort input subarray of array a ..n defined by its left and right indices l and r output subarray a l..r sorted in nondecreasing order if l r s partition a l..r s is a split position quicksort a l..s quicksort a s ..r as a partition algorithm we can certainly use the lomuto partition discussed in section . . alternatively we can partition a ..n and more generally its subarray a l..r l r n by the more sophisticated method suggested by c.a.r. hoare the prominent british computer scientist who invented quicksort. . c.a.r. hoare at age invented his algorithm in while trying to sort words for a machine translation project from russian to english. says hoare my first thought on how to do this was bubblesort and by an amazing stroke of luck my second thought was quicksort. it is hard to disagree with his overall assessment i have been very lucky. what a wonderful way to start a career in computing by discovering a new sorting algorithm! hoa . twenty years later he received the turing award for fundamental contributions to the definition and design of programming languages in he was also knighted for services to education and computer science. as before we start by selecting a pivot an element with respect to whose value we are going to divide the subarray. there are several different strategies for selecting a pivot we will return to this issue when we analyze the algorithm's efficiency. for now we use the simplest strategy of selecting the subarray's first element p a l . unlike the lomuto algorithm we will now scan the subarray from both ends comparing the subarray's elements to the pivot. the left to right scan denoted below by index pointer i starts with the second element. since we want elements smaller than the pivot to be in the left part of the subarray this scan skips over elements that are smaller than the pivot and stops upon encountering the first element greater than or equal to the pivot. the right to left scan denoted below by index pointer j starts with the last element of the subarray. since we want elements larger than the pivot to be in the right part of the subarray this scan skips over elements that are larger than the pivot and stops on encountering the first element smaller than or equal to the pivot. why is it worth stopping the scans after encountering an element equal to the pivot? because doing this tends to yield more even splits for arrays with a lot of duplicates which makes the algorithm run faster. for example if we did otherwise for an array of n equal elements we would have gotten a split into subarrays of sizes n and reducing the problem size just by after scanning the entire array. after both scans stop three situations may arise depending on whether or not the scanning indices have crossed. if scanning indices i and j have not crossed i.e. i j we simply exchange a i and a j and resume the scans by incrementing i and decrementing j respectively i j p all are p p ... p all are p if the scanning indices have crossed over i.e. i j we will have partitioned the subarray after exchanging the pivot with a j j i p all are p p p all are p finally if the scanning indices stop while pointing to the same element i.e. i j the value they are pointing to must be equal to p why? . thus we have the subarray partitioned with the split position s i j j i p all are p p all are p we can combine the last case with the case of crossed over indices i j by exchanging the pivot with a j whenever i j . here is pseudocode implementing this partitioning procedure. algorithm hoarepartition a l ..r partitions a subarray by hoare's algorithm using the first element as a pivot input subarray of array a ..n defined by its left and right indices l and r l r output partition of a l..r with the split position returned as this function's value p a l i l j r repeat repeat i i until a i p repeat j j until a j p swap a i a j until i j swap a i a j undo last swap when i j swap a l a j return j note that index i can go out of the subarray's bounds in this pseudocode. rather than checking for this possibility every time index i is incremented we can append to array a ..n a sentinel that would prevent index i from advancing beyond position n. note that the more sophisticated method of pivot selection mentioned at the end of the section makes such a sentinel unnecessary. an example of sorting an array by quicksort is given in figure . . we start our discussion of quicksort's efficiency by noting that the number of key comparisons made before a partition is achieved is n if the scanning indices cross over and n if they coincide why? . if all the splits happen in the middle of corresponding subarrays we will have the best case. the number of key comparisons in the best case satisfies the recurrence cbest n cbest n n for n cbest . according to the master theorem cbest n n log n solving it exactly for n k yields cbest n n log n. in the worst case all the splits will be skewed to the extreme one of the two subarrays will be empty and the size of the other will be just less than the size of the subarray being partitioned. this unfortunate situation will happen in particular for increasing arrays i.e. for inputs for which the problem is already solved! indeed if a ..n is a strictly increasing array and we use a as the pivot the left to right scan will stop on a while the right to left scan will go all the way to reach a indicating the split at position i j i j i j i j i j j i i j i r s i j i j i r i r s s j i i r i r i r i r ij s j i i r i r i j b i j j i a figure . example of quicksort operation. a array's transformations with pivots shown in bold. b tree of recursive calls to quicksort with input values l and r of subarray bounds and split position s of a partition obtained. j i a a . . . a n so after making n comparisons to get to this partition and exchanging the pivot a with itself the algorithm will be left with the strictly increasing array a ..n to sort. this sorting of strictly increasing arrays of diminishing sizes will continue until the last one a n ..n has been processed. the total number of key comparisons made will be equal to cworst n n n . . . n n n . thus the question about the utility of quicksort comes down to its averagecase behavior. let cavg n be the average number of key comparisons made by quicksort on a randomly ordered array of size n. a partition can happen in any position s s n after n comparisons are made to achieve the partition. after the partition the left and right subarrays will have s and n s elements respectively. assuming that the partition split can happen in each position s with the same probability n we get the following recurrence relation n cavg n n n cavg s cavg n s for n s cavg cavg . its solution which is much trickier than the worst and best case analyses turns out to be cavg n n ln n . n log n. thus on the average quicksort makes only more comparisons than in the best case. moreover its innermost loop is so efficient that it usually runs faster than mergesort and heapsort another n log n algorithm that we discuss in chapter on randomly ordered arrays of nontrivial sizes. this certainly justifies the name given to the algorithm by its inventor. because of quicksort's importance there have been persistent efforts over the years to refine the basic algorithm. among several improvements discovered by researchers are better pivot selection methods such as randomized quicksort that uses a random element or the median of three method that uses the median of the leftmost rightmost and the middle element of the array switching to insertion sort on very small subarrays between and elements for most computer systems or not sorting small subarrays at all and finishing the algorithm with insertion sort applied to the entire nearly sorted array modifications of the partitioning algorithm such as the three way partition into segments smaller than equal to and larger than the pivot see problem in this section's exercises according to robert sedgewick sed p. the world's leading expert on quicksort such improvements in combination can cut the running time of the algorithm by . like any sorting algorithm quicksort has weaknesses. it is not stable. it requires a stack to store parameters of subarrays that are yet to be sorted. while the size of this stack can be made to be in o log n by always sorting first the smaller of two subarrays obtained by partitioning it is worse than the o space efficiency of heapsort. although more sophisticated ways of choosing a pivot make the quadratic running time of the worst case very unlikely they do not eliminate it completely. and even the performance on randomly ordered arrays is known to be sensitive not only to implementation details of the algorithm but also to both computer architecture and data type. still the january february issue of computing in science engineering a joint publication of the american institute of physics and the ieee computer society selected quicksort as one of the algorithms with the greatest influence on the development and practice of science and engineering in the th century. exercises . . apply quicksort to sort the list e x a m p l e in alphabetical order. draw the tree of the recursive calls made. . for the partitioning procedure outlined in this section a. prove that if the scanning indices stop while pointing to the same element i.e. i j the value they are pointing to must be equal to p. b. prove that when the scanning indices stop j cannot point to an element more than one position to the left of the one pointed to by i. . give an example showing that quicksort is not a stable sorting algorithm. . give an example of an array of n elements for which the sentinel mentioned in the text is actually needed. what should be its value? also explain why a single sentinel suffices for any input. . for the version of quicksort given in this section a. are arrays made up of all equal elements the worst case input the bestcase input or neither? b. are strictly decreasing arrays the worst case input the best case input or neither? . a. for quicksort with the median of three pivot selection are strictly increasing arrays the worst case input the best case input or neither? b. answer the same question for strictly decreasing arrays. . a. estimate how many times faster quicksort will sort an array of one million random numbers than insertion sort. b. true or false for every n there are n element arrays that are sorted faster by insertion sort than by quicksort? . design an algorithm to rearrange elements of a given array of n real numbers so that all its negative elements precede all its positive elements. your algorithm should be both time efficient and space efficient. . a. the dutch national flag problem is to rearrange an array of characters r w and b red white and blue are the colors of the dutch national flag so that all the r's come first the w's come next and the b's come last. dij design a linear in place algorithm for this problem. b. explain how a solution to the dutch national flag problem can be used in quicksort. . implement quicksort in the language of your choice. run your program on a sample of inputs to verify the theoretical assertions about the algorithm's efficiency. . nuts and bolts you are given a collection of n bolts of different widths and n corresponding nuts. you are allowed to try a nut and bolt together from which you can determine whether the nut is larger than the bolt smaller than the bolt or matches the bolt exactly. however there is no way to compare two nuts together or two bolts together. the problem is to match each bolt to its nut. design an algorithm for this problem with average case efficiency in n log n . raw 