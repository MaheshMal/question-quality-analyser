i often say that when you can measure what you are speaking about and express it in numbers you know something about it but when you cannot express it in numbers your knowledge is a meagre and unsatisfactory kind it may be the beginning of knowledge but you have scarcely in your thoughts advanced to the stage of science whatever the matter may be. lord kelvin not everything that can be counted counts and not everything that counts can be counted. albert einstein this chapter is devoted to analysis of algorithms. the american heritage dictionary defines analysis as the separation of an intellectual or substantial whole into its constituent parts for individual study. accordingly each of the principal dimensions of an algorithm pointed out in section . is both a legitimate and desirable subject of study. but the term analysis of algorithms is usually used in a narrower technical sense to mean an investigation of an algorithm's efficiency with respect to two resources running time and memory space. this emphasis on efficiency is easy to explain. first unlike such dimensions as simplicity and generality efficiency can be studied in precise quantitative terms. second one can argue although this is hardly always the case given the speed and memory of today's computers that the efficiency considerations are of primary importance from a practical point of view. in this chapter we too will limit the discussion to an algorithm's efficiency. we start with a general framework for analyzing algorithm efficiency in section . . this section is arguably the most important in the chapter the fundamental nature of the topic makes it also one of the most important sections in the entire book. in section . we introduce three notations o big oh big omega and big theta . borrowed from mathematics these notations have become the language for discussing the efficiency of algorithms. in section . we show how the general framework outlined in section . can be systematically applied to analyzing the efficiency of nonrecursive algorithms. the main tool of such an analysis is setting up a sum representing the algorithm's running time and then simplifying the sum by using standard sum manipulation techniques. in section . we show how the general framework outlined in section . can be systematically applied to analyzing the efficiency of recursive algorithms. here the main tool is not a summation but a special kind of equation called a recurrence relation. we explain how such recurrence relations can be set up and then introduce a method for solving them. although we illustrate the analysis framework and the methods of its applications by a variety of examples in the first four sections of this chapter section . is devoted to yet another example that of the fibonacci numbers. discovered years ago this remarkable sequence appears in a variety of applications both within and outside computer science. a discussion of the fibonacci sequence serves as a natural vehicle for introducing an important class of recurrence relations not solvable by the method of section . . we also discuss several algorithms for computing the fibonacci numbers mostly for the sake of a few general observations about the efficiency of algorithms and methods of analyzing them. the methods of sections . and . provide a powerful technique for analyzing the efficiency of many algorithms with mathematical clarity and precision but these methods are far from being foolproof. the last two sections of the chapter deal with two approaches empirical analysis and algorithm visualization that complement the pure mathematical techniques of sections . and . . much newer and hence less developed than their mathematical counterparts these approaches promise to play an important role among the tools available for analysis of algorithm efficiency. 