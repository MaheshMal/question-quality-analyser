many problems of optimal decision making can be reduced to an instance of the linear programming problem a problem of optimizing a linear function of several variables subject to constraints in the form of linear equations and linear inequalities. example consider a university endowment that needs to invest million. this sum has to be split between three types of investments stocks bonds and cash. the endowment managers expect an annual return of and for their stock bond and cash investments respectively. since stocks are more risky than bonds the endowment rules require the amount invested in stocks to be no more than one third of the moneys invested in bonds. in addition at least of the total amount invested in stocks and bonds must be invested in cash. how should the managers invest the money to maximize the return? let us create a mathematical model of this problem. let x y and z be the amounts in millions of dollars invested in stocks bonds and cash respectively. by using these variables we can pose the following optimization problem maximize . x . y . z subject to x y z x y z . x y x y z . although this example is both small and simple it does show how a problem of optimal decision making can be reduced to an instance of the general linear programming problem maximize or minimize c x . . . cnxn subject to ai x . . . ainxn or or bi for i . . . m x . . . xn . the last group of constraints called the nonnegativity constraints are strictly speaking unnecessary because they are special cases of more general constraints ai x . . . ainxn bi but it is convenient to treat them separately. linear programming has proved to be flexible enough to model a wide variety of important applications such as airline crew scheduling transportation and communication network planning oil exploration and refining and industrial production optimization. in fact linear programming is considered by many as one of the most important achievements in the history of applied mathematics. the classic algorithm for this problem is called the simplex method section . . it was discovered by the u.s. mathematician george dantzig in the s dan . although the worst case efficiency of this algorithm is known to be exponential it performs very well on typical inputs. moreover a more recent algorithm by narendra karmarkar kar not only has a proven polynomial worstcase efficiency but has also performed competitively with the simplex method in empirical tests. it is important to stress however that the simplex method and karmarkar's algorithm can successfully handle only linear programming problems that do not limit its variables to integer values. when variables of a linear programming problem are required to be integers the linear programming problem is said to be an integer linear programming problem. except for some special cases e.g. the assignment problem and the problems discussed in sections . . integer linear programming problems are much more difficult. there is no known polynomial time algorithm for solving an arbitrary instance of the general integer linear programming problem and as we see in chapter such an algorithm quite possibly does not exist. other approaches such as the branch and bound technique discussed in section . are typically used for solving integer linear programming problems. example let us see how the knapsack problem can be reduced to a linear programming problem. recall from section . that the knapsack problem can be posed as follows. given a knapsack of capacity w and n items of weights w . . . wn and values v . . . vn find the most valuable subset of the items that fits into the knapsack. we consider first the continuous or fractional version of the problem in which any fraction of any item given can be taken into the knapsack. let xj j . . . n be a variable representing a fraction of item j taken into the knapsack. obviously xj must satisfy the inequality xj . then the total weight of the selected items can be expressed by the sum n wj xj and their n j total value by the sum j vj xj . thus the continuous version of the knapsack problem can be posed as the following linear programming problem n maximize vj xj j n subject to wj xj w j xj for j . . . n. there is no need to apply a general method for solving linear programming problems here this particular problem can be solved by a simple special algorithm that is introduced in section . . but why wait? try to discover it on your own now. this reduction of the knapsack problem to an instance of the linear programming problem is still useful though to prove the correctness of the algorithm in question. in the discrete or version of the knapsack problem we are only allowed either to take a whole item or not to take it at all. hence we have the following integer linear programming problem for this version n maximize vj xj j n subject to wj xj w j xj for j . . . n. this seemingly minor modification makes a drastic difference for the complexity of this and similar problems constrained to take only discrete values in their potential ranges. despite the fact that the version might seem to be easier because it can ignore any subset of the continuous version that has a fractional value of an item the version is in fact much more complicated than its continuous counterpart. the reader interested in specific algorithms for solving this problem will find a wealth of literature on the subject including the monographs mar and kel . 