this algorithm is based on an observation that the graph of a continuous function must intersect with the x axis between two points a and b at least once if the function's values have opposite signs at these two points figure . . the validity of this observation is proved as a theorem in calculus courses and we take it for granted here. it serves as the basis of the following algorithm called the bisection method for solving equation . . starting with an interval a b at whose endpoints f x has opposite signs the algorithm computes the value of f x at the middle point xmid a b . if f xmid a root was found and the algorithm stops. otherwise it continues the search for a root either on a xmid or on xmid b depending on which of the two halves the values of f x have opposite signs at the endpoints of the new interval. since we cannot expect the bisection algorithm to stumble on the exact value of the equation's root and stop we need a different criterion for stopping the algo . ruffini's discovery was completely ignored by almost all prominent mathematicians of that time. abel died young after a difficult life of poverty. galois was killed in a duel when he was only years old. their results on the solution of higher degree equations are now considered to be among the crowning achievements in the history of mathematics. f x a x b x figure . first iteration of the bisection method x is the middle point of interval a b . rithm. we can stop the algorithm after the interval an bn bracketing some root x becomes so small that we can guarantee that the absolute error of approximating x by xn the middle point of this interval is smaller than some small preselected number . since xn is the middle point of an bn and x lies within this interval as well we have xn x bn an . . hence we can stop the algorithm as soon as bn an or equivalently xn an . . it is not difficult to prove that xn x b a for n . . . . . n this inequality implies that the sequence of approximations xn can be made as close to root x as we wish by choosing n large enough. in other words we can say that xn converges to root x. note however that because any digital computer represents extremely small values by zero section . the convergence assertion is true in theory but not necessarily in practice. in fact if we choose below a certain machine dependent threshold the algorithm may never stop! another source of potential complications is round off errors in computing values of the function in question. therefore it is a good practice to include in a program implementing the bisection method a limit on the number of iterations the algorithm is allowed to run. here is pseudocode of the bisection method. algorithm bisection f x a b eps n implements the bisection method for finding a root of f x input two real numbers a and b a b a continuous function f x on a b f a f b an upper bound on the absolute error eps an upper bound on the number of iterations n output an approximate or exact value x of a root in a b or an interval bracketing the root if the iteration number limit is reached n iteration count while n n do x a b if x a eps return x fval f x if fval return x if fval f a bx else a x nn return iteration limit a b note that we can use inequality . to find in advance the number of iterations that should suffice at least in theory to achieve a preselected accuracy level. indeed choosing the number of iterations n large enough to satisfy b a n i.e. n log b a . does the trick. example let us consider equation x x . . it has one real root. see figure . for the graph of f x x x . since f and f the root must lie within interval . if we choose the error tolerance level as inequality . would require n log or n iterations. figure . contains a trace of the first eight iterations of the bisection method applied to equation . . thus we obtained x . as an approximate value for the root x of equation . and we can guarantee that . x . moreover if we take into account the signs of the function f x at a b and x we can assert that the root lies between . and . . the principal weakness of the bisection method as a general algorithm for solving equations is its slow rate of convergence compared with other known methods. it is for this reason that the method is rarely used. also it cannot be extended to solving more general equations and systems of equations. but it does have several strong points. it always converges to a root whenever we start with an y f x x x x figure . graph of function f x x x . n an bn xn f xn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . figure . trace of the bisection method for solving equation . . the signs after the numbers in the second and third columns indicate the sign of f x x x at the corresponding endpoints of the intervals. interval whose properties are very easy to check. and it does not use derivatives of the function f x as some faster methods do. what important algorithm does the method of bisection remind you of? if you have found it to closely resemble binary search you are correct. both of them solve variations of the searching problem and they are both divide byhalf algorithms. the principal difference lies in the problem's domain discrete for binary search and continuous for the bisection method. also note that while binary search requires its input array to be sorted the bisection method does not require its function to be nondecreasing or nonincreasing. finally whereas binary search is very fast the bisection method is relatively slow. f x an xn bn x figure . iteration of the method of false position. 