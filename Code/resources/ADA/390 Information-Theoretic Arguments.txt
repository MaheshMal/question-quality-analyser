while the approach outlined above takes into account the size of a problem's output the information theoretical approach seeks to establish a lower bound based on the amount of information it has to produce. consider as an example the well known game of deducing a positive integer between and n selected by somebody by asking that person questions with yes no answers. the amount of uncertainty that any algorithm solving this problem has to resolve can be measured by log n the number of bits needed to specify a particular number among the n possibilities. we can think of each question or to be more accurate an answer to each question as yielding at most bit of information about the algorithm's output i.e. the selected number. consequently any such algorithm will need at least log n such steps before it can determine its output in the worst case. the approach we just exploited is called the information theoretic argument because of its connection to information theory. it has proved to be quite useful for finding the so called information theoretic lower bounds for many problems involving comparisons including sorting and searching. its underlying idea can be realized much more precisely through the mechanism of decision trees. because of the importance of this technique we discuss it separately and in more detail in section . . 