most sorting algorithms are comparison based i.e. they work by comparing elements in a list to be sorted. by studying properties of decision trees for such algorithms we can derive important lower bounds on their time efficiencies. we can interpret an outcome of a sorting algorithm as finding a permutation of the element indices of an input list that puts the list's elements in ascending order. consider as an example a three element list a b c of orderable items such as real numbers or strings. for the outcome a c b obtained by sorting this list see figure . the permutation in question is . in general the number of possible outcomes for sorting an arbitrary n element list is equal to n!. abc yes a b no abc abc yes a c no yes b c no abc cba bac cba yes b c no b a no yes a c no yes b a a b c a c b c a b b a c b c a c b a figure . decision tree for the tree element selection sort. a triple above a node indicates the state of the array being sorted. note two redundant comparisons b a with a single possible outcome because of the results of some previously made comparisons. inequality . implies that the height of a binary decision tree for any comparison based sorting algorithm and hence the worst case number of comparisons made by such an algorithm cannot be less than log n! cworst n log n! . . using stirling's formula for n! we get log n! log n n e n log log log n log n log n. n n n e in other words about n log n comparisons are necessary in the worst case to sort an arbitrary n element list by any comparison based sorting algorithm. note that mergesort makes about this number of comparisons in its worst case and hence is asymptotically optimal. this also implies that the asymptotic lower bound n log n is tight and therefore cannot be substantially improved. we should point out however that the lower bound of log n! can be improved for some values of n. for example log ! but it has been proved that comparisons are necessary and sufficient to sort an array of elements in the worst case. we can also use decision trees for analyzing the average case efficiencies of comparison based sorting algorithms. we can compute the average number of comparisons for a particular algorithm as the average depth of its decision tree's leaves i.e. as the average path length from the root to the leaves. for example for abc yes a b no abc bac yes b c no yes a c no a b c acb b a c bca yes a c no yes b c no a c b c a b b c a c b a figure . decision tree for the three element insertion sort. the three element insertion sort whose decision tree is given in figure . this number is . under the standard assumption that all n! outcomes of sorting are equally likely the following lower bound on the average number of comparisons cavg made by any comparison based algorithm in sorting an n element list has been proved cavg n log n!. . as we saw earlier this lower bound is about n log n. you might be surprised that the lower bounds for the average and worst cases are almost identical. remember however that these bounds are obtained by maximizing the number of comparisons made in the average and worst cases respectively. for a particular sorting algorithm the average case efficiency can of course be significantly better than their worst case efficiency. 