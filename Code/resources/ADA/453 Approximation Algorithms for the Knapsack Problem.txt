the knapsack problem another well known np hard problem was also introduced in section . given n items of known weights w . . . wn and values v . . . vn and a knapsack of weight capacity w find the most valuable subset of the items that fits into the knapsack. we saw how this problem can be solved by exhaustive search section . dynamic programming section . . we did not include the results for the twice around the tree heuristic because of the inferior quality of its approximations with the average excess of about . nor did we quote the results for the most sophisticated local search heuristics with the average excess over optimum of less than a fraction of . and branch and bound section . . now we will solve this problem by approximation algorithms. greedy algorithms for the knapsack problem we can think of several greedy approaches to this problem. one is to select the items in decreasing order of their weights however heavier items may not be the most valuable in the set. alternatively if we pick up the items in decreasing order of their value there is no guarantee that the knapsack's capacity will be used efficiently. can we find a greedy strategy that takes into account both the weights and values? yes we can by computing the value to weight ratios vi wi i . . . n and selecting the items in decreasing order of these ratios. in fact we already used this approach in designing the branch and bound algorithm for the problem in section . . here is the algorithm based on this greedy heuristic. greedy algorithm for the discrete knapsack problem step compute the value to weight ratios ri vi wi i . . . n for the items given. step sort the items in nonincreasing order of the ratios computed in step . ties can be broken arbitrarily. step repeat the following operation until no item is left in the sorted list if the current item on the list fits into the knapsack place it in the knapsack and proceed to the next item otherwise just proceed to the next item. example let us consider the instance of the knapsack problem with the knapsack capacity and the item information as follows item weight value computing the value to weight ratios and sorting the items in nonincreasing order of these efficiency ratios yields item weight value value weight the greedy algorithm will select the first item of weight skip the next item of weight select the next item of weight and skip the last item of weight . the solution obtained happens to be optimal for this instance see section . where we solved the same instance by the branch and bound algorithm . does this greedy algorithm always yield an optimal solution? the answer of course is no if it did we would have a polynomial time algorithm for the nphard problem. in fact the following example shows that no finite upper bound on the accuracy of its approximate solutions can be given either. example item weight value value weight the knapsack capacity is w . w w since the items are already ordered as required the algorithm takes the first item and skips the second one the value of this subset is . the optimal selection consists of item whose value is w. hence the accuracy ratio r sa of this approximate solution is w which is unbounded above. it is surprisingly easy to tweak this greedy algorithm to get an approximation algorithm with a finite performance ratio. all it takes is to choose the better of two alternatives the one obtained by the greedy algorithm or the one consisting of a single item of the largest value that fits into the knapsack. note that for the instance of the preceding example the second alternative is better than the first one. it is not difficult to prove that the performance ratio of this enhanced greedy algorithm is . that is the value of an optimal subset s will never be more than twice as large as the value of the subset sa obtained by this enhanced greedy algorithm and is the smallest multiple for which such an assertion can be made. it is instructive to consider the continuous version of the knapsack problem as well. in this version we are permitted to take arbitrary fractions of the items given. for this version of the problem it is natural to modify the greedy algorithm as follows. greedy algorithm for the continuous knapsack problem step compute the value to weight ratios vi wi i . . . n for the items given. step sort the items in nonincreasing order of the ratios computed in step . ties can be broken arbitrarily. step repeat the following operation until the knapsack is filled to its full capacity or no item is left in the sorted list if the current item on the list fits into the knapsack in its entirety take it and proceed to the next item otherwise take its largest fraction to fill the knapsack to its full capacity and stop. for example for the four item instance used in example to illustrate the greedy algorithm for the discrete version the algorithm will take the first item of weight and then of the next item on the sorted list to fill the knapsack to its full capacity. it should come as no surprise that this algorithm always yields an optimal solution to the continuous knapsack problem. indeed the items are ordered according to their efficiency in using the knapsack's capacity. if the first item on the sorted list has weight w and value v no solution can use w units of capacity with a higher payoff than v . if we cannot fill the knapsack with the first item or its fraction we should continue by taking as much as we can of the secondmost efficient item and so on. a formal rendering of this proof idea is somewhat involved and we will leave it for the exercises. note also that the optimal value of the solution to an instance of the continuous knapsack problem can serve as an upper bound on the optimal value of the discrete version of the same instance. this observation provides a more sophisticated way of computing upper bounds for solving the discrete knapsack problem by the branch and bound method than the one used in section . . approximation schemes we now return to the discrete version of the knapsack problem. for this problem unlike the traveling salesman problem there exist polynomial time approximation schemes which are parametric families of algorithms that allow us to get approximations sa k with any predefined accuracy level f s k for any instance of size n f sa k where k is an integer parameter in the range k n. the first approximation scheme was suggested by s. sahni in sah . this algorithm generates all subsets of k items or less and for each one that fits into the knapsack it adds the remaining items as the greedy algorithm would do i.e. in nonincreasing order of their value to weight ratios . the subset of the highest value obtained in this fashion is returned as the algorithm's output. example a small example of an approximation scheme with k is provided in figure . . the algorithm yields which is the optimal solution for this instance. you can be excused for not being overly impressed by this example. and indeed the importance of this scheme is mostly theoretical rather than practical. it lies in the fact that in addition to approximating the optimal solution with any predefined accuracy level the time efficiency of this algorithm is polynomial in n. indeed the total number of subsets the algorithm generates before adding extra elements is k n k n n . . . n j k k j j! nj nk k nk. j j j j item weight value value weight subset added items value capacity w not feasible not feasible a b figure . example of applying sahni's approximation scheme for k . a instance. b subsets generated by the algorithm. for each of those subsets it needs o n time to determine the subset's possible extension. thus the algorithm's efficiency is in o knk . note that although it is polynomial in n the time efficiency of sahni's scheme is exponential in k. more sophisticated approximation schemes called fully polynomial schemes do not have this shortcoming. among several books that discuss such algorithms the monographs mar and kel are especially recommended for their wealth of other material about the knapsack problem. exercises . . a. apply the nearest neighbor algorithm to the instance defined by the intercity distance matrix below. start the algorithm at the first city assuming that the cities are numbered from to . b. compute the accuracy ratio of this approximate solution. . a. write pseudocode for the nearest neighbor algorithm. assume that its input is given by an n n intercity distance matrix. b. what is the time efficiency of the nearest neighbor algorithm? . apply the twice around the tree algorithm to the graph in figure . a with a walk around the minimum spanning tree that starts at the same vertex a but differs from the walk in figure . b. is the length of the obtained tour the same as the length of the tour in figure . b? . prove that making a shortcut of the kind used by the twice around the tree algorithm cannot increase the tour's length in a euclidean graph. . what is the time efficiency class of the greedy algorithm for the knapsack problem? . prove that the performance ratio ra of the enhanced greedy algorithm for the knapsack problem is equal to . . consider the greedy algorithm for the bin packing problem which is called the first fit ff algorithm place each of the items in the order given into the first bin the item fits in when there are no such bins place the item in a new bin and add this bin to the end of the bin list. a. apply ff to the instance s . s . s . s . s . and determine whether the solution obtained is optimal. b. determine the worst case time efficiency of ff. c. prove that ff is a approximation algorithm. . the first fit decreasing ffd approximation algorithm for the bin packing problem starts by sorting the items in nonincreasing order of their sizes and then acts as the first fit algorithm. a. apply ffd to the instance s . s . s . s . s . and determine whether the solution obtained is optimal. b. does ffd always yield an optimal solution? justify your answer. c. prove that ffd is a . approximation algorithm. d. run an experiment to determine which of the two algorithms ff or ffd yields more accurate approximations on a random sample of the problem's instances. . a. design a simple approximation algorithm for finding a minimum vertex cover a vertex cover with the smallest number of vertices in a given graph. b. consider the following approximation algorithm for finding a maximum independent set an independent set with the largest number of vertices in a given graph. apply the approximation algorithm of part a and output all the vertices that are not in the obtained vertex cover. can we claim that this algorithm is a approximation algorithm too? . a. design a polynomial time greedy algorithm for the graph coloring problem. b. show that the performance ratio of your approximation algorithm is infinitely large. 