greed for lack of a better word is good! greed is right! greed works! michael douglas us actor in the role of gordon gecko in the film wall street let us revisit the change making problem faced at least subconsciously by millions of cashiers all over the world give change for a specific amount n with the least number of coins of the denominations d d . . . dm used in that locale. here unlike section . we assume that the denominations are ordered in decreasing order. for example the widely used coin denominations in the united states are d quarter d dime d nickel and d penny . how would you give change with coins of these denominations of say cents? if you came up with the answer quarter dimes and pennies you followed consciously or not a logical strategy of making a sequence of best choices among the currently available alternatives. indeed in the first step you could have given one coin of any of the four denominations. greedy thinking leads to giving one quarter because it reduces the remaining amount the most namely to cents. in the second step you had the same coins at your disposal but you could not give a quarter because it would have violated the problem's constraints. so your best selection in this step was one dime reducing the remaining amount to cents. giving one more dime left you with cents to be given with three pennies. is this solution to the instance of the change making problem optimal? yes it is. in fact one can prove that the greedy algorithm yields an optimal solution for every positive integer amount with these coin denominations. at the same time it is easy to give an example of coin denominations that do not yield an optimal solution for some amounts e.g. d d d and n . the approach applied in the opening paragraph to the change making problem is called greedy. computer scientists consider it a general design technique despite the fact that it is applicable to optimization problems only. the greedy approach suggests constructing a solution through a sequence of steps each expanding a partially constructed solution obtained so far until a complete solution to the problem is reached. on each step and this is the central point of this technique the choice made must be feasible i.e. it has to satisfy the problem's constraints locally optimal i.e. it has to be the best local choice among all feasible choices available on that step irrevocable i.e. once made it cannot be changed on subsequent steps of the algorithm these requirements explain the technique's name on each step it suggests a greedy grab of the best alternative available in the hope that a sequence of locally optimal choices will yield a globally optimal solution to the entire problem. we refrain from a philosophical discussion of whether greed is good or bad. if you have not seen the movie from which the chapter's epigraph is taken its hero did not end up well. from our algorithmic perspective the question is whether such a greedy strategy works or not. as we shall see there are problems for which a sequence of locally optimal choices does yield an optimal solution for every instance of the problem in question. however there are others for which this is not the case for such problems a greedy algorithm can still be of value if we are interested in or have to be satisfied with an approximate solution. in the first two sections of the chapter we discuss two classic algorithms for the minimum spanning tree problem prim's algorithm and kruskal's algorithm. what is remarkable about these algorithms is the fact that they solve the same problem by applying the greedy approach in two different ways and both of them always yield an optimal solution. in section . we introduce another classic algorithm dijkstra's algorithm for the shortest path problem in a weighted graph. section . is devoted to huffman trees and their principal application huffman codes an important data compression method that can be interpreted as an application of the greedy technique. finally a few examples of approximation algorithms based on the greedy approach are discussed in section . . as a rule greedy algorithms are both intuitively appealing and simple. given an optimization problem it is usually easy to figure out how to proceed in a greedy manner possibly after considering a few small instances of the problem. what is usually more difficult is to prove that a greedy algorithm yields an optimal solution when it does . one of the common ways to do this is illustrated by the proof given in section . using mathematical induction we show that a partially constructed solution obtained by the greedy algorithm on each iteration can be extended to an optimal solution to the problem. the second way to prove optimality of a greedy algorithm is to show that on each step it does at least as well as any other algorithm could in advancing toward the problem's goal. consider as an example the following problem find the minimum number of moves needed for a chess knight to go from one corner of a board to the diagonally opposite corner. the knight's moves are l shaped jumps two squares horizontally or vertically followed by one square in the perpendicular direction. a greedy solution is clear here jump as close to the goal as possible on each move. thus if its start and finish squares are and respectively a sequence of moves such as . . . solves the problem. the number k of two move advances can be obtained from the equation k . why is this a minimum move solution? because if we measure the distance to the goal by the manhattan distance which is the sum of the difference between the row numbers and the difference between the column numbers of two squares in question the greedy algorithm decreases it by on each move the best the knight can do. the third way is simply to show that the final result obtained by a greedy algorithm is optimal based on the algorithm's output rather than the way it operates. as an example consider the problem of placing the maximum number of chips on an board so that no two chips are placed on the same or adjacent vertically horizontally or diagonally squares. to follow the prescription of the greedy strategy we should place each new chip so as to leave as many available squares as possible for next chips. for example starting with the upper left corner of the board we will be able to place chips as shown in figure . a. why is this solution optimal? to see why partition the board into sixteen squares as shown in figure . b. obviously it is impossible to place more than one chip in each of these squares which implies that the total number of nonadjacent chips on the board cannot exceed . as a final comment we should mention that a rather sophisticated theory has been developed behind the greedy technique which is based on the abstract combinatorial structure called matroid. an interested reader can check such books as cor as well as a variety of internet resources on the subject. figure . a placement of chips on non adjacent squares. b partition of the board proving impossibility of placing more than chips. a b a b a b a b c d c d c d c d graph w t w t w t figure . graph and its spanning trees with t being the minimum spanning tree. 