many important algorithms especially those for sorting and searching work by comparing items of their inputs. we can study the performance of such algorithms with a device called a decision tree. as an example figure . presents a decision tree of an algorithm for finding a minimum of three numbers. each internal node of a binary decision tree represents a key comparison indicated in the node e.g. k k . the node's left subtree contains the information about subsequent comparisons made if k k and its right subtree does the same for the case of k k . for the sake of simplicity we assume throughout this section that all input items are distinct. each leaf represents a possible outcome of the algorithm's run on some input of size n. note that the number of leaves can be greater than the number of outcomes because for some algorithms the same outcome can be arrived at through a different chain of comparisons. this happens to be the case for the decision tree in figure . . an important point is that the number of leaves must be at least as large as the number of possible outcomes. the algorithm's work on a particular input of size n can be traced by a path from the root to a leaf in its decision tree and the number of comparisons made by the algorithm on such yes a b no yes a c no yes b c no a c b c figure . decision tree for finding a minimum of three numbers. a run is equal to the length of this path. hence the number of comparisons in the worst case is equal to the height of the algorithm's decision tree. the central idea behind this model lies in the observation that a tree with a given number of leaves which is dictated by the number of possible outcomes has to be tall enough to have that many leaves. specifically it is not difficult to prove that for any binary tree with l leaves and height h h log l . . indeed a binary tree of height h with the largest number of leaves has all its leaves on the last level why? . hence the largest number of leaves in such a tree is h. in other words h l which immediately implies . . inequality . puts a lower bound on the heights of binary decision trees and hence the worst case number of comparisons made by any comparison based algorithm for the problem in question. such a bound is called the informationtheoretic lower bound see section . . we illustrate this technique below on two important problems sorting and searching in a sorted array. 