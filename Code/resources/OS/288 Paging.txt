 is a memory management scheme that permits the physical address space of a process to be noncontiguous. paging avoids the considerable problem of fitting memory chunks of varying sizes onto the backing store most memory management schemes used before the introduction of paging suffered from this problem. the problem arises because when some code fragments or data residing in main memory need to be swapped out space must be found logical physical l address address f i it physical memory page table figure . paging hardware. . paging on the backing store. the backing store also has the fragmentation problems discussed in connection with main memory except that access is much slower so compaction is impossible. because of its advantages over earlier methods paging in its various forms is commonly used in. most operating systems. traditionally support for paging has been handled by hardware. however recent designs have implemented paging by closely integrating the hardware and operating system especially on bit microprocessors. . . basic method the basic method for implementing paging involves breaking physical memory into fixed sized blocks called frames and breaking logical memory into blocks of the same size called pages. when a process is to be executed its pages are loaded into any available memory frames from the backing store. the backing store is divided into fixed sized blocks that are of the same size as the memory frames. the hardware support for paging is illustrated in figure . . every address generated by the cpu is divided into two parts a page number p and a page offset d . the page number is used as an index into a page table. the page table contains the base address of each page in physical memory. this base address is combined with the page offset to define the physical memory address that is sent to the memory unit. the paging model of memory is shown in figure . . the page size like the frame size is defined by the hardware. the size of a page is typically a power of varying between bytes and mb per page depending on the computer architecture. the selection of a power of as a page size makes the translation of a logical address into a page number frame number page page op age o ' page w page page table logical page i memory lil'llf page physical memory figure . paging model of logical and physical memory. chapter main memory and page offset particularly easy. if the size of logical address space is ' and a page size is addressing units bytes or words then the high order m n bits of a logical address designate the page number and the n low order bits designate the page offset. thus the logical address is as follows page number page offset m n where p is an index into the page table and d is the displacement within the page. as a concrete although minuscule example consider the memory in figure . . using a page size of bytes and a physical memory of bytes pages we show how the user's view of memory can be mapped into physical memory. logical address is page offset . indexing into the page table we find that page is in frame . thus logical address maps to physical address x . logical address page offset maps to physical address x . logical address is page offset according to the page table page is mapped to frame . thus logical address maps to physical address x . logical address maps to physical address . a a b ! ! ... id e .s f h i ' i!! ! k i page table it! til p. logical memory ?n a la g d e f q ft physical memory figure . paging example for a byte memory with byte pages. . paging you may have noticed that paging itself is a form of dynamic relocation. every logical address is bound by the paging hardware to some physical address. using paging is similar to using a table of base or relocation registers one for each frame of memory. when we use a paging scheme we have no external fragmentation an free frame can be allocated to a process that needs it. however we may have some internal fragmentation. notice that frames are allocated as units. if the memory requirements of a process do not happen to coincide with page boundaries the last frame allocated may not be completely full. for example if page size is bytes a process of bytes would need pages phis bytes. it would be allocated frames resulting in an internal fragmentation of bytes. in the worst case a process would need n pages plus byte. it would be allocated n frames resulting in an internal fragmentation of almost an entire frame. if process size is independent of page size we expect internal fragmentation to average one half page per process. this consideration suggests that small page sizes are desirable. however overhead is involved in each page table entry and this overhead is reduced as the size of the pages increases. also disk i o is more efficient when the number of data being transferred is larger chapter . generally page sizes have grown over time as processes data sets and main memory have become larger. today pages typically are between kb and kb in size and some systems support even larger page sizes. some cpus and kernels even support multiple page sizes. for instance solaris uses page sizes of kb and mb depending on the data stored by the pages. researchers are now developing variable on the fly page size support. usually each page table entry is bytes long but that size can vary as well. a bit entry can point to one of physical page frames. if frame size is kb then a system with byte entries can address bytes or tb of physical memory. when a process arrives in the system to be executed its size expressed in pages is examined. each page of the process needs one frame. thus if the process requires n pages at least n frames must be available in memory. if n frames are available they are allocated to this arriving process. the first page of the process is loaded into one of the allocated frames and the frame number is put in. the page table for this process. the next page is loaded into another frame and its frame number is put into the page table and so on figure . . an important aspect of paging is the clear separation between the user's view of memory and the actual physical memory. the user program views memory as one single space containing only this one program. in fact the user program is scattered throughout physical memory which also holds other programs. the difference between the user's view of memory and the actual physical memory is reconciled by the address translation hardware. the logical addresses are translated into physical addresses. this mapping is hidden from the user and is controlled by the operating system. notice that the user process by definition is unable to access memory it does not own. it has no way of addressing memory outside of its page table and the table includes only those pages that the process owns. since the operating system is managing physical memory it must be aware of the allocation details of physical memory which frames are allocated which frames are available how manv total frames there are and so on. this chapter main memory free frame lis free frame lis jul j nuirtih i nrrr p ge i n j ui i ui 'pdgec page . .! ! ! ipago paye pdse page paije hi new piocesd t v oroceas h hr h' pgge pp. !i iii ! new process page table a b figure . free frames a before allocation and b after allocation. information is generally kept in a data structure called a frame table. the frame table has one entry for each physical page frame indicating whether the latter is free or allocated and if it is allocated to which page of which process or processes. in addition the operating system must be aware that user processes operate in user space and all logical addresses must be mapped to produce physical addresses. if a user makes a system call to do i o for example and provides an address as a parameter a buffer for instance that address must be mapped to produce the correct physical address. the operating system maintains a copy of the page table for each process just as it maintains a copy of the instruction counter and register contents. this copy is used to translate logical addresses to physical addresses whenever the operating system must map a logical address to a physical address manually. it is also used by the cpu dispatcher to define the hardware page table when a process is to be allocated the cpu. paging therefore increases the context switch time. . . hardware support each operating system has its own methods for storing page tables. most allocate a page table for each process. a pointer to the page table is stored with the other register values like the instruction counter in the process control block. when the dispatcher is told to start a process it must reload the user registers and define the correct hardware page table values from the stored user page table. the hardware implementation of the page table can be done in several ways. in the simplest case the page table is implemented as a set of dedicated registers. these registers should be built with very high speed logic to make the paging address translation efficient. every access to memory must go through the paging map so efficiency is a major consideration. the cpu dispatcher . paging reloads these registers just as it reloads the other registers. instructions i load or modify the page table registers are of course privileged so that only the operating system can change the memory map. the dec pdp is an example of such an architecture. the address consists of bits and the page size is kb. the page table thus consists of eight entries that are kept in fast registers. the use of registers for the page table is satisfactory if the page table is reasonably small for example entries . most contemporary computers however allow the page table to be very large for example million entries . for these machines the use of fast registers to implement the page table is not feasible. rather the page table is kept in main memory and a page table base register ptbr points to the page table. changing page tables requires changing only this one register substantially reducing context switch time. the problem with this approach is the time required to access a user memory location. if we want to access location we must first index into the page table using the value in the ptbr offset by the page number for ch . this task requires a memory access. it provides us with the frame number which is combined with the page offset to produce the actual address. we can then access the desired place in memory. with this scheme two memory accesses are needed to access a byte one for the page table entry one for the byte . thus memory access is slowed by a factor of . this delay would be intolerable under most circumstances. we might as well resort to sivapping! the standard solution to this problem is to use a special small fastlookup hardware cache called a translation look aside buffer tlb . the tlb is associative high speed memory. each entry in the tlb consists of two parts a key or tag and a value. when the associative memory is presented with an item the item is compared with all keys simultaneously. if the item is found the corresponding value field is returned. the search is fast the hardware however is expensive. typically the number of entries in a tlb is small often numbering between and . the tlb is used with page tables in the following way. the tlb contains only a few of the page table entries. when a logical address is generated by the cpu its page number is presented to the tlb. if the page number is found its frame number is immediately available and is used to access memory. the whole task may take less than percent longer than it would if an unmapped memory reference were used. if the page number is not in the tlb known as a tlb miss a memory reference to the page table must be made. when the frame number is obtained we can use it to access memory figure . . in addition we add the page number and frame number to the tlb so that they will be found quickly on the next reference. if the tlb is already full of entries the operating system must select one for replacement. replacement policies range from least recently used lru to random. furthermore some tlbs allow entries to be wired down meaning that they cannot be removed from the tlb. typically tlb entries for kernel code are wired down. some tlbs store address space identifiers asids in each tlb entry. an asid uniquely identifies each process and is used to provide address space protection for that process. wtien the tlb attempts to resolve virtual page numbers it ensures that the asid for the currently running process matches the asid associated with the virtual page. if the asids do not match the attempt is treated as a tlb miss. in addition to providing address space protection an asid chapter main memory logical address gpu page frame number number physical memory page table figure . paging hardware with tlb. allows the tlb to contain entries for several different processes simultaneously. if the tlb does not support separate asids then every time a new page table is selected for instance with each context switch the tlb must be flushed or erased to ensure that the next executing process does not use the wrong translation information. otherwise the tlb could include old entries that contain valid virtual addresses but have incorrect or invalid physical addresses left over from the previous process. the percentage of times that a particular page number is found in the tlb is called the hit ratio. an percent hit ratio means that we find the desired page number in the tlb percent of the time. if it takes nanoseconds to search the tlb and nanoseconds to access memory then a mapped memory access takes nanoseconds when the page number is in the tlb. if we fail to find the page number in the tlb nanoseconds then we must first access memory for the page table and frame number nanoseconds and then access the desired byte in memory nanoseconds for a total of nanoseconds. to find the effective memory access time we weight each case by its probability effective access time . x . x nanoseconds. in this example we suffer a percent slowdown in memory access time from to nanoseconds . for a percent hit ratio we have effective access time . x . x nanoseconds. this increased hit rate produces only a percent slowdown in access time. we will further explore the impact of the hit ratio on the tlb in chapter . . paging s . . protection memory protection in a paged environment is accomplished by protection bits associated with each frame. normally these bits are kept in the page table. one bit can define a page to be read write or read only. every reference to memory goes through the page table to find the correct frame number. at the same time that the physical address is being computed the protection bits can be checked to verify that no writes are being made to a read only page. an attempt to write to a read only page causes a hardware trap to the operating system or memory protection violation . we can easily expand this approach to provide a finer level of protection. we can create hardware to provide read only read write or execute only protection or by providing separate protection bits for each kind of access we can allow any combination of these accesses. illegal attempts will be trapped to the operating system. one additional bit is generally attached to each entry in the page table a valid invalid bit. when this bit is set to valid the associated page is in the process's logical address space and is thus a legal or valid page. when the bit is set to invalid ' the page is not in the process's logical address space. illegal addresses are trapped by use of the valid invalid bit. the operating system sets this bit for each page to allow or disallow access to the page. suppose for example that in a system with a bit address space to we have a program that should use only addresses to . given a page size of kb we get the situation shown in figure . . addresses in pages fpage frame number . valid invalid bit page gage fl g mragep natje uaqc oage t ' . page k q p ags t page table pagers ft figure . valid v or invalid i bit in a page table. chapter main memory and are mapped normally through the page table. any attempt to generate an address in pages or however will find that the valid invalid bit is set to invalid and the computer will trap to the operating system invalid page reference . notice that this scheme has created a problem. because the program extends to only address any reference beyond that address is illegal. however references to page are classified as valid so accesses to addresses up to are valid. only the addresses from to are invalid. this problem is a result of the kb page size and reflects the internal fragmentation of paging. rarely does a process use all its address range. in fact many processes use only a small fraction of the address space available to them. it would be wasteful in these cases to create a page table with entries for every page in the address range. most of this table would be unused but would take up valuable memory space. some systems provide hardware in the form of a page table length register ptlr to indicate the size of the page table. this value is checked against every logical address to verify that the address is in the valid range for the process. failure of this test causes an error trap to the operating system. . . shared pages an advantage of paging is the possibility of sharing common code. this consideration is particularly important in a time sharing environment. consider a system that supports users each of whom executes a text editor. if the text editor consists of kb of code and kb of data space we need kb to support the users. if the code is reentrant code or pure code however it can be shared as shown in figure . . here we see a three page editor each page kb in size the large page size is used to simplify the figure being shared among three processes. each process has its own data page. reentrant code is non self modifying code it never changes during execution. thus two or more processes can execute the same code at the same time. each process has its own copy of registers and data storage to hold the data for the process's execution. the data for two different processes will of course be different. only one copy of the editor need be kept in physical memory. each user's page table maps onto the same physical copy of the editor but data pages are mapped onto different frames. thus to support users we need only one copy of the editor kb plus copies of the kb of data space per user. the total space required is now kb instead of kb a significant savings. other heavily used programs can also be shared compilers window systems run time libraries database systems and so on. to be sharable the code must be reentrant. the read only nature of shared code should not be left to the correctness of the code the operating system should enforce this property. the sharing of memory among processes on a system is similar to the sharing of the address space of a task by threads described in chapter . furthermore recall that in chapter we described shared memory as a method