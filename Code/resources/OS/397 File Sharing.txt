 and volumes assigned drive letters. volumes have a general graph directory structure associated with the drive letter. the path to a specific file takes the form of drive letter path to file. the more recent versions of windows allow a file system to he mounted anywhere in the directory tree just as unix does. windows operating systems automatically discover all devices and mount all located file systems at boot time. in some systems like unix the mount commands are explicit. a system configuration file contains a list of devices and mount points for automatic mounting at boot time but other mounts may be executed manually. issues concerning file system mounting are further discussed in section . . and in appendix a. . . . file sharing in the previous sections we explored the motivation for file sharing and some of the difficulties involved in allowing users to share files. such file sharing is very desirable for users who want to collaborate and to reduce the effort required to achieve a computing goal. therefore user oriented operating systems must accommodate the need to share files in spite of the inherent difficulties. in this section we examine more aspects of file sharing. w'e begin by discussing general issues that arise when multiple users share files. once multiple users are allowed to share files the challenge is to extend sharing to multiple file systems including remote file systems and we discuss that challenge as well. finally we consider what to do about conflicting actions occurring on shared files. for instance if multiple users are writing to a file should all the writes be allowed to occur or should the operating system protect the user actions from one another? . . multiple users when an operating system accommodates multiple users the issues of file sharing file naming and file protection become preeminent. given a directory structure that allows files to be shared by users the system must mediate the file sharing. the system can either allow a user to access the files of other users by default or require that a user specifically grant access to the files. these are the issues of access control and protection which are covered in section . . to implement sharing and protection the system must maintain more file and directory attributes than are needed on a single user system. although many approaches have been taken to this requirement historically most systems have evolved to use the concepts of file or directory owner or user and group. the owner is the user who can change attributes and grant access and who has the most control over the file. the group attribute defines a subset of users who can share access to the file. for example the owner of a file on a unix system can issue all operations on a file while members of the file's group can execute one subset of those operations and all other users can execute another subset of operations. exactly which operations can be executed by group members and other users is definable by the file's owner. more details on permission attributes are included in the next section. chapter file system interface the owner and group ids of a given file or directory are stored with the other file attributes. when a user requests an operation on a file the user id can be compared with the owner attribute to determine if the requesting user is the owner of the file. likewise the group ids can be compared. the result indicates which permissions are applicable. the system then applies those permissions to the requested operation and allows or denies it. many systems have multiple local file systems including volumes of a single disk or multiple volumes on multiple attached disks. in these cases the id checking and permission matching are straightforward once the file systems are mounted. . remote fi!e systems with the advent of networks chapter communication among remote computers became possible. networking allows the sharing of resources spread across a campus or even around the world. one obvious resource to share is data in the form of files. through the evolution of network and file technology remote file sharing methods have changed. the first implemented method involves manually transferring files between machines via programs like ftp. the second major method uses a distributed file system dfs in which remote directories are visible from a local machine. in some ways the third method the world wide web is a reversion to the first. a browser is needed to gain access to the remote files and separate operations essentially a wrapper for ftp are used to transfer files. f t p is used for both anonymous and authenticated access. anonymous access allows a user to transfer files without having an account on the remote system. the world wide web uses anonymous file exchange almost exclusively. dfs involves a much tighter integration between the machine that is accessing the remote files and the machine providing the files. this integration adds complexity which we describe in this section. . . . the client server model remote file systems allow a computer to mount one or more file systems from one or more remote machines. in this case the machine containing the files is the server and the machine seeking access to the files is the client. the client server relationship is common with networked machines. generally the server declares that a resource is available to clients and specifies exactly which resource in this case which files and exactly which clients. a server can serve multiple clients and a client can use multiple servers depending on the implementation details of a given client server facility. the server usually specifies the available files on a volume or directory level. client identification is more difficult. a client can be specified by a network name or other identifier such as an ip address but these can be spoofed or imitated. as a result of spoofing an unauthorized client could be allowed access to the server. more secure solutions include secure authentication of the client via encrypted keys. unfortunately with security come many challenges including ensuring compatibility of the client and server they must use the same encryption algorithms and security of key exchanges intercepted keys . file sharing could again allow unauthorized access . because of the difficulty of solving these problems unsecure authentication methods are most commonly used. in the case of unix and its network file system nfs authentication takes place via the client networking information by default. in this scheme the user's ids on the client and server must match. if they do not the server will be unable to determine access rights to files. consider the example of a user who has an id of on the client and on the server. a request from the client to the server for a specific file will not be handled appropriately as the server will determine if user has access to the file rather than basing the determination on the real user id of . access is thus granted or denied based on incorrect authentication information. the server must trust the client to present the correct user id. note that the nfs protocols allow many to many relationships. that is many servers can provide files to many clients. in fact a given machine can be both a server to other nfs clients and a client of other nfs servers. once the remote file system is mounted file operation requests are sent on behalf of the user across the network to the server via the dfs protocol. typically a file open request is sent along with the id of the requesting user. the server then applies the standard access checks to determine if the user has credentials to access the file in the mode requested. the request is either allowed or denied. if it is allowed a file handle is returned to the client application and the application then can perform read write and other operations on the file. the client closes the file when access is completed. the operating system may apply semantics similar to those for a local file system mount or may use different semantics. . . . distributed information systems to make client server systems easier to manage distributed information systems also known as distributed naming services provide unified access to the information needed for remote computing. the domain name system dns provides host name to network address translations for the entire internet including the world wide web . before dnis became widespread files containing the same information were sent via e mail or f t p between all networked hosts. this methodology was not scalable. dns is further discussed in section . . . other distributed information systems provide user name password user id group id space for a distributed facility. unix systems have employed a wide variety of distributed information methods. sun microsystems introduced yellow pages since renamed network information service or nis and most of the industry adopted its use. it centralizes storage of user names host names printer information and the like. unfortunately it uses unsecure authentication methods including sending user passwords unencrypted in clear text and identifying hosts by if address. sun's nis is a much more secure replacement for nis but is also much more complicated and has not been widely adopted. in the case of microsofts common internet file system cifs network information is used in conjunction with user authentication user name and password to create a network login that the server uses to decide whether to allow or deny access to a requested file system. for this authentication to be valid the user names must match between the machines as with chapter file system interface nfs . microsoft uses two distributed naming structures to provide a single name space for users. the older naming technology is domains. the newer technology available in windows xp and windows is active directory. once established the distributed naming facility is used by all clients and servers to authenticate users. the industry is moving toward use of the lightweight directory access protocol ldap as a secure distributed naming mechanism. in fact active directory is based on ldap. sun microsystems includes ldap with the operating system and allows it to be used for user authentication as well as system wide retrieval of information such as availability of printers. conceivably one distributed ldap directory could be used by an organization to store all user and resource information for all the organization's computers. the result would be secure single sign on for users who would enter their authentication information once for access to all computers within the organization. it would also ease systems administration efforts by combining in one location information that is currently scattered in various files on each system or in different distributed information services. . . . failure modes local file systems can fail for a variety of reasons including failure of the disk containing the file system corruption of the directory structure or other disk management information collectively called metadata disk controller failure cable failure and host adapter failure. user or systems administrator failure can also cause files to be lost or entire directories or volumes to be deleted. many of these failures will cause a host to crash and an error condition to be displayed and human intervention will be required to repair the damage. remote file systems have even more failure modes. because of the complexity of network systems and the required interactions between remote machines many more problems can interfere with the proper operation of remote file systems. in the case of networks the network can be interrupted between two hosts. such interruptions can result from hardware failure poor hardware configuration or networking implementation issues. although some networks have built in resiliency including multiple paths between hosts many do not. any single failure can thus interrupt the flow of dfs commands. consider a client in the midst of using a remote file system. it has files open from the remote host among other activities it may be performing directory lookups to open files reading or writing data to files and closing files. now consider a partitioning of the network a crash of the server or even a scheduled shutdown of the server. suddenly the remote file system is no longer reachable. this scenario is rather common so it would not be appropriate for the client system to act as it would if a local file system were lost. rather the system can either terminate all operations to the lost server or delay operations until the server is again reachable. these failure semantics are defined and implemented as part of the remote file system protocol. termination of all operations can result in users' losing data and patience. thus most dfs protocols either enforce or allow delaying of file system operations to remote hosts with the hope that the remote host will become available again. to implement this kind of recovery from failure some kind of state information may be maintained on both the client and the server. if both server . file sharing and client maintain knowledge of their current activities and open files then they can seamlessly recover from a failure. in the situation where the server crashes but must recognize that it has remotely mounted exported file systems and opened files nfs takes a simple approach implementing a stateless dfs. in essence it assumes that a client request for a file read or write would not have occurred unless the file system had been remotely mounted and the file had been previously open. the nfs protocol carries all the information needed to locate the appropriate file and perform the requested operation. similarly it does not track which clients have the exported volumes mounted again assuming that if a request comes in it must be legitimate. while this stateless approach makes nfs resilient and rather easy to implement it also makes it unsecure. for example forged read or write requests could be allowed by an nfs server even though the requisite mount request and permission check have not taken place. these issues are addressed in the industry standard nfs version in which nfs is inade stateful to improve its security performance and functionality. . . consistency semantics consistency semantics represent an important criterion for evaluating any file system that supports file sharing. these semantics specify how multiple users of a system are to access a shared file simultaneously. in particular they specify when modifications of data by one user will be observable by other users. these semantics are typically implemented as code with the file system. consistency semantics are directly related to the process synchronization algorithms of chapter . however the complex algorithms of that chapter tend not to be implemented in the case of file i o because of the great latencies and slow transfer rates of disks and networks. for example performing an atomic transaction to a remote disk could involve several network communications several disk reads and writes or both. systems that attempt such a full set of functionalities tend to perform poorly. a successful implementation of complex sharing semantics can be found in the andrew file system. for the following discussion we assume that a series of file accesses that is reads and writes attempted by a user to the same file is always enclosed between the openq and close operations. the series of accesses between the openo and close operations makes up a file session. to illustrate the concept we sketch several prominent examples of consistency semantics. . . . unix semantics the umix file system chapter uses the following consistency semantics writes to an open file by a user are visible immediately to other users that have this file open. one mode of sharing allows users to share the pointer of current location into the file. thus the advancing of the pointer by one user affects all sharing users. here a file has a single image that interleaves all accesses regardless of their origin. in the unix semantics a file is associated with a single physical image that is accessed as an exclusive resource. contention for this single image causes delays in user processes. chapter file system interface . . . session semantics the andrew file system afs chapter uses the following consistency semantics writes to an open file by a user are not visible immediately to other users that have the same file open. once a file is closed the changes made to it are visible only in sessions starting later. already open instances of the file do not reflect these changes. according to these semantics a file may be associated temporarily with several possibly different images at the same time. consequently multiple xisers are allowed to perform both read and write accesses concurrently on their images of the file without delay. almost no constraints are enforced on scheduling accesses. . . . immutable shared files semantics a unique approach is that of immutable shared files. once a file is declared as shared by its creator it cannot be modified. an immutable file has two key properties its name may not be reused and its contents may not be altered. thus the name of an immutable file signifies that the contents of the file are fixed. the implementation of these semantics in a distributed system chapter is simple because the sharing is disciplined read only . 