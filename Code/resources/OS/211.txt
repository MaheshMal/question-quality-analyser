Mac OS X Grand Central Dispatch

           As was mentioned in Chapter 2, Mac OS X Grand Central Dispatch (GCD) pro-
           vides a pool of available threads. Designers can designate portions of applications,
           called blocks, that can be dispatched independently and run concurrently. The OS
           will provide as much concurrency as possible based on the number of cores avail-
           able and the thread capacity of the system. Although other operating systems have
           implemented thread pools, GCD provides a qualitative improvement in ease of use
           and efficiency.
           A block is a simple extension to C or other languages, such as C++. The pur-
           pose of defining a block is to define a self-contained unit of work, including code
           plus data. Here is a simple example of a block definition:
           x  =  ^{         printf("hello          world\n");      }
           A block is denoted by a caret at the start of the function, which is enclosed in
           curly brackets. The above block definition defines x as a way of calling the func-
           tion, so that invoking the function x() would print the words hello world.

     Blocks enable the programmer to encapsulate complex functions, together
     with their arguments and data, so that they can easily be referenced and passed
     around in a program, much like a variable.9 Symbolically:
                             F     =F+    data
     Blocks are scheduled and dispatched by means of queues. The application
     makes use of system queues provided by GCD and may also set up private queues.
     Blocks are put onto a queue as they are encountered during program execution.
     GCD then uses those queues to describe concurrency, serialization, and callbacks.
     Queues are lightweight user-space data structures, which generally makes them far
     more efficient than manually managing threads and locks. For example, this queue
     has three blocks:
                             H     G      F
                                   Queue
     Depending on the queue and how it is defined, GCD either treats these blocks
     as potentially concurrent activities, or treats them as serial activities. In either case,
     blocks are dispatched on a first-in-first-out basis. If this is a concurrent queue, then
     the dispatcher assigns F to a thread as soon as one is available, then G, then H. If
     this is a serial queue, the dispatcher assigns F to a thread, and then only assigns G
     to a thread after F has completed. The use of predefined threads saves the cost of
     creating a new thread for each request, reducing the latency associated with process-
     ing a block. Thread pools are automatically sized by the system to maximize the
     performance of the applications using GCD while minimizing the number of idle or
     competing threads.
                          H     G  F
                             Pool         Thread
     In addition to scheduling blocks directly, the application can associate a sin-
     gle block and queue with an event source, such as a timer, network socket, or file
     descriptor. Every time the source issues an event, the block is scheduled if it is not
     9Much of the material in the remainder of this section is based on [APPL09].

already running. This allows rapid response without the expense of polling or "park-
ing a thread" on the event source.
                       Source               E
                                               E       E
An example from [SIRA09] indicates the ease of using GCD. Consider a
document-based application with a button that, when clicked, will analyze the
current document and display some interesting statistics about it. In the common
case, this analysis should execute in under a second, so the following code is used
to connect the button with an action:
-  (Inaction)analyzeDocument:(NSButton                    *)sender
{
   NSDictionary      *stats            =  [myDoc  analyze];
   [myModel  setDict:stats];
   [myStatsView      setNeedsDisplay:YES];
   [stats    release];
}
The first line of the function body analyzes the document, the second line
updates the application's internal state, and the third line tells the application that
the statistics view needs to be updated to reflect this new state. This code, which fol-
lows a common pattern, is executed in the main thread. The design is acceptable so
long as the analysis does not take too long, because after the user clicks the button,
the main thread of the application needs to handle that user input as fast as pos-
sible so it can get back to the main event loop to process the next user action. But
if the user opens a very large or complex document, the analyze step may take an
unacceptably long amount of time. A developer may be reluctant to alter the code
to meet this unlikely event, which may involve application-global objects, thread
management, callbacks, argument marshalling, context objects, new variables, and
so on. But with GCD, a modest addition to the code produces the desired result:
-  (IBAction)analyzeDocument:(NSButton                    *)sender
   {dispatch_async(dispatch_get_global_queue(0,                     0),          ^{
        NSDictionary                *stats  =  [myDoc  analyze];
        dispatch_async(dispatch_get_main_queue(),                   ^{
             [myModel   setDict:stats];
             [myStatsView              setNeedsDisplay:YES];
             [stats  release];
        });
   });
}

     All functions in GCD begin with dispatch_. The outer dispatch_
     async() call puts a task on a global concurrent queue. This tells the OS that the
     block can be assigned to a separate concurrent queue, off the main queue, and exe-
     cuted in parallel. Therefore, the main thread of execution is not delayed. When the
     analyze function is complete, the inner dispatch_async() call is encountered.
     This directs the OS to put the following block of code at the end of the main queue,
     to be executed when it reaches the head of the queue. So, with very little work on
     the part of the programmer, the desired requirement is met.
