 in a single processor system only one process can run at a time any others must wait until the cpu is free and can be rescheduled. the objective of multiprogramming is to have some process running at all times to maximize cpu utilization. the idea is relatively simple. a process is executed until it must wait typically for the completion of some i o request. in a simple computer system the cpu then just sits idle. all this waiting time is wasted no useful work is accomplished. with multiprogramming we try to use this time productively. several processes are kept in memory at one time. when one process has to wait the operating system takes the cpu away from that chapter cpu scheduling process and gives the cpu to another process. this pattern continues. every time one process has to wait another process can take over use of the cpu. scheduling of this kind is a fundamental operating system function. almost all computer resources are scheduled before use. the cpu is of course one of the primary computer resources. thus its scheduling is central to operating system design. . . cpu i o burst cycle the success of cpu scheduling depends on an observed property of processes process execution consists of a cycle of cpu execution and i o wait. processes alternate between these two states. process execution begins with a cpu burst. that is followed by an i o burst which is followed by another cpu burst then another i o burst and so on. eventually the final cpu burst ends with a system request to terminate execution figure . . the durations of cpu bursts have been measured extensively. although they vary greatly from process to process and from computer to computer they tend to have a frequency curve similar to that shown in figure . . the curve is generally characterized as exponential or hyperexponential with a large number of short cpu bursts and a small number of long cpu bursts. an i o bound program typically has many short cpu bursts. a cpu bound load store add store cpu burst read from file wait for i o i o burst store increment index cpu burst write to file wait for i o i o burst load store add store cpu burst read from file wait for i o i o burst figure . alternating sequence of cpu and i o bursts. . basic concepts burst duration milliseconds figure . histogram of cpu burst durations. program might have a few long cpu bursts. this distribution can be important in the selection of an appropriate cpu scheduling algorithm. . . cpu scheduler whenever the cpu becomes idle the operating system must select one of the processes in the ready queue to be executed. the selection process is carried out by the short term scheduler or cpu scheduler . the scheduler selects a process from the processes in memory that are ready to execute and allocates the cpu to that process. note that the ready queue is not necessarily a first in first out fifo queue. as we shall see when we consider the various scheduling algorithms a ready queue can be implemented as a fifo queue a priority queue a tree or simply an unordered linked list. conceptually however all the processes in the ready queue are lined up waiting for a chance to run on the cpu. the records in the queues are generally process control blocks pcbs of the processes. . . preemptive scheduling cpu scheduling decisions may take place under the following four circumstances . when a process switches from the running state to the waiting state for example as the result of an i o request or an invocation of wait for the termination of one of the child processes chapter cpu scheduling . when a process switches from the running state to the ready state ioi example when an interrupt occurs . when a process switches from the waiting state to the ready state for example at completion of i o . when a process terminates for situations and there is no choice in terms of scheduling. a new process if one exists in the ready queue must be selected for execution. there is a choice however for situations and . when scheduling takes place only under circumstances and we say that the scheduling scheme is nonpreemptive or cooperative otherwise it is preemptive. under nonpreemptive scheduling once the cpu has been allocated to a process the process keeps the cpu until it releases the cpu either by terminating or by switching to the waiting state. this scheduling method was vised by microsoft windows .x windows introduced preemptive scheduling and all subsequent versions of windows operating systems have used preemptive scheduling. the mac os x operating system for the macintosh uses preemptive scheduling previous versions of the macintosh operating system relied on cooperative scheduling. cooperative scheduling is the only method that can be used on certain hardware platforms because it does not require the special hardware for example a timer needed for preemptive scheduling. unfortunately preemptive scheduling incurs a cost associated with access to shared data. consider the case of two processes that share data. while one is updating the data it is preempted so that the second process can run. the second process then tries to read the data which are in an inconsistent state. in such situations we need new mechanisms to coordinate access to shared data we discuss this topic in chapter . preemption also affects the design of the operating system kernel. during the processing of a system call the kernel may be busy with an activity on behalf of a process. such activities may involve changing important kernel data for instance i o queues . what happens if the process is preempted in the middle of these changes and the kernel or the device driver needs to read or modify the same structure? chaos ensues. certain operating systems including most versions of unix deal with this problem by waiting either for a system call to complete or for an i o block to take place before doing a context switch. this scheme ensures that the kernel structure is simple since the kernel will not preempt a process while the kernel data structures are in an inconsistent state. unfortunately this kernel execution model is a poor one for supporting real time computing and multiprocessing. these problems and their solutions are described in sections . and . . because interrupts can by definition occur at any time and because they cannot always be ignored by the kernel the sections of code affected by interrupts must be guarded from simultaneous use. the operating system needs to accept interrupts at almost all times otherwise input might be lost or output overwritten. so that these sections of code are not accessed concurrently by several processes they disable interrupts at entry and reenable interrupts at exit. it is important to note that sections of code that disable interrupts do not occur very often and typically contain few instructions