 in general a multilevel feedback queue scheduler is defined by the following parameters the number of queues the scheduling algorithm for each queue the method used to determine when to upgrade a process to a higherpriority queue the method used to determine when to demote a process to a lowerpriority queue the method used to determine which queue a process will enter when that process needs service the definition of a multilevel feedback queue scheduler makes it the most general cpu scheduling algorithm. it can be configured to match a specific system under design. unfortunately it is also the most complex algorithm since defining the best scheduler requires some means by which to select values for all the parameters. . multiple processor scheduling our discussion thus far has focused on the problems of scheduling the cpu in a system with a single processor. if multiple cpus are available load sharing becomes possible however the scheduling problem becomes correspondingly more complex. many possibilities have been tried and as we saw with singleprocessor cpu scheduling there is no one best solution. here we discuss several concerns in multiprocessor scheduling. we concentrate on systems in which the processors are identical homogeneous in terms of their functionality we can then use any available processor to run any process in the queue. note however that even with homogeneous multiprocessors there are sometimes limitations on scheduling. consider a system with an i o device attached to a private bus of one processor. processes that wish to use that device must be scheduled to run on that processor. . . approaches to multiple processor scheduling one approach to cpu scheduling in a multiprocessor system has all scheduling decisions i o processing and other system activities handled by a single processor the master server. the other processors execute only user code. this asymmetric multiprocessing is simple because only one processor accesses the system data structures reducing the need for data sharing. a second approach uses symmetric multiprocessing smp where each processor is self scheduling. all processes may be in a common ready queue or each processor may have its own private queue of ready processes. regardless scheduling proceeds by having the scheduler for each processor examine the ready queue and select a process to execute. as we shall see in chapter if we have multiple processors trying to access and update a common data structure the scheduler must be programmed carefully we must ensure that chapter cpu scheduling two processors do not choose the same process and that processes are n t lost from the queue. virtually all modern operating systems support smp including windows xp windows solaris linux and mac os x. in the remainder of this section we will discuss issues concerning smp systems. . . processor affinity consider what happens to cache memory when a process has been running on a specific processor the data most recently accessed by the process populates the cache for the processor and as a result successive memory accesses by the process are often satisfied in cache memory. now consider what happens if the process migrates to another processor the contents of cache memory must be invalidated for the processor being migrated from and the cache for the processor being migrated to must be re populated. because of the high cost of invalidating and re populating caches most smp systems try to avoid migration of processes from one processor to another and instead attempt to keep a process running on the same processor. this is known as processor affinity meaning that a process has an affinity for the processor on which it is currently running. processor affinity takes several forms. when an operating system has a policy of attempting to keep a process running on the same processor but not guaranteeing that it will do so we have a situation known as soft affinity. here it is possible for a process to migrate between processors. some systems such as linux also provide system calls that support hard affinity thereby allowing a process to specify that it is not to migrate to other processors. . . load balancing on smp systems it is important to keep the workload balanced among all processors to fully utilize the benefits of having more than one processor. otherwise one or more processors may sit idle while other processors have high workloads along with lists of processes awaiting the cpu. load balancing attempts to keep the workload evenly distributed across all processors in an smp system. it is important to note that load balancing is typically only necessary on systems where each processor has its own private queue of eligible processes to execute. on systems with a common run queue load balancing is often unnecessary because once a processor becomes idle it immediately extracts a runnable process from the common run queue. it is also important to note however that in most contemporary operating systems supporting smp each processor does have a private queue of eligible processes. there are two general approaches to load balancing push migration and pull migration. with push migration a specific task periodically checks the load on each processor and if it finds an imbalance evenly distributes the load by moving or pushing processes from overloaded to idle or less busy processors. pull migration occurs when an idle processor pulls a waiting task from a busy processor. push and pull migration need not be mutually exclusive and are in fact often implemented in parallel on load balancing systems. for example the linux scheduler described in section . . and the ule scheduler available for freebsd systems implement both techniques. linux runs its load . multiple processor scheduling balancing algorithm every milliseconds push migration or whenever the run queue for a processor is empty pull migration . interestingly load balancing often counteracts the benefits of processor affinity discussed in section . . . that is the benefit of keeping a process running on the same processor is that the process can take advantage of its data being in that processor's cache memory. by either pulling or pushing a process from one processor to another we invalidate this benefit. as is often the case in systems engineering there is no absolute rule concerning what policy is best. thus in some systems an idle processor always pulls a process from a non idle processor and in other systems processes are moved only if the imbalance exceeds a certain threshold. . . symmetric multithreading smp systems allow several threads to run concurrently by providing multiple physical processors. an alternative strategy is to provide multiple logical rather than physical processors. such a strategy is known as symmetric multithreading or smt it has also been termed hyperthreading technology on intel processors. the idea behind smt is to create multiple logical processors on the same physical processor presenting a view of several logical processors to the operating system even on a system with only a single physical processor. each logical processor has its own architecture state which includes general purpose and machine state registers. furthermore each logical processor is responsible for its own interrupt handling meaning that interrupts are delivered to and handled by logical processors rather than physical ones. otherwise each logical processor shares the resources of its physical processor such as cache memory and buses. figure . illustrates a typical smt architecture with two physical processors each housing two logical processors. from the operating system's perspective four processors are available for work on this system. it is important to recognize that smt is a feature provided in hardware not software. that is hardware must provide the representation of the architecture state for each logical processor as well as interrupt handling. operating systems need not necessarily be designed differently if they are to run on an smt system however certain performance gains are possible if the operating system is aware that it is running on such a system. for example consider a system with two physical processors both of which are idle. the scheduler should first try scheduling separate threads on each physical processor rather logical logical logicali logical cpu cpu cpu physical m i gpu . cf system bus figure . a typical smt architecture chapter cpu scheduling than on separate logical processors on the same physical processor. otherwise both logical processors on one physical processor could be busy while the other physical processor remained idle