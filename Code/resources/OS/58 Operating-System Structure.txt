s if it is written in a higher level language. for example ms dos was wrftten in intel assembly language. consequently it is available on only the intel family of cpus. the linux operating system in contrast is written mostly in c and is available on a number of different cpus including intel x motorola x sparc and mips rxoo . the only possible disadvantages of implementing an operating system in a higher level language are reduced speed and increased storage requirements. this however is no longer a major issue in today's systems. although an expert assembly language programmer can produce efficient small routines for large programs a modern compiler can perform complex analysis and apply sophisticated optimizations that produce excellent code. modern processors have deep pipelining and multiple functional units that can handle complex dependencies that can overwhelm the limited ability of the human mind to keep track of details. as is true in other systems major performance improvements in operating systems are more likely to be the result of better data structures and algorithms than of excellent assembly language code. in addition although operating systems are large only a small amount of the code is critical to high performance the memory manager and the cpu scheduler are probably the most critical routines. after the system is written and is working correctly bottleneck routines can be identified and can be replaced with assembly language equivalents. to identify bottlenecks we must be able to monitor system performance. code must be added to compute and display measures of system behavior. in a number of systems the operating system does this task by producing trace listings of system behavior. all interesting events are logged with their time and important parameters and are written to a file. later an analysis program can process the log file to determine system performance and to identify bottlenecks and inefficiencies. these same traces can be run as input for a simulation of a suggested improved system. traces also can help people to find errors in operating system behavior. . operating system structure a system as large and complex as a modern operating system must be engineered carefully if it is to function properly and be modified easily. a common approach is to partition the task into small components rather than have one monolithic system. each of these modules should be a well defined portion of the system with carefully defined inputs outputs and functions. we have already discussed briefly in chapter the common components of operating systems. in this section we discuss how these components are interconnected and melded into a kernel. . . simple structure many commercial systems do not have well defined structures. frequently such operating systems started as small simple and limited systems and then grew beyond their original scope. ms dos is an example of such a system. it was originally designed and implemented by a few people who had no idea that it would become so popular. it was written to provide the most functionality in . operating system structure application program resident system program rom bios device drivers figure . ms dos layer structure. the least space so it was not divided into modules carefully. figure . shows its structure. in ms dos the interfaces and levels of functionality are not well separated. for instance application programs are able to access the basic i o routines to write directly to the display and disk drives. such freedom leaves ms dos vulnerable to errant or malicious programs causing entire system crashes when user programs fail. of course ms dos was also limited by the hardware of its era. because the intel for which it was written provides no dual mode and no hardware protection the designers of ms dos had no choice but to leave the base hardware accessible. another example of limited structuring is the original unix operating system. unix is another system that initially was limited by hardware functionality. it consists of two separable parts the kernel and the system programs. the kernel is further separated into a series of interfaces and device drivers which have been added and expanded over the years as unix has evolved. we can view the traditional unix operating system as being layered as shown in figure . . everything below the system call interface and above the physical hardware is the kernel. the kernel provides the file system cpu scheduling memory management and other operating system functions through system calls. taken in sum that is an enormous amount of functionality to be combined into one level. this monolithic structure was difficult to implement and maintain. . . layered approach with proper hardware support operating systems can be broken into pieces that are smaller and more appropriate than those allowed by the original ms dos or unix systems. the operating system can then retain much greater control over the computer and over the applications that make use of that computer. implementers have more freedom in changing the inner workings of the system and in creating modular operating systems. under the topdown approach the overall functionality and features are determined and are chapter operating system structures the users shells and commands compilers and interpreters . system libraries system call interface to the kernel signals terminal file system cpu scheduling handling swapping block i o page replacement character i o system system demand paging terminal drivers disk and tape drivers virtual memory kernel interface to the hardware terminal controllers device controllers memory controllers terminals disks and tapes physical memory figure . unix system structure. separated into components. information hiding is also important because it leaves programmers free to implement the low level routines as they see fit provided that the external interface of the routine stays unchanged and that the routine itself performs the advertised task. a system can be made modular in many ways. one method is the layered approach in which the operating system is broken up into a number of layers levels . the bottom layer layer is the hardware the highest layer n is the user interface. this layering structure is depicted in figure . . an operating system layer is an implementation of an abstract object made up of data and the operations that can manipulate those data. a typical operating system layer say layer m consists of data structures and a set of routines that can be invoked by higher level layers. layer m in turn can invoke operations on lower level layers. the main advantage of the layered approach is simplicity of construction and debugging. the layers are selected so that each uses functions operations and services of only lower level layers. this approach simplifies debugging and system verification. the first layer can be debugged without any concern for the rest of the system because by definition it uses only the basic hardware which is assumed correct to implement its functions. once the first layer is debugged its correct functioning can be assumed while the second layer is debugged and so on. if an error is found during the debugging of a particular layer the error must be on that layer because the layers below it are already debugged. thus the design and implementation of the system is simplified. each layer is implemented with only those operations provided by lowerlevel layers. a layer does not need to know how these operations are implemented it needs to know only what these operations do. hence each layer hides the existence of certain data structures operations and hardware from higher level layers. the major difficulty with the layered approach involves appropriately defining the various layers. because a layer can use only lower level layers careful planning is necessary. for example the device driver for the backing . operating system structure ' layer hardware i figure . a layered operating system. store disk space used by virtual memory algorithms must be at a lower level than the memory management routines because memory management requires the ability to use the backing store. other requirements may not be so obvious. the backing store driver would normally be above the cpu scheduler because the driver may need to wait for i o and the cpu can be rescheduled during this time. however on a large system the cpu scheduler may have more information about all the active processes than can fit in memory. therefore this information may need to be swapped in and out of memory requiring the backing store driver routine to be below the cpu scheduler. a final problem with layered implementations is that they tend to be less efficient than other types. for instance when a user program executes an i o operation it executes a system call that is trapped to the i o layer which calls the memory management layer which in turn calls the cpu scheduling layer which is then passed to the hardware. at each layer the parameters may be modified data may need to be passed and so on. each layer adds overhead to the system call the net result is a system call that takes longer than does one on a nonlayered system. these limitations have caused a small backlash against layering in recent years. fewer layers with more functionality are being designed providing most of the advantages of modularized code while avoiding the difficult problems of laver definition and interaction. . . microkernels we have already seen that as unix expanded the kernel became large and difficult to manage. in the mid s researchers at carnegie mellon university developed an operating system called mach that modularized the kernel using the microkernel approach. this method structures the operating system by removing all nonessential components from the kernel and chapter operating system structures implementing them as system and user level programs. the result is a smaller kernel. there is little consensus regarding which services should remain in the kernel and which should be implemented in user space. typically however microkernels provide minimal process and memory management in addition to a communication facility. the main function of the microkernel is to provide a communication facility between the client program and the various services that are also running in user space. communication is provided by message passing which was described in section . . . for example if the client program wishes to access a file it must interact with the file server. the client program and service never interact directly. rather they communicate indirectly by exchanging messages with the microkernel. one benefit of the microkernel approach is ease of extending the operating system. all new services are added to user space and consequently do not require modification of the kernel. when the kernel does have to be modified the changes tend to be fewer because the microkernel is a smaller kernel. the resulting operating system is easier to port from one hardware design to another. the microkernel also provides more security and reliability since most services are running as user rather than kernel processes. if a service fails the rest of the operating system remains untouched. several contemporary operating systems have used the microkernel approach. tru unix formerly digital unix provides a unix interface to the user but it is implemented with a mach kernel. the mach kernel maps unix system calls into messages to the appropriate user level services. another example is qnx. qnx is a real time operating system that is also based on the microkernel design. the qnx microkernel provides services for message passing and process scheduling. it also handles low level network communication and hardware interrupts. all other services in qnx are provided by standard processes that run outside the kernel in user mode. unfortunately microkernels can suffer from performance decreases due to increased system function overhead. consider the history of windows nt. the first release had a layered microkernel organization. however this version delivered low performance compared with that of windows . windows nt . partially redressed the performance problem by moving layers from user space to kernel space and integrating them more closely. by the time windows xp was designed its architecture was more monolithic than microkernel. . . modules perhaps the best current methodology for operating system design involves using object oriented programming techniques to create a modular kernel. here the kernel has a set of core components and dynamically links in additional services either during boot time or during run time. such a strategy uses dynamically loadable modules and is common in modern implementations of unix such as solaris linux and mac os x. for example the solaris operating system structure shown in figure . is organized around a core kernel with seven types of loadable kernel modules . scheduling classes . file systems . operating system structure figure . solaris loadable modules. . loadable system calls . executable formats . streams modules . miscellaneous . device and bus drivers such a design allows the kernel to provide core services yet also allows certain features to be implemented dynamically. for example device and bus drivers for specific hardware can be added to the kernel and support for different file systems can be added as loadable modules. the overall result resembles a layered system in that each kernel section has defined protected interfaces but it is more flexible than a layered system in that any module can call any other module. furthermore the approach is like the microkernel approach in that the primary module has only core functions and knowledge of how to load and communicate with other modules but it is more efficient because modules do not need to invoke message passing in order to communicate. the apple macintosh mac os x operating system uses a hybrid structure. mac os x also known as danvin structures the operating system using a layered technique where one layer consists of the mach microkernel. the structure of mac os x appears in figure . . the top layers include application environments and a set of services providing a graphical interface to applications. below these layers is the kernel environment which consists primarily of the mach microkernel and the bsd kernel. mach provides memory management support for remote procedure calls rpcs and interprocess communication ipc facilities including message passing and thread scheduling. the bsd component provides a bsd command line interface support for networking and file systems and an implementation of posix apis including pthreads. in addition to mach and bsd the kernel environment provides an i o kit for development of device drivers and dynamically loadable modules which mac os x refers to as kernel extensions . as shown in the figure applications and common services can make use of either the mach or bsd facilities directly. chapter operating system structures application environments and common services ik i r r kernel bsd environment i .. .. p . .ijl l. .. ... .. i figure . the mac os x structure