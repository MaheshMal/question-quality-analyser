 in this section we discuss some of the issues to consider with multithreaded programs. . . the fork and exec system calls in chapter we described how the forkq system call is used to create a separate duplicate process. the semantics of the f ork and exec system calls change in a multithreaded program. if one thread in a program calls f ork does the new process duplicate all threads or is the new process single threaded? some unix systems have chosen to have two versions of forkq one that duplicates all threads and another that duplicates only the thread that invoked the forko system call. the execo system call typically works in the same way as described in chapter . that is if a thread invokes the exec system call the program specified in the parameter to exec will replace the entire process including all threads. which of the two versions of f orko to use depends on the application. if execo is called immediately after forking then duplicating all threads is unnecessary as the program specified in the parameters to exec will replace the process. in this instance duplicating only the calling thread is appropriate. if however the separate process does not call exec after forking the separate process should duplicate all threads. . threading issues . . cancellation ? thread cancellation is the task of terminating a thread before it has completed. for example if multiple threads are concurrently searching through a database and one thread returns the result the remaining threads might be canceled. f another situation might occur when a user presses a button on a web browser i that stops a web page from loading any further. often a web page is loaded using several threads each image is loaded in a separate thread. when a user presses the stop button on the browser all threads loading the page are . canceled. a thread that is to be canceled is often referred to as the target thread. cancellation of a target thread may occur in two different scenarios . asynchronous cancellation. one thread immediately terminates the target thread. . deferred cancellation. the target thread periodically checks whether it should terminate allowing it an opportunity to terminate itself in an orderly fashion. the difficulty with cancellation occurs in situations where resources have been allocated to a canceled thread or where a thread is canceled while in the midst of updating data it is sharing with other threads. this becomes especially troublesome with asynchronous cancellation. often the operating system will reclaim system resources from a canceled thread but will not reclaim all resources. therefore canceling a thread asynchronously may not free a necessary system wide resource. with deferred cancellation in contrast one thread indicates that a target thread is to be canceled but cancellation occurs only after the target thread has checked a flag to determine if it should be canceled or not. this allows a thread to check whether it should be canceled at a point when it can be canceled safely. pthreads refers to such points as cancellation points. . . signal handling a signal is used in unix systems to notify a process that a particular event has occurred. a signal may be received either synchronously or asynchronously 't depending on the source of and the reason for the event being signaled. all i signals whether synchronous or asynchronous follow the same pattern i i. . a signal is generated by the occurrence of a particular event. . a generated signal is delivered to a process. . once delivered the signal must be handled. examples of synchronous signals include illegal memory access and division by . if a running program performs either of these actions a signal is generated. synchronous signals are delivered to the same process that i performed the operation that caused the signal that is the reason they are considered synchronous . chapter threads when a signal is generated by an event external to a running process that process receives the signal asynchronously. examples of such signals iiiclude terminating a process with specific keystrokes such as control c and having a timer expire. typically an asynchronous signal is sent to another process. every signal may be handled by one of two possible handlers . a default signal handler . a user defined signal handler every signal has a default signal handler that is run by the kernel when handling that signal. this default action can be overridden by a user defined signal handler that is called to handle the signal. signals may be handled in different ways. some signals such as changing the size of a window may simply be ignored others such as an illegal memory access may be handled by terminating the program. handling signals in single threaded programs is straightforward signals are always delivered to a process. however delivering signals is more complicated in multithreaded programs where a process may have several threads. where then should a signal be delivered? in general the following options exist . deliver the signal to the thread to which the signal applies. . deliver the signal to every thread in the process. . deliver the signal to certain threads in the process. . assign a specific thread to receive all signals for the process. the method for delivering a signal depends on the type of signal generated. for example synchronous signals need to be delivered to the thread causing the signal and not to other threads in the process. however the situation with asynchronous signals is not as clear. some asynchronous signals such as a signal that terminates a process control c for example should be sent to all threads. most multithreaded versions of unix allow a thread to specify which signals it will accept and which it will block. therefore in some cases an asynchronous signal may be delivered only to those threads that are not blocking it. however because signals need to be handled only once a signal is typically delivered only to the first thread found that is not blocking it. the standard unix function for delivering a signal is k i l l aid t aid int signal here we specify the process aid to which a particular signal is to be delivered. however posix pthreads also provides the p t h r e a d j k i l l p t h r e a d t tid int signal function which allows a signal to be delivered to a specified thread tid. although windows does not explicitly provide support for signals they can be emulated using asynchronous procedure calls apcs . the apc facility allows a user thread to specify a function that is to be called when the user thread receives notification of a particular event. as indicated by its name an apc is roughly equivalent to an asynchronous signal in unix. however . threading issues whereas unix must contend with how to deal with signals in a multithreaded environment the apc facility is more straightforward as an apc is delivered to a particular thread rather than a process. . . thread pools in section . we mentioned multithreading in a web server. in this situation whenever the server receives a request it creates a separate thread to service the request. whereas creating a separate thread is certainly superior to creating a separate process a multithreaded server nonetheless has potential problems. the first concerns the amount of time required to create the thread prior to servicing the request together with the fact that this thread will be discarded once it has completed its work. the second issue is more troublesome if we allow all concurrent requests to be serviced in a new thread we have not placed a bound on the number of threads concurrently active in the system. unlimited threads could exhaust system resources such as cpu time or memory. one solution to this issue is to use a thread pool. the general idea behind a thread pool is to create a number of threads at process startup and place them into a pool where they sit and wait for work. when a server receives a request it awakens a thread from this pool if one is available and passes it the request to service. once the thread completes its service it returns to the pool and awaits more work. if the pool contains no available thread the server waits until one becomes free. thread pools offer these benefits . servicing a request with an existing thread is usually faster than waiting to create a thread. . a thread pool limits the number of threads that exist at any one point. this is particularly important on systems that cannot support a large number of concurrent threads. the number of threads in the pool can be set heuristically based on factors such as the number of cpus in the system the amount of physical memory and the expected number of concurrent client requests. more sophisticated thread pool architectures can dynamically adjust the number of threads in the pool according to usage patterns. such architectures provide the further benefit of having a smaller pool thereby consuming less memory when the load on the system is low. the win api provides several functions related to thread pools. using the thread pool api is similar to creating a thread with the thread create function as described in section . . . here a function that is to run as a separate thread is defined. such a function may appear as follows dword winapi poolfunction avoid param this function runs as a separate thread. a pointer to poolfunctionq is passed to one of the functions in the thread pool api and a thread from the pool executes this function. one such member chapter threads in the thread pool api is the queueuserworkltemo function which is passed three parameters lpthread start routine function a pointer to the function that is to run as a separate thread pvoid param the parameter passed to function ulong flags flags indicating how the thread pool is to create and manage execution of the thread an example of an invocation is queueuserworkltemc poolfunction null this causes a thread from the thread pool to invoke poolfunction on behalf of the programmer. in this instance we pass no parameters to poolfunct i o n . because we specify as a flag we provide the thread pool with no special instructions for thread creation. other members in the win thread pool api include utilities that invoke functions at periodic intervals or when an asynchronous i o request completes. the j a v a . u t i l . concurrent package in java . provides a thread pool utility as well. . . thread specific data threads belonging to a process share the data of the process. indeed this sharing of data provides one of the benefits of multithreaded programming. however in some circumstances each thread might need its own copy of certain data. we will call such data thread specific data. for example in a transaction processing system we might service each transaction in a separate thread. furthermore each transaction may be assigned a unique identifier. to associate each thread with its unique identifier we could use thread specific data. most thread libraries including win and pthreads provide some form of support for thread specific data. java provides support as well. . . scheduler activations a final issue to be considered with multithreaded programs concerns communication between the kernel and the thread library which may be required by the many to many and two level models discussed in section . . . such coordination allows the number of kernel threads to be dynamically adjusted to help ensure the best performance. many systems implementing either the many to many or two level model place an intermediate data structure between the user and kernel threads. this data structure typically known as a lightweight process or lwp is shown in figure . . to the user thread library the lwp appears to be a virtual processor on which the application can schedule a user thread to run. each lwp is attached to a kernel thread and it is kernel threads that the operating system schedules to run on physical processors. if a kernel thread blocks such as while waiting for an i o operation to complete the lwp blocks as well. up the chain the user level thread attached to the lwp also blocks