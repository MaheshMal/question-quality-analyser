 data link layer header network layer header transport layer header session layer header presentation layer application layer message data link layer trailer figure . an iso network message. has been adopted by virtually all internet sites. the tcp ip protocol stack has fewer layers than does the iso model. theoretically because it combines several functions in each layer it is more difficult to implement but more efficient than iso networking. the relationship between the iso and tcp ip models is shown in figure . . the tcp ip application layer identifies several protocols in widespread use in the internet including http ftp telnet dns and smtp. the transport layer identifies the unreliable connectionless user datagram protocol udp and the reliable connection oriented transmission control protocol tcp . the internet protocol ip is responsible for routing ip datagrams through the internet. the tcp ip model does not formally identify a link or physical layer allowing tcp ip traffic to run across any physical network. in section . we consider the tcp ip model running over an ethernet network. . robustness a distributed system may suffer from various types of hardware failure. the failure of a link the failure of a site and the loss of a message are the most common types. to ensure that the system is robust we must detect any of these failures reconfigure the system so that computation can continue and recover when a site or a link is repaired. . . failure detection in an environment with no shared memory we are generally unable to differentiate among link failure site failure and message loss. we can usually detect only that one of these failures has occurred. once a failure has been detected appropriate action must be taken. what action is appropriate depends on the particular application. chapter distributed system structures iso t cp ip http dns telnet smtp ftp not defined session not defined data lartk not defined physical not defined figure . the iso and tcp ip protocol stacks. to detect link and site failure we use a handshaking procedure. suppose that sites a and b have a direct physical link between them. at fixed intervals the sites send each other an l am up message. if site a does not receive this message within a predetermined time period it can assume that site b has failed that the link between a and b has failed or that the message from b has been lost. at this point site a has two choices. it can wait for another time period to receive an l am up message from b or it can send an are you up? message to b. if time goes by and site a still has not received an l am up message or if site a has sent an are you up? message and has not received a reply the procedure can be repeated. again the only conclusion that site a can draw safely is that some type of failure has occurred. site a can try to differentiate between link failure and site failure by sending an are you up? message to b by another route if one exists . if and when b receives this message it immediately replies positively. this positive reply tells a that b is up and that the failure is in the direct link between them. since we do not know in advance how long it will take the message to travel from a to b and back we must use a time out scheme. at the time a sends the are you up? message it specifies a time interval during which it is willing to wait for the reply from b. if a receives the reply message within that time interval then it can safely conclude that b is up. if not however that is if a time out occurs then a may conclude only that one or more of the following situations has occurred site b is down. the direct link if one exists from a to b is down. . design issues the alternative path from a to b is down. the message has been lostsite a cannot however determine which of these events has occurred. . . reconfiguration suppose that site a has discovered through the mechanism described in the previous section that a failure has occurred. it must then initiate a procedure that will allow the system to reconfigure and to continue its normal mode of operation. if a direct link from a to b has failed this information must be broadcast to every site in the system so that the various routing tables can be updated accordingly. if the system believes that a site has failed because that site can be reached no longer then all sites in the system must be so notified so that they will no longer attempt to use the services of the failed site. the failure of a site that serves as a central coordinator for some activity such as deadlock detection requires the election of a new coordinator. similarly if the failed site is part of a logical ring then a new logical ring must be constructed. note that if the site has not failed that is if it is up but cannot be reached then we may have the undesirable situation where two sites serve as the coordinator. when the network is partitioned the two coordinators each for its own partition may initiate conflicting actions. for example if the coordinators are responsible for implementing mutual exclusion we may have a situation where two processes are executing simultaneously in their critical sections. . . recovery from failure when a failed link or site is repaired it must be integrated into the system gracefully and smoothly. suppose that a link between a and b has failed. when it is repaired both a and b must be notified. we can accomplish this notification by continuously repeating the handshaking procedure described in section . . . suppose that site b has failed. when it recovers it must notify all other sites that it is up again. site b then may have to receive information from the other sites to update its local tables for example it may need routing table information a list of sites that are down or undelivered messages and mail. if the site has not failed but simply could not be reached then this information is still required. . design issues making the multiplicity of processors and storage devices transparent to the users has been a key challenge to many designers. ideally a distributed system chapter distributed system structures should look to its users like a conventional centralized system. the user interface of a transparent distributed system should not distinguish between local and remote resources. that is users should be able to access remote resources as though these resources were local and the distributed system should be responsible for locating the resources and for arranging for the appropriate interaction. another aspect of transparency is user mobility it would be convenient to allow users to log into any machine in the system rather than forcing them to use a specific machine. a transparent distributed system facilitates user mobility by bringing over the user's environment for example home directory to wherever she logs in. both the andrew file system from cmu and project athena from met provide this functionality on a large scale nfs can provide it on a smaller scale. another design issue involves fault tolerance. we use the termfault tolerance in a broad sense. communication faults machine failures of type fail stop storage device crashes and decays of storage media should all be tolerated to some extent. a fault tolerant system should continue to function perhaps in a degraded form when faced with these failures. the degradation can be in performance in functionality or in both. it should be proportional however to the failures that cause it. a system that grinds to a halt when only a few of its components fail is certainly not fault tolerant. unfortunately fault tolerance is difficult to implement. most commercial systems provide only limited fault tolerance. for instance the dec vax cluster allows multiple computers to share a set of disks. if a system crashes users can still access their information from another system. of course if a disk fails all systems will lose access. but in this case raid can ensure continued access to the data even in the event of a failure section . . still another issue is scalability the capability of a system to adapt to increased service load. systems have bounded resources and can become completely saturated under increased load. for example regarding a file system saturation occurs either when a server's cpu runs at a high utilization rate or when disks are almost full. scalability is a relative property but it can be measured accurately. a scalable system reacts more gracefully to increased load than does a nonscalable one. first its performance degrades more moderately and second its resources reach a saturated state later. even perfect design cannot accommodate an ever growing load. adding new resources might solve the problem but it might generate additional indirect load on other resources for example adding machines to a distributed system can clog the network and increase service loads . even worse expanding the system can call for expensive design modifications. a scalable system should have the potential to grow without these problems. in a distributed system the ability to scale up gracefully is of special importance since expanding the network by adding new machines or interconnecting two networks is commonplace. in short a scalable design should withstand high service load accommodate growth of the user community and enable simple integration of added resources. fault tolerance and scalability are related to each other. a heavily loaded component can become paralyzed and behave like a faulty component. also shifting the load from a faulty component to that component's backup can saturate the latter. generally having spare resources is essential for ensuring reliability as well as for handling peak loads gracefully an inherent advantage . design issues of a distributed system is a potential for fault tolerance and scalability because of the multiplicity of resources. however inappropriate design can obscure this potential. fault tolerance and scalability considerations call for a design demonstrating distribution of control and data. very large scale distributed systems to a great extent are still only theoretical. no magic guidelines ensure the scalability of a system. it is easier to point out why current designs are not scalable. we next discuss several designs that pose problems and propose possible solutions all in the context of scalability. one principle for designing very large scale systems is that the service demand from any component of the system should be bounded by a constant that is independent of the number of nodes in the system. any service mechanism whose load demand is proportional to the size of the system is destined to become clogged once the system grows beyond a certain size. adding more resources will not alleviate such a problem. the capacity of this mechanism simply limits the growth of the system. central control schemes and central resources should not be used to build scalable and fault tolerant systems. examples of centralized entities are central authentication servers central naming servers and central file servers. centralization is a form of functional asymmetry among machines constituting the system. the ideal alternative is a functionally symmetric configuration that is all the component machines have an equal role in the operation of the system and hence each machine has some degree of autonomy. practically it is virtually impossible to comply with such a principle. for instance incorporating diskless machines violates functional symmetry since the workstations depend on a central disk. however autonomy and symmetry are important goals to which we should aspire. the practical approximation of symmetric and autonomous configuration is clustering in which the system is partitioned into a collection of semiautonomous clusters. a cluster consists of a set of machines and a dedicated cluster server. so that cross cluster resource references are relatively infrequent each cluster server should satisfy requests of its own machines most of the time. of course this scheme depends on the ability to localize resource references and to place the component units appropriately. if the cluster is well balanced that is if the server in charge suffices to satisfy all the cluster demands it can be used as a modular building block to scale up the system. deciding on the process structure of the server is a major problem in the design of any service. servers are supposed to operate efficiently in peak periods when hundreds of active clients need to be served simultaneously. a single process server is certainly not a good choice since whenever a request necessitates disk i o the whole service will be blocked. assigning a process for each client is a better choice however the expense of frequent context switches between the processes must be considered. a related problem occurs because all the server processes need to share information. one of the best solutions for the server architecture is the use of lightweight processes or threads which we discussed in chapter . we can think of a group of lightweight processes as multiple threads of control associated with some shared resources. usually a lightweight process is not bound to a particular client. instead it serves single requests of different clients. scheduling of threads can be preemptive or nonpreemptive. if threads are allowed to run chapter distributed system structures to completion nonpreemptive then their shared data do not need to be protected explicitly. otherwise some explicit locking mechanism must be used. clearly some form of lightweight process scheme is essential if servers are to be scalable. . an example networking we now return to the name resolution issue raised in section . . and examine its operation with respect to the tcp ip protocol stack on the internet. we consider the processing needed to transfer a packet between hosts on different ethernet networks. in a tcp ip network every host has a name and an associated bit internet number or host id . both of these strings must be unique and so that the name space can be managed they are segmented. the name is hierarchical as explained in section . . describing the host name and then the organization with which the host is associated. the host id is split into a network number and a host number. the proportion of the split varies depending on the size of the network. once the internet administrators assign a network number the site with that number is free to assign host ids. the sending system checks its routing tables to locate a router to send the packet on its way. the routers use the network part of the host id to transfer the packet from its source network to the destination network. the destination system then receives the packet. the packet may be a complete message or it may just be a component of a message with more packets needed before the message can be reassembled and passed to the tcp udp layer for transmission to the destination process. now we know how a packet moves from its source network to its destination. within a network how does a packet move from sender host or router to receiver? every ethernet device has a unique byte number called the medium access control mac address assigned to it for addressing. two devices on a lan communicate with each other only with this number. if a system needs to send data to another system the kernel generates an address resolution protocol arp packet containing the ip address of the destination system. this packet is broadcast to all other systems on that ethernet network. a broadcast uses a special network address usually the maximum address to signal that all hosts should receive and process the packet. the broadcast is not re sent by gateways so only systems on the local network receive it. only the system whose ip address matches the ip address of the arp request responds and sends back its mac address to the system that initiated the query. for efficiency the host caches the ip mac address pair in an internal table. the cache entries are aged so that an entry is eventually removed from the cache if an access to that system is not required in a given time. in this way hosts that are removed from a network are eventually forgotten. for added performance arp entries for heavily used hosts may be hardwired in the arp cache. once an ethernet device has announced its host id and address communication can begin. a process may specify the name of a host with which to communicate. the kernel takes that name and determines the internet number of the target using a dks lookup. the message is passed from the application