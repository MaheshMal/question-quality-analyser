 the various hardware based solutions to the critical section problem using the testandsetc and swapo instructions presented in section . are complicated for application programmers to use. to overcome this difficulty we can use a synchronization tool called a semaphore. a semaphore s is an integer variable that apart from initialization is accessed only through two standard atomic operations wait and signal . the waito operation was originally termed p from the dutch probercn to test signal was originally called v from verhogen to increment . the definition of wait is as follows wait s while s no op s the definition of signal is as follows signal s s all the modifications to the integer value of the semaphore in the wait and signal operations must be executed indivisibly. that is when one process modifies the semaphore value no other process can simultaneously modify that same semaphore value. in addition in the case of wait s the testing of the integer value of s s and its possible modification s must also be executed without interruption. we shall see how these operations can be implemented in section . . first let us see how semaphores can be used. . semaphores . . usage ' operating systems often distinguish between counting and binary semaphores. the value of a counting semaphore can range over an unrestricted domain. the value of a binary semaphore can range only between and . on some systems binary semaphores are known as mutex locks as they are locks that provide mutual t'.rclusion. we can use binary semaphores to deal with the critical section problem for multiple processes. the n processes share a semaphore mutex initialized to . each process p is organized as shown in figure . . counting semaphores can be used to control access to a given resource consisting of a finite number of instances. the semaphore is initialized to the number of resources available. each process that wishes to use a resource performs a waitq operation on the semaphore thereby decrementing the count . when a process releases a resource it performs a signal operation incrementing the count . when the count for the semaphore goes to all resources are being used. after that processes that wish to use a resource will block until the count becomes greater than . we can also use semaphores to solve various synchronization problems. for example consider two concurrently running processes p with a statement si and pi with a statement si. suppose we require that so be executed only after si has completed. we can implement this scheme readily by letting pi and pi share a common semaphore synch initialized to and by inserting the statements si signal synch in process p and the statements wait synch si in process p?. because synch is initialized to p? will execute s only after p has invoked s i g n a l synch which is after statement si has been executed. do waiting mutex critical section signal mutex remainder section while true figure . mutual exclusion implementation with semaphores. chapter process synchronization . . implementation ? the main disadvantage of the semaphore definition given here is that it requires busy waiting. while a process is in its critical section any other process that tries to enter its critical section must loop continuously in the entry code. this continual looping is clearly a problem in a real multiprogramming system where a single cpu is shared among many processes. busy waiting wastes cpu cycles that some other process might be able to use productively. this type of semaphore is also called a spinlock because the process spins while waiting for the lock. spinlocks do have an advantage in that no context switch is required when a process must wait on a lock and a context switch may take considerable time. thus when locks are expected to be held for short times spinlocks are useful they are often employed on multiprocessor systems where one thread can spin on one processor while another thread performs its critical section on another processor. to overcome the need for busy waiting we can modify the definition of the wait and signal semaphore operations. when a process executes the wait operation and finds that the semaphore value is not positive it must wait. however rather than engaging in busy waiting the process can block itself. the block operation places a process into a waiting queue associated with the semaphore and the state of the process is switched to the waiting state. then control is transferred to the cpu scheduler which selects another process to execute. a process that is blocked waiting on a semaphore s should be restarted when some other process executes a signal operation. the process is restarted by a wakeup operation which changes the process from the waiting state to the ready state. the process is then placed in the ready queue. the cpu may or may not be switched from the running process to the newly ready process depending on the cpu scheduling algorithm. to implement semaphores under this definition we define a semaphore as a c struct typedef struct int value struct process list semaphore each semaphore has an integer value and a list of processes list. when a process must wait on a semaphore it is added to the list of processes. a signal operation removes one process from the list of waiting processes and awakens that process. the wait semaphore operation can now be defined as wait semaphore s s value if s value add this process to s list block . semaphores the signal semaphore operation can now be defined as signal semaphore s s value if s value remove a process p from s list wakeup p the blocko operation suspends the process that invokes it. the wakeup p operation resumes the execution of a blocked process p. these two operations are provided by the operating system as basic system calls. note that although under the classical definition of semaphores with busy waiting the semaphore value is never negative this implementation may have negative semaphore values. if the semaphore value is negative its magnitude is the number of processes waiting on that semaphore. this fact results from switching the order of the decrement and the test in the implementation of the waito operation. the list of waiting processes can be easily implemented by a link field in each process control block pcb . each semaphore contains an integer value and a pointer to a list of pcbs. one way to add and remove processes from the list in a way that ensures bounded waiting is to use a fifo queue where the semaphore contains both head and tail pointers to the queue. in general however the list can use any queueing strategy. correct usage of semaphores does not depend on a particular queueing strategy for the semaphore lists. the critical aspect of semaphores is that they be executed atomically we must guarantee that no two processes can execute waito and signal operations on the same semaphore at the same time. this is a critical section problem and in a single processor environment that is where only one cpu exists we can solve it by simply inhibiting interrupts during the time the wait and signal operations are executing. this scheme works in a singleprocessor environment because once interrupts are inhibited instructions from different processes cannot be interleaved. only the currently running process executes until interrupts are reenabled and the scheduler can regain control. in a multiprocessor environment interrupts must be disabled on every processor otherwise instructions from different processes running on different processors may be interleaved in some arbitrary way. disabling interrupts on every processor can be a difficult task and furthermore can seriously diminish performance. therefore smp systems must provide alternative locking techniques such as spinlocks to ensure that waito and signal are performed atomically. it is important to admit that we have not completely eliminated busy waiting with this definition of the waito and signal operations. rather we have removed busy waiting from the entry section to the critical sections of application programs. furthermore we have limited busy waiting to the critical sections of the wait and signal operations and these sections are short if properly coded they should be no more than about ten instructions . chapter process synchronization thus the critical section is almost never occupied and busy waiting occurs rarely and then for only a short time. an entirely different situation exists with application programs whose critical sections may be long minutes or even hours or may almost always be occupied. in such cases busy waiting is extremely inefficient. . . deadlocks and starvation the implementation of a semaphore with a waiting queue may result in a situation where two or more processes are waiting indefinitely for an event that can be caused only by one of the waiting processes. the event in question is the execution of a s i g n a l operation. when such a state is reached these processes are said to be deadlocked. to illustrate this we consider a system consisting of two processes pq and pi each accessing two semaphores s and q set to the value wait s wait q wait q wait s signal s signal q signal q signal s suppose that p executes wait s and then pi executes wait q . when po executes wait q it must wait until pi executes signal q . similarly when pi executes wait s it must wait until po executes signal s . since these s i g n a l operations cannot be executed po and pi are deadlocked. we say that a set of processes is in a deadlock state when every process in the set is waiting for an event that can be caused only by another process in the set. the events with which we are mainly concerned here are resource acquisition and release. however other types of events may result in deadlocks as we shall show in chapter . in that chapter we shall describe various mechanisms for dealing with the deadlock problem. another problem related to deadlocks is indefinite blocking or starvation a situation in which processes wait indefinitely within the semaphore. indefinite blocking may occur if we add and remove processes from the list associated with a semaphore in lifo last in first out order. . classic problems of synchronization in this section we present a number of synchronization problems as examples of a large class of concurrency control problems. these problems are used for testing nearly every newly proposed synchronization scheme. in our solutions to the problems we use semaphores for synchronization. . classic problems of synchronization do produce an item in nextp wait empty wait mutex add nextp to buffer signal mutex signal full while true figure . the structure of the producer process. . . the bounded buffer problem the bounded buffer problem was introduced in section . it is commonly used to illustrate the power of synchronization primitives. we present here a general structure of this scheme without committing ourselves to any particular implementation we provide a related programming project in the exercises at the end of the chapter. we assume that the pool consists of n buffers each capable of holding one item. the mutex semaphore provides mutual exclusion for accesses to the buffer pool and is initialized to the value . the empty and f u l l semaphores count the number of empty and full buffers. the semaphore empty is initialized to the value n the semaphore f u l l is initialized to the value . the code for the producer process is shown in figure . the code for the consumer process is shown in figure . . note the symmetry between the producer and the consumer. we can interpret this code as the producer producing full buffers for the consumer or as the consumer producing empty buffers for the producer. do wait full wait mutex remove an item from buffer to nextc signal mutex signal empty consume the item in nextc while true figure . the structure of the consumer process. chapter process synchronization . . the readers writers problem a database is to be shared among several concurrent processes. some of these processes may want only to read the database whereas others may want to update that is to read and write the database. we distinguish between these two types of processes by referring to the former as readers and to the latter as writers. obviously if two readers access the shared data simultaneously no adverse affects will result. however if a writer and some other thread either a reader or a writer access the database simultaneously chaos may ensue. to ensure that these difficulties do not arise we require that the writers have exclusive access to the shared database. this synchronization problem is referred to as the readers writers problem. since it was originally stated it has been used to test nearly every new synchronization primitive. the readerswriters problem has several variations all involving priorities. the simplest one referred to as the first readers writers problem requires that no reader will be kept waiting unless a writer has already obtained permission to use the shared object. in other words no reader should wait for other readers to finish simply because a writer is waiting. the second readers writers problem requires that once a writer is ready that writer performs its write as soon as possible. in other words if a writer is waiting to access the object no new readers may start reading. a solution to either problem may result in starvation. in the first case writers may starve in the second case readers may starve. for this reason other variants of the problem have been proposed. in this section we present a solution to the first readers writers problem. refer to the bibliographical notes at the end of the chapter for references describing starvation free solutions to the second readers writers problem. in the solution to the first readers writers problem the reader processes share the following data structures semaphore mutex wrt int readcount the semaphores mutex and wrt are initialized to readcount is initialized to . the semaphore wrt is common to both reader and writer processes. the mutex semaphore is used to ensure mutual exclusion when the variable readcount is updated. the readcount variable keeps track of how many processes are currently reading the object. the semaphore wrt functions as a mutual exclusion semaphore for the writers. it is also used by the first or last do wait wrt writing is performed signal wrt while true figure . the structure of a writer process. . classic problems of synchronization do wait mutex readcount if readcount wait wrt signal mutex reading is performed wait mutex readcount if readcount signal wrt signal mutex jwhile true figure . the structure of a reader process. reader that enters or exits the critical section. it is not used by readers who enter or exit while other readers are in their critical sections. the code for a writer process is shown in figure . the code for a reader process is shown in figure . . note that if a writer is in the critical section and n readers are waiting then one reader is queued on wrt and n readers are queued on mutex. also observe that when a writer executes s i g n a l wrt we may resume the execution of either the waiting readers or a single waiting writer. the selection is made by the scheduler. the readers writers problem and its solutions has been generalized to provide reader writer locks on some systems. acquiring a reader writer lock requires specifying the mode of the lock either read or write access. when a process only wishes to read shared data it requests the reader wrriter lock in read mode a process wishing to modify the shared data must request the lock in write mode. multiple processes are permitted to concurrently acquire a reader writer lock in read mode only one process may acquire the lock for writing as exclusive access is required for writers. reader writer locks are most useful in the following situations in applications where it is easy to identify which processes only read shared data and which threads only write shared data. in applications that have more readers than writers. this is because readerwriter locks generally require more overhead to establish than semaphores or mutual exclusion locks and the overhead for setting up a reader writer lock is compensated by the increased concurrency of allowing multiple readers. . . the dining philosophers problem consider five philosophers who spend their lives thinking and eating. the philosophers share a circular table surrounded by five chairs each belonging to one philosopher. in the center of the table is a bowl of rice and the table is laid chapter process synchronization o o figure . the situation of the dining philosophers. with five single chopsticks figure . . when a philosopher thinks she does not interact with her colleagues. from time to time a philosopher gets hungry and tries to pick up the two chopsticks that are closest to her the chopsticks that are between her and her left and right neighbors . a philosopher may pick up only one chopstick at a time. obviously she cannot pick up a chopstick that is already in the hand of a neighbor. when a hungry philosopher has both her chopsticks at the same time she eats without releasing her chopsticks. when she is finished eating she puts down both of her chopsticks and starts thinking again. the dining philosophers problem is considered a classic synchronization problem neither because of its practical importance nor because computer scientists dislike philosophers but because it is an example of a large class of concurrency control problems. it is a simple representation of the need to allocate several resources among several processes in a deadlock free and starvation free manner. one simple solution is to represent each chopstick with a semaphore. a philosopher tries to grab a chopstick by executing a wait operation on that semaphore she releases her chopsticks by executing the signal operation on the appropriate semaphores. thus the shared data are semaphore chopstick where all the elements of chopstick are initialized to . the structure of philosopher is shown in figure . . although this solution guarantees that no two neighbors are eating simultaneously it nevertheless must be rejected because it could create a deadlock. suppose that all five philosophers become hungry simultaneously and each grabs her left chopstick. all the elements of chopstick will now be equal to . when each philosopher tries to grab her right chopstick she will be delayed forever. several possible remedies to the deadlock problem are listed next. in section . we present a solution to the dining philosophers problem that ensures freedom from deadlocks. allow at most four philosophers to be sitting simultaneously at the table