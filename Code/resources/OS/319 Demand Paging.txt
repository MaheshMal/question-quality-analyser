 . demand paging consider how an executable program might be loaded from disk into memory. one option is to load the entire program in physical memory at program execution time. however a problem with this approach is that we may not initially need the entire program in memory. consider a program that starts with a list of available options from which the user is to select. loading the entire program into memory results in loading the executable code for all options regardless of whether an option is ultimately selected by the user or not. an alternative strategy is to initially load pages only as they are needed. this technique is known as demand paging and is commonly used in virtual memory systems. with demand paged virtual memory pages are only loaded when they are demanded during program execution pages that are never accessed are thus never loaded into physical memory. a demand paging system is similar to a paging system with swapping figure . where processes reside in secondary memory usually a disk . when we want to execute a process we swap it into memory. rather than swapping the entire process into memory however we use a lazy swapper. a lazy swapper never swaps a page into memory unless that page will be needed. since we are now viewing a process as a sequence of pages rather than as one large contiguous address space use of the term swapper is technically incorrect. a swapper manipulates entire processes whereas a pager is concerned with the individual pages of a process. we thus use pager rather than swapper in connection with demand paging. program a program b prihkr main memory figure . transfer of a paged memory to contiguous disk space. chapter virtual memory . . basic concepts when a process is to be swapped in the pager guesses which pages will be used before the process is swapped out again. instead of swapping in a whole process the pager brings only those necessary pages into memory. thus it avoids reading into memory pages that will not be used anyway decreasing the swap rime and the amount of physical memory needed. with this scheme we need some form of hardware support to distinguish between the pages that are in memory and the pages that are on the disk. the valid invalid bit scheme described in section . can be used for this purpose. this time however when this bit is set to valid the associated page is both legal and in memory. if the bit is set to invalid the page either is not valid that is not in the logical address space of the process or is valid but is currently on the disk. the page table entry for a page that is brovight into memory is set as usual but the page table entry for a page that is not currently in memory is either simply marked invalid or contains the address of the page on disk. this situation is depicted in figure . . notice that marking a page invalid will have no effect if the process never attempts to access that page. hence if we guess right and page in all and only those pages that are actually needed the process will run exactly as though we had brought in all pages. while the process executes and accesses pages that are memory resident execution proceeds normally. a valid invalid b frame c a d e c f g h iff logical page table memory physical memory figure . page table when some pages are not in main memory. . demand paging physical memory figure . steps in handling a page fault. but what happens if the process tries to access a page that was not brought into memory? access to a page marked invalid causes a page fault trap. the paging hardware in translating the address through the page table will notice that the invalid bit is set causing a trap to the operating system. this trap is the result of the operating system's failure to bring the desired page into memory. the procedure for handling this page fault is straightforward figure . . we check an internal table usually kept with the process control block for this process to determine whether the reference was a valid or an invalid memory access. . if the reference was invalid we terminate the process. if it was valid but we have not yet brought in that page we now page it in. . we find a free frame by taking one from the free frame list for example . . we schedule a disk operation to read the desired page into the newly allocated frame. . when the disk read is complete we modify the internal table kept with the process and the page table to indicate that the page is now in memory. . we restart the instruction that was interrupted by the trap. the process can now access the page as though it had always been in memory. in the extreme case we can start executing a process with no pages in memory. when the operating system sets the instruction pointer to the first chapter virtual memory instruction of the process which is on a non memory resident page the process immediately faults for the page. after this page is brought into memory the process continues to execute faulting as necessary until every page that it needs is in memory. at that point it can execute with no more faults. this scheme is pure demand paging never bring a page into memory until it is required. theoretically some programs could access several new pages of memory with each instruction execution one page for the instruction and many for data possibly causing multiple page faults per instruction. this situation would result in unacceptable system performance. fortunately analysis of running processes shows that this behavior is exceedingly unlikely. programs tend to have locality of reference described in section . . which results in reasonable performance from demand paging. the hardware to support demand paging is the same as the hardware for paging and swapping page table. this table has the ability to mark an entry invalid through a valid invalid bit or special value of protection bits. secondary memory. this memory holds those pages that are not present in main memory. the secondary memory is usually a high speed disk. it is known as the swap device and the section of disk used for this purpose is known as swap space. swap space allocation is discussed in chapter . a crucial requirement for demand paging is the need to be able to restart any instruction after a page fault. because we save the state registers condition code instruction counter of the interrupted process when the page fault occurs we must be able to restart the process in exactly the same place and state except that the desired page is now in memory and is accessible. in most cases this requirement is easy to meet. a page fault may occur at any memory reference. if the page fault occurs on the instruction fetch we can restart byfetching the instruction again. if a page fault occurs while we are fetching an operand we must fetch and decode the instruction again and then fetch the operand. as a worst case example consider a three address instruction such as add the content of a to b placing the result in c. these are the steps to execute this instruction . fetch and decode the instruction add . . fetch a. . fetch b. . add a and b. . store the sum in c. if we fault when we try to store in c because c is in a page not currently in memory we will have to get the desired page bring it in correct the page table and restart the instruction. the restart will require fetching the instruction again decoding it again fetching the two operands again and . demand paging then adding again. however there is not much repeated work less than one complete instruction and the repetition is necessary only when a page fault occurs. the major difficulty arises when one instruction may modify several different locations. for example consider the ibm. system mvc move character instruction. which can move up to bytes from one location to another possibly overlapping location. if either block source or destination straddles a page boundary a page fault might occur after the move is partially done. in addition if the source and destination blocks overlap the source block may have been modified in which case we cannot simply restart the instruction. this problem can be solved in two different ways. in one solution the microcode computes and attempts to access both ends of both blocks. if a page fault is going to occur it will happen at this step before anything is modified. the move can then take place wre know that no page fault can occur since all the relevant pages are in memory. the other solution uses temporary registers to hold the values of overwritten locations. if there is a page fault all the old values are written back into memory before the trap occurs. this action restores memory to its state before the instruction was started so that the instruction can be repeated. this is by no means the only architectural problem resulting from adding paging to an existing architecture to allow demand paging but it illustrates some of the difficulties involved. paging is added between the cpu and the memory in a computer system. it should be entirely transparent to the user process. thus people often assume that paging can be added to any system. although this assumption is true for a non demand paging environment where a page fault represents a fatal error it is not true where a page fault means only that an additional page must be brought into memory and the process restarted. . . performance of demand paging demand paging can significantly affect the performance of a computer system. to see why let's compute the effective access time for a demand paged memory. for most computer systems the memory access time denoted ma ranges from to nanoseconds. as long as we have no page faults the effective access time is equal to the memory access time. if however a page fault occurs we must first read the relevant page from disk and then access the desired word. let p be the probability of a page fault s p . we would expect p to be close to zero that is we would expect to have only a few page faults. the effective access time is then effective access time p x ma p x page fault time. to compute the effective access time we must know how much time is needed to service a page fault. a page fault causes the following sequence to occur . trap to the operating system. . save the user registers and process state. chapter virtual memory . determine that the interrupt was a page fault. ' . check that the page reference was legal and determine the location of the page on the disk. . issue a read from the disk to a free frame a. wait in a queue for this device until the read request is serviced. b. wait for the device seek and or latency time. c. begin the transfer of the page to a free frame. . while waiting allocate the cpu to some other user cpu scheduling optional . . receive an interrupt from the disk i o subsystem i o completed . . save the registers and process state for the other user if step is executed . . determine that the interrupt was from the disk. . correct the page table and other tables to show that the desired page is now in memory. . wait for the cpu to be allocated to this process again. . restore the user registers process state and new page table and then resume the interrupted instruction. not all of these steps are necessary in every case. for example we are assuming that in step the cpu is allocated to another process while the i o occurs. this arrangement allows multiprogramming to maintain cpu utilization but requires additional time to resume the page fault service routine when the i o transfer is complete. in any case we are faced with three major components of the page fault service time . service the page fault interrupt. . read in the page. . restart the process. the first and third tasks can be reduced with careful coding to several hundred instructions. these tasks may take from to microseconds each. the page switch time however will probably be close to milliseconds. a typical hard disk has an average latency of milliseconds a seek of milliseconds and a transfer time of . milliseconds. thus the total paging time is about milliseconds including hardware and software time. remember also that we are looking at only the device service time. if a queue of processes is waiting for the device other processes that have caused page faults we have to add device queueing time as we wait for the paging device to be free to service our request increasing even more the time to swap. if we take an average page fault service time of milliseconds and a memory access time of nanoseconds then the effective access time in nanoseconds is