 historically ms dos systems have used the file allocation table fat file system. the bit fat file system has several shortcomings including internal fragmentation a size limitation of gb and a lack of access protection for files. the bit fat file system has solved the size and fragmentation problems but its performance and features are still weak by comparison with modern file systems. the ntfs file system is much better. it was designed to include many features including data recovery security fault tolerance large files and file systems multiple data streams unicode names sparse files encryption journaling volume shadow copies and file compression. windows xp uses ntfs as its basic file system and we focus on it here. windows xp continues to use fat however to read floppies and other removable media. and despite the advantages of ntfs fat continues to be important for interoperability of media with windows systems. windows xp supports additional file system types for the common formats used for cd and dvd media. . . ntfs internal layout the fundamental entity in ntfs is a volume. a volume is created by the windows xp logical disk management utility and is based on a logical disk . file system partition. a volume may occupy a portion of a disk may occupy an entire disk or may span several disks. ntfs does not deal with individual sectors of a disk but instead uses clusters as the units of disk allocation. a cluster is a number of disk sectors that is a power of . the cluster size is configured when an ntfs file system is formatted. the default cluster size is the sector size for volumes up to mb kb for volumes up to gb kb for volumes up to gb and kb for larger volumes. this cluster size is much smaller than that for the bit fat file system and the small size reduces the amount of internal fragmentation. as an example consider a . gb disk with files. if you use a fat file system mb may be lost to internal fragmentation because the cluster size is kb. under ntfs only mb would be lost when storing the same files. ntfs uses logical cluster numbers lcns as disk addresses. it assigns them by numbering clusters from the beginning of the disk to the end. using this scheme the system can calculate a physical disk offset in bytes by multiplying the lcn by the cluster size. a file in ntfs is not a simple byte stream as it is m ms dos or unix rather it is a structured object consisting of typed attributes. each attribute of a file is an independent byte stream that can be created deleted read and written. some attribute types are standard for all files including the file name or names if the file has aliases such as an ms dos shortname the creation time and the security descriptor that specifies access control. user data is stored in data attributes. most traditional data files have an unnamed data attribute that contains all the file's data. however additional data streams can be created with explicit names. for instance in macintosh files stored on a windows xp server the resource fork is a named data stream. the iprop interfaces of the component object model com use a named data stream to store properties on ordinary files including thumbnails of images. in general attributes may be added as necessary and are accessed using afile name attributesyntax. ntfs returns the size of the unnamed attribute only in response to file query operations such as when running the d i r command. every file in ntfs is described by one or more records in an array stored in a special file called the master file table mft . the size of a record is determined when the file system is created it ranges from to kb. small attributes are stored in the mft record itself and are called resident attributes. large attributes such as the unnamed bulk data are called nonresident attributes and are stored in one or more contiguous extents on the disk a pointer to each extent is stored in the mft record. for a small file even the data attribute may fit inside the mft record. if a file has many attributes or if it is highly fragmented so that many pointers are needed to point to all the fragments one record in the mft might not be large enough. in this case the file is described by a record called the base file record which contains pointers to overflow records that hold the additional pointers and attributes. each file in an ntfs volume has a unique id called a file reference. the file reference is a bit quantity that consists of a bit file number and a bit sequence number. the file number is the record number that is the array slot in the mft that describes the file. the sequence number is incremented every time an mft entry is reused. the sequence number enables ntfs to perform chapter windows xp internal consistency checks such as catching a stale reference to a deleted file after the mft entry has been reused for a new file. . . . ntfs b tree as in ms dos and unfix the ntfs namespace is organized as a hierarchy of directories. each directory uses a data structure called a b tree to store an index of the file names in that directory. a b tree is used because it eliminates the cost of reorganizing the tree and has the property that the length of every path from the root of the tree to a leaf is the same. the index root of a directory contains the top level of the b tree. for a large directory this top level contains pointers to disk extents that hold the remainder of the tree. each entry in the directory contains the name and file reference of the file as well as a copy of the update timestamp and file size taken from the file's resident attributes in the mft. copies of this information are stored in the directory so a directory listing can be efficiently generated. because all the file names sizes and update times are available from the directory itself there is no need to gather these attributes from the mft entries for each of the files. . . . ntfs metadata the ntfs volume's metadata are all stored in files. the first file is the mft. the second file which is used during recovery if the mft is damaged contains a copy of the first entries of the mft. the next few files are also special in purpose. they include the log file volume file attribute definition table root directory bitmap file boot file and bad cluster file. we describe the role of each of these files below. the log file records all metadata updates to the file system. the volume file contains the name of the volume the version of ntfs that formatted the volume and a bit that tells whether the volume may have been corrupted and needs to be checked for consistency. the attribute definition table indicates which attribute types are used in the volume and what operations can be performed on each of them. the root directory is the top level directory in the file system hierarchy. the bitmap file indicates which clusters on a volume are allocated to files and which are free. the boot file contains the startup code for windows xp and must be located at a particular disk address so that it can be found easily by a simple rom bootstrap loader. the boot file also contains the physical address of the mft. the bad cluster file keeps track of any bad areas on the volume ntfs uses this record for error recovery. . . recovery in many simple file systems a power failure at the wrong time can damage the file system data structures so severely that the entire volume is scrambled. . file system many versions of unix store redundant metadata on the disk and they recover from crashes using the f sck program to check all the file system data structures and restore them forcibly to a consistent state. restoring them often involves deleting damaged files and freeing data clusters that had been written with user data but not properly recorded in the file system's metadata structures. this checking can be a slow process and can cause the loss of significant amounts of data. ntfs takes a different approach to file system robustness. in ntfs all filesystem data structure updates are performed inside transactions. before a data structure is altered the transaction writes a log record that contains redo and undo information after the data structure has been changed the transaction writes a commit record to the log to signify that the transaction succeeded. after a crash the system can restore the file system data structures to a consistent state by processing the log records first redoing the operations for committed transactions and then undoing the operations for transactions that did not commit successfully before the crash. periodically usually every seconds a checkpoint record is written to the log. the system does not need log records prior to the checkpoint to recover from a crash. they can be discarded so the log file does not grow without bounds. the first time after system startup that an ntfs volume is accessed ntfs automatically performs file system recovery. this scheme does not guarantee that all the user file contents are correct after a crash it ensures only that the file system data structures the metadata files are undamaged and reflect some consistent state that existed prior to the crash. it would be possible to extend the transaction scheme to cover user files and microsoft may do so in the future. the log is stored in the third metadata file at the beginning of the volume. it is created with a fixed maximum size when the file system is formatted. it has two sections the logging area which is a circular queue of log records and the restart area which holds context information such as the position in the logging area where ntfs should start reading during a recovery. in fact the restart area holds two copies of its information so recovery is still possible if one copy is damaged during the crash. the logging functionality is provided by the windows xp log file service. in addition to writing the log records and performing recovery actions the log file service keeps track of the free space in the log file. if the free space gets too low the log file service queues pending transactions and ntfs halts all new i o operations. after the in progress operations complete ntfs calls the cache manager to flush all data then resets the log file and performs the queued transactions. . . security the security of an ntfs volume is derived from the windows xp object model. each ntfs file references a security descriptor which contains the access token of the owner of the file and an access control list which states the access privileges granted to each user having access to the file. in normal operation ntfs does not enforce permissions on traversal of directories in file path names. however for compatibility with posix these checks can be enabled. traversal checks are inherently more expensive chapter windows xp disk . gb disk . gb ' ' ' ' ' . . . . disk c fat gb ' . . ' . ' . ' . . ' . . ' ' . ' ' ' ' logical drive d ntfs gb ! lcns o i ! . . . . '' ' ' ' ' ' ' ' '' '. figure . volume set on two drives. since modern parsing of file path names uses prefix matching rather than component by component opening of directory names. . . volume management and fault tolerance ftdisk is the fault tolerant disk driver for windows xp. when installed it provides several ways to combine multiple disk drives into one logical volume so as to improve performance capacity or reliability. . . . volume set one way to combine multiple disks is to concatenate them logically to form a large logical volume as shown in figure . . in windows xp this logical volume called a volume set can consist of up to physical partitions. a volume set that contains an ntfs volume can be extended without disturbance of the data already stored in the file system. the bitmap metadata on the ntfs volume are simply extended to cover the newly added space. ntfs continues to use the same lcn mechanism that it uses for a single physical disk and the ftdisk driver supplies the mapping from a logical volume offset to the offset on one particular disk. . . . stripe set another way to combine multiple physical partitions is to interleave their blocks in round robin fashion to form what is called a stripe set as shown in figure . . this scheme is also called raid level or disk striping. ftdisk uses a stripe size of kb the first kb of the logical volume are stored in the first physical partition the second kb in the second physical partition and so on until each partition has contributed kb of space. then the allocation wraps around to the first disk allocating the second kb block. a stripe set forms one large logical volume but the physical layout can improve the i o bandwidth because for a large i o all the disks can transfer data in parallel. . file system disk gb disk gb lcns i logical drive c gb figure . stripe set on two drives. . . . stripe set with parity a variation of this idea is the stripe set with parity which is shown in figure . . this scheme is also called raid level . suppose that a stripe set has eight disks. seven of the disks will store data stripes with one data stripe on each disk and the eighth disk will store a parity stripe for each data stripe. the parity stripe contains the byte wise exclusive or of the data stripes. if any one of the eight stripes is destroyed the system can reconstrvict the data by calculating the exclusive or of the remaining seven. this ability to reconstruct data makes the disk array much less likely to lose data in case of a disk failure. notice that an update to one data stripe also requires recalculation of the parity stripe. seven concurrent writes to seven different data stripes thus would also require updates to seven parity stripes. if the parity stripes were all on the same disk that disk could have seven times the i o load of the data disks. to disk gb disk gb disk gb parity lcns lcns lcns parity lcns lcns lcns parity parity lgns lcns . . d logical drive c gb figure . stripe set with parity on three drives. chapter windows xp disk gb disk gb drive c gb copy of drive c gb figure . mirror set on two drives. avoid creating this bottleneck we spread the parity stripes over all the disks by assigning them in round robin style. to build a stripe set with parity we need a minimum of three equal sized partitions located on three separate disks. . . . disk mirroring an even more robust scheme is called disk mirroring or raid level it is depicted in figure . . a mirror set comprises two equal sized partitions on two disks. when an application writes data to a mirror set ftdisk writes the data to both partitions so that the data contents of the two partitions are identical. if one partition fails ftdisk has another copy safely stored on the mirror. mirror sets can also improve performance because read requests can be split between the two mirrors giving each mirror half of the workload. to protect against the failure of a disk controller we can attach the two disks of a mirror set to two separate disk controllers. this arrangement is called a duplex set. . . . sector sparing and cluster remapping to deal with disk sectors that go bad ftdisk uses a hardware technique called sector sparing and ntfs uses a software technique called cluster remapping. sector sparing is a hardware capability provided by many disk drives. when a disk drive is formatted it creates a map from logical block numbers to good sectors on the disk. it also leaves extra sectors unmapped as spares. if a sector fails ftdisk instructs the disk drive to substitute a spare. cluster remapping is a software technique performed by the file system. if a disk block goes bad ntfs substitutes a different unallocated block by changing any affected pointers in the mft. ntfs also makes a note that the bad block should never be allocated to any file. . file system when a disk block goes bad the usual outcome is a data loss. but sector sparing or cluster remapping can be combined with fault tolerant volumes to mask the failure of a disk block. if a read fails the system reconstructs the missing data by reading the mirror or by calculating the exclusive or parity in a stripe set with parity. the reconstructed data are stored into a new location that is obtained by sector sparing or cluster remapping. . . compression and encryption ntfs can perform data compression on individual files or on all data files in a directory. to compress a file ntfs divides the file's data into compression units which are blocks of contiguous clusters. when each compression unit is written a data compression algorithm is applied. if the result fits into fewer than clusters the compressed version is stored. when reading ntfs can determine whether data have been compressed if they have been the length of the stored compression unit is less than clusters. to improve performance when reading contiguous compression units ntfs prefetches and decompresses ahead of the application requests. for sparse files or files that contain mostly zeros ntfs uses another technique to save space. clusters that contain only zeros because they have never been written are not actually allocated or stored on disk. instead gaps are left in the sequence of virtual cluster numbers stored in the mft entry for the file. when reading a file if it finds a gap in the virtual cluster numbers ntfs just zero fills that portion of the caller's buffer. this technique is also used by unix. ntfs supports encryption of files. individual files or entire directories can be specified for encryption. the security system manages the keys used and a key recovery service is available to retrieve lost keys. . . mount points mount points are a form of symbolic link specific to directories on ntfs. they provide a mechanism for administrators to organize disk volumes that is more flexible than the use of global names like drive letters . mount points are implemented as a symbolic link with associated data that contain the true volume name. ultimately mount points will supplant drive letters completely but there will be a long transition due to the dependence of many applications on the drive letter scheme. . . change journal ntfs keeps a journal describing all changes that have been made to the file system. user mode services can receive notifications of changes to the journal and then identify what files have changed. the content indexing service uses the change journal to identify files that need to be re indexed. the filereplication service uses it to identify files that need to be replicated across the network. . . volume shadow copies windows xp implements the capability of bringing a volume to a known state and then creating a shadow copy that can be used to back up a consistent view chapter windows xp of the volume. making a shadow copy of a volume is a form of copy on a'rite where blocks modified after the shadow copy is created have their original contents stashed in the copy. to achieve a consistent state for the volume requires the cooperation of applications since the system cannot know when the data used by the application are in a stable state from which the application could be safely restarted. the server version of windows xp uses shadow copies to efficiently maintain old versions of files stored on file servers. this allows users to see documents stored on file servers as they existed at earlier points in time. the user can use this feature to recover files that were accidentally deleted or simply to look at a previous version of the file all without pulling out a backup tape