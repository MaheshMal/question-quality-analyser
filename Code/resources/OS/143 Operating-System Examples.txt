 user thread uwp lightweight process kernel thread figure . lightweight process lwp. an application may require any number of lwps to run efficiently. consider a cpu bound application running on a single processor. in this scenario only one thread can run at once so one lwp is sufficient. an application that is i ointensive may require multiple lwps to execute however. typically an lwp is required for each concurrent blocking system call. suppose for example that five different file read requests occur simultaneously. five lwps are needed because all could be waiting for i o completion in the kernel. if a process has only four lwps then the fifth request must wait for one of the lwps to return from the kernel. one scheme for communication between the user thread library and the kernel is known as scheduler activation. it works as follows the kernel provides an application with a set of virtual processors lwps and the application can schedule user threads onto an available virtual processor. furthermore the kernel must inform an application about certain events. this procedure is known as an upcall. upcalls are handled by the thread library with an upcall handler and upcall handlers must run on a virtual processor. one event that triggers an upcall occurs when an application thread is about to block. in this scenario the kernel makes an upcall to the application informing it that a thread is about to block and identifying the specific thread. the kernel then allocates a new virtual processor to the application. the application runs an upcall handler on this new virtual processor which saves the state of the blocking thread and relinquishes the virtual processor on which the blocking thread is running. the upcall handler then schedules another thread that is eligible to run on the new virtual processor. when the event that the blocking thread was waiting for occurs the kernel makes another upcall to the thread library informing it that the previously blocked thread is now eligible to run. the upcall handler for this event also requires a virtual processor and the kernel may allocate a new virtual processor or preempt one of the user threads and run the upcall handler on its virtual processor. after marking the unblocked thread as eligible to run the application schedules an eligible thread to run on an available virtual processor. . operating system examples in this section we explore how threads are implemented in windows xp and linux systems. chapter threads . . windows xp threads windows xp implements the win api. the win api is the primary api for the family of microsoft operating systems windows nt and xp . indeed much of what is mentioned in this section applies to this entire family of operating systems. a windows xp application runs as a separate process and each process may contain one or more threads. the win api for creating threads is covered in section . . . windows xp uses the one to one mapping described in section . . where each user level thread maps to an associated kernel thread. however windows xp also provides support for a fiber library which provides the functionality of the many to many model section . . . by using the thread library any thread belonging to a process can access the address space of the process. the general components of a thread include a thread id uniquely identifying the thread a register set representing the status of the processor a user stack employed when the thread is running in user mode and a kernel stack employed when the thread is running in kernel mode a private storage area used by various run time libraries and dynamic link libraries dlls the register set stacks and private storage area are known as the context of the thread. the primary data structures of a thread include ethread executive thread block kthread kernel thread block teb thread environment block the key components of the ethread include a pointer to the process to which the thread belongs and the address of the routine in which the thread starts control. the ethread also contains a pointer to the corresponding kthread. the kthread includes scheduling and synchronization information for the thread. in addition the kthread includes the kernel stack used when the thread is running in kernel mode and a pointer to the teb. the ethread and the kthread exist entirely in kernel space this means that only the kernel can access them. the teb is a user space data structure that is accessed when the thread is running in user mode. among other fields the teb contains the thread identifier a user mode stack and an array for threadspecific data which windows xp terms thread local storage . the structure of a windows xp thread is illustrated in figure . . . . linux threads linux provides the f ork system call with the traditional functionality of duplicating a process as described in chapter . linux also provides the ability . operating system examples ethread i tteeacfi sfer i . kthread . . sclngdiujing . m syrjekronizatitin! ! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ' . .. . ... . ... i ' . . .. .' .. . .. . ... .teb thread identifier . . . .. i. !.. .. . . . .. !. ... !. .. . .. i.?r.. .. . . .. . !.. .. . . user slack . thread local storage . . . ... kernel s pace user space figure . data structures of a windows xp thread. to create threads using the clone system call. however linux does not distinguish between processes and threads. in fact linux generally uses the term task rather than process or thread when referring to a flow of control within a program. when clone is invoked it is passed a set of flags which determine how much sharing is to take place between the parent and child tasks. some of these flags are listed below flag meaning clone fs file system information is shared. cl ne vm the same memory space is shared. clone sighand signal handlers are shared. clone files the set of open fifes is shared. for example if clone is passed the flags cl ne fs clonejm clone sighand and clone files the parent and child tasks will share the same file system information such as the current working directory the same memory space the same signal handlers and the same set of open files. using clone in this fashion is equivalent to creating a thread as described in this chapter since the parent task shares most of its resources with its child task. however if none of these flags are set when clone is invoked no chapter threads sharing takes place resulting in functionality similar to that provided by the forko system call. the varying level of sharing is possible because of the way a task is represented in the linux kernel. a unique kernel data structure specifically struct task.struct exists for each task in the system. this data structure instead of storing data for the task contains pointers to other data structures where these data are stored for example data structures that represent the list of open files signal handling information and virtual memory. when f ork is invoked a new task is created along with a copy of all the associated data structures of the parent process. a new task is also created when the clone system call is made. however rather than copying all data structures the new task points to the data structures of the parent task depending on the set of flags passed to clone 