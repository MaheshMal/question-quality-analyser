 early computers were physically enormous machines run from a console. the programmer who was also the operator of the computer system would write a program and then would operate the program directly from the operator's console. first the program would be loaded manually into memory from the front panel switches one instruction at a time from paper tape or from punched cards. then the appropriate buttons would be pushed to set the starting address and to start the execution of the program. as the program ran the programmer operator could monitor its execution by the display lights on the console. if errors were discovered the programmer could halt the program examine the contents of memory and registers and debug the program directly from the console. output was printed or was punched onto paper tape or cards for later printing. . . dedicated computer systems as time went on additional software and hardware were developed. card readers line printers and magnetic tape became commonplace. assemblers loaders and linkers were designed to ease the programming task. libraries of common functions were created. common functions could then be copied chapter influential operating systems into a new program without having to be written again providing software reusability. the routines that performed i o were especially important. each new i o device had its own characteristics requiring careful programming. a special subroutine called a device driver was written for each i o device. a device driver knows how the buffers flags registers control bits and status bits for a particular device should be used. each type of device has its own driver. a simple task such as reading a character from a paper tape reader might involve complex sequences of device specific operations. rather than writing the necessary code every time the device driver was simply used from the library. later compilers for fortran cobol and other languages appeared making the programming task much easier but the operation of the computer more complex. to prepare a fortran program for execution for example the programmer would first need to load the fortran compiler into the computer. the compiler was normally kept on magnetic tape so the proper tape would need to be mounted on a tape drive. the program would be read through the card reader and written onto another tape. the fortran compiler produced assembly language output which then needed to be assembled. this procedure required mounting another tape with the assembler. the output of the assembler would need to be linked to supporting library routines. finally the binary object form of the program would be ready to execute. it could be loaded into memory and debugged from the console as before. a significant amount of set up time could be involved in the running of a job. each job consisted of many separate steps . loading the fortran compiler tape . running the compiler . unloading the compiler tape . loading the assembler tape . running the assembler . unloading the assembler tape . loading the object program . running the object program if an error occurred during any step the programmer operator might have to start over at the beginning. each job step might involve the loading and unloading of magnetic tapes paper tapes and punch cards. the job set up time was a real problem. while tapes were being mounted or the programmer was operating the console the cpu sat idle. remember that in the early days few computers were available and they were expensive. a computer might have cost millions of dollars not including the operational costs of power cooling programmers and so on. thus computer time was extremely valuable and owners wanted their computers to be used as much as possible. they needed high utilization to get as much as they could from their investments. . early systems . . shared computer systems ? the solution was two fold. first a professional computer operator was hired. the programmer no longer operated the machine. as soon as one job was finished the operator could start the next. since the operator had more experience with mounting tapes than a programmer set up time was reduced. the programmer provided whatever cards or tapes were needed as well as a short description of how the job was to be run. of course the operator could not debug an incorrect program at the console since the operator would not understand the program. therefore in the case of program error a dump of memory and registers was taken and the programmer had to debug from the dump. dumping the memory and registers allowed the operator to continue immediately with the next job but left the programmer with the more difficult debugging problem. second jobs with similar needs were batched together and run through the computer as a group to reduce set up time. for instance suppose the operator received one fortran job one cobol job and another fortran job. if she ran them in that order she would have to set up for fortran load the compiler tapes and so on then set up for cobol and then set up for fortran again. if she ran the two fortran programs as a batch however she could set up only once for fortran saving operator time. but there were still problems. for example when a job stopped the operator would have to notice that it had stopped by observing the console determine why it stopped normal or abnormal termination dump memory and register if necessary load the appropriate device with the next job and restart the computer. during this transition from one job to the next the cpu sat idle. to overcome this idle time people developed automatic job sequencing with this technique the first rudimentary operating systems were created. a small program called a resident monitor was created to transfer control automatically from one job to the next figure . . the resident monitor is always in memory or resident . loader monitor job sequencing control card interpreter user program area figure . memory layout for a resident monitor. chapter influential operating systems when the computer was turned on the resident monitor was invoked and it would transfer control to a program. when the program terminated it would return control to the resident monitor which would then go on to the next program. thus the resident monitor would automatically sequence from one program to another and from one job to another. but how would the resident monitor know which program to execute? previously the operator had been given a short description of what programs were to be run on what data. control cards were introduced to provide this information directly to the monitor. the idea is simple in addition to the program or data for a job the programmer included the control cards which contained directives to the resident monitor indicating what program to run. for example a normal user program might reqtiire one of three programs to run the fortran compiler ftn the assembler asm or the user's program run . we could use a separate control card for each of these ftn execute the fortran compiler. asm execute the assembler. run execute the user program. these cards tell the resident monitor which programs to run. we can use two additional control cards to define the boundaries of each job job first card of a job end final card of a job these two cards might be useful in accounting for the machine resources used by the programmer. parameters can be used to define the job name account number to be charged and so on. other control cards can be defined for other functions such as asking the operator to load or unload a tape. one problem with control cards is how to distinguish them from data or program cards. the usual solution is to identify them by a special character or pattern on the card. several systems used the dollar sign character in the first column to identify a control card. others used a different code. ibm's job control language jcl used slash marks in the first two columns. figure . shows a sample card deck setup for a simple batch system. a resident monitor thus has several identifiable parts the control card interpreter is responsible for reading and carrying out the instructions on the cards at the point of execution. the loader is invoked by the control card interpreter to load system programs and application programs into memory at intervals. the device drivers are used by both the control card interpreter and the loader for the system's i o devices to perform i o. often the system and application programs are linked to these same device drivers providing continuity in their operation as well as saving memory space and programming time. . early systems figure . card deck for a simple batch system. these batch systems work fairly well. the resident monitor provides automatic job sequencing as indicated by the control cards. when a control card indicates that a program is to be run the monitor loads the program into memory and transfers control to it. when the program completes it transfers control back to the monitor which reads the next control card loads the appropriate program and so on. this cycle is repeated until all control cards are interpreted for the job. then the monitor automatically continues with the next job. the switch to batch systems with automatic job sequencing was made to improve performance. the problem quite simply is that humans are considerably slower than the computer. consequently it is desirable to replace human operation with operating system software. automatic job sequencing eliminates the need for human set up time and job sequencing. as was pointed out above however even with this arrangement the cpu is often idle. the problem is the speed of the mechanical i o devices which are intrinsically slower than electronic devices. even a slow cpu works in the microsecond range with thousands of instructions executed per second. a fast card reader in contrast might read cards per minute or cards per second . thus the difference in speed between the cpu and its i o devices may be three orders of magnitude or more. over time of course improvements in technology resulted in faster i o devices. unfortunately cpu speeds increased even faster so that the problem was not only unresolved but also exacerbated. . . overlapped i o one common solution to the i o problem was to replace slow card readers input devices and line printers output devices with magnetic tape units. the majority of computer systems in the late s and early s were batch systems reading from card readers and writing to line printers or card punches. rather than have the cpu read directly from cards however the cards were first copied onto a magnetic tape via a separate device. when the tape was sufficiently full it was taken down and carried over to the computer. when a card was needed for input to a program the equivalent record was read from chapter influential operating systems cpu card reader line printer a cpu j card reader tape drives tape drives line printer b figure . operation of i o devices a online and b off line. the tape. similarly output was written to the tape and the contents of the tape were printed later. the card readers and line printers were operated off line rather than by the main computer figure . . an obvious advantage of off line operation was that the main computer was no longer constrained by the speed of the card readers and line printers but was limited only by the speed of the much faster magnetic tape units. the technique of using magnetic tape for all i o could be applied with any similar equipment such as card readers card punches plotters paper tape and printers . the real gain in off line operation comes from the possibility of using multiple reader to tape and tape to printer systems for one cpu. if the cpu can process input twice as fast as the reader can read cards then two readers working simultaneously can produce enough tape to keep the cpu busy. there is a disadvantage too however a longer delay in getting a particular job run. the job must first be read onto tape. then it must wait until enough other jobs are read onto the tape to fill it. the tape must then be rewound unloaded hand carried to the cpu and mounted on a free tape drive. this process is not unreasonable for batch systems of course. many similar jobs can be batched onto a tape before it is taken to the computer. although off line preparation of jobs continued for some time it was quickly replaced in most systems. disk systems became widely available and greatly improved on off line operation. the problem with tape systems was that the card reader could not write onto one end of the tape while the cpu read from the other. the entire tape had to be written before it was rewound and read because tapes are by nature sequential access devices. disk systems eliminated this problem by being random access devices. because the head is moved from one area of the disk to another a disk can switch rapidly from the area on the disk being used by the card reader to store new cards to the position needed by the cpu to read the next card. in a disk system cards are read directly from the card reader onto the disk. the location of card images is recorded in a table kept by the operating system. when a job is executed the operating system satisfies its requests for card reader input by reading from the disk. similarly when the job requests the printer to output a line that line is copied into a system buffer and is written to the disk. when the job is completed the output is actually printed. this form of processing is called spooling figure . the name is an acronym for