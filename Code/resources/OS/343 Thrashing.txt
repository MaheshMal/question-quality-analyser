 differently for example taking . seconds for one execution and . seconds for the next execution because of totally external circumstances. such is not the case with a local replacement algorithm. under local replacement the set of pages in memory for a process is affected by the paging behavior of only that process. local replacement might hinder a process however by not making available to it other less used pages of memory. thus global replacement generally results in greater system throughput and is therefore the more common method. thrashing if the number of frames allocated to a low priority process falls below the minimum number required by the computer architecture we must suspend that process's execution. we should then page out its remaining pages freeing all its allocated frames. this provision introduces a swap in swap out level of intermediate cpu scheduling. in fact look at any process that does not have ''enough frames. if the process does not have the number of frames it needs to support pages in active use it will quickly page fault. at this point it must replace some page. however since all its pages are in active use it must replace a page that will be needed again right away. consequently it quickly faults again and again and again replacing pages that it must bring back in immediately. this high paging activity is called thrashing. a process is thrashing if it is spending more time paging than executing. . . cause of thrashing thrashing results in severe performance problems. consider the following scenario which is based on the actual behavior of early paging systems. the operating system monitors cpu utilization. if cpu utilization is too low we increase the degree of multiprogramming by introducing a new process to the system. a global page replacement algorithm is used it replaces pages without regard to the process to which they belong. now suppose that a process enters a new phase in its execution and needs more frames. it starts faulting and taking frames away from other processes. these processes need those pages however and so they also fault taking frames from other processes. these faulting processes must use the paging device to swap pages in and out. as they queue up for the paging device the ready queue empties. as processes wait for the paging device cpu utilization decreases. the cpu scheduler sees the decreasing cpu utilization and increases the degree of multiprogramming as a result. the new process tries to get started by taking frames from running processes causing more page faults and a longer queue for the paging device. as a result cpu utilization drops even further and the cpu scheduler tries to increase the degree of multiprogramming even more. thrashing has occurred and system throughput plunges. the pagefault rate increases tremendously as a result the effective memory access time increases. no work is getting done because the processes are spending all their time paging. chapter virtual memory degree of multiprogramming figure . thrashing. this phenomenon is illustrated in figure . in which cpu utilization is plotted against the degree of multiprogramming. as the degree of multiprogramming increases cpu utilization also increases although more slowly until a maximum is reached. if the degree of multiprogramming is increased even further thrashing sets in and cpu utilization drops sharply. at this point to increase cpu utilization and stop thrashing we must decrease the degree of multi pro grammi rig. we can limit the effects of thrashing by using a local replacement algorithm or priority replacement algorithm . with local replacement if one process starts thrashing it cannot steal frames from another process and cause the latter to thrash as well. however the problem is not entirely solved. if processes are thrashing they will be in the queue for the paging device most of the time. the average service time for a page fault will increase because of the longer average queue for the paging device. thus the effective access time will increase even for a process that is not thrashing. to prevent thrashing we must provide a process with as many frames as it needs. but how do we know how many frames it needs'? there are several techniques. the working set strategy section . . starts by looking at how many frames a process is actually using. this approach defines the locality model of process execution. the locality model states that as a process executes it moves from locality to locality. a locality is a set of pages that are actively used together figure . . a program is generally composed of several different localities which may overlap. for example when a function is called it defines a new locality. in this locality memory references are made to the instructions of the function call its local variables and a subset of the global variables. when we exit the function the process leaves this locality since the local variables and instructions of the function are no longer in active use. we may return to this locality later. thus we see that localities are defined by the program structure and its data structures. the locality model states that all programs will exhibit this basic memory reference structure. note that the locality model is the unstated principle behind the caching discussions so far in this book. if accesses to any types of data were random rather than patterned caching would be useless. . thrashing en b a ra b cd e ....ll!! .l. ii r ' . e c cd en execution time figure . locality in a memory reference pattern. suppose we allocate enough frames to a process to accommodate its current locality. it will fault for the pages in its locality until all these pages are in memory then it will not fault again until it changes localities. if we allocate fewer frames than the size of the current locality the process will thrash since it cannot keep in memory all the pages that it is actively using. . . working set mode! as mentioned the working set model is based on the assumption of locality. this model uses a parameter a to define the working set window. the idea is to examine the most recent a page references. the set of pages in the most chapter virtual memory recent a page references is the working set figure . . if a page is in active use it will be in the working set. if it is no longer being used it will drop from the working set a time units after its last reference. thus the working set is an approximation of the program's locality. for example given the sequence of memory references shown in figure . if a memory references then the working set at time t is . by time h the working set has changed to . the accuracy of the working set depends on the selection of a. if a is too small it will not encompass the entire locality if a is too large it may overlap several localities. in the extreme if a is infinite the working set is the set of pages touched during the process execution. the most important property of the working set then is its size. if we compute the working set size wssj for each process in the system we can then consider that where d is the total demand for frames. each process is actively using the pages in its working set. thus process i needs wssj frames. if the total demand is greater than the total number of available frames d m thrashing will occur because some processes will not have enough frames. once a has been selected use of the working set model is simple. the operating system monitors the working set of each process and allocates to that working set enough frames to provide it with its working set size. if there are enough extra frames another process can be initiated. if the sum of the working set sizes increases exceeding the total number of available frames the operating system selects a process to suspend. the process's pages are written out swapped and its frames are reallocated to other processes. the suspended process can be restarted later. this working set strategy prevents thrashing while keeping the degree of multiprogramming as high as possible. thus it optimizes cpu utilization. the difficulty with the working set model is keeping track of the working set. the working set window is a moving window. at each memory reference a new reference appears at one end and the oldest reference drops off the other end. a page is in the working set if it is referenced anywhere in the working set window. we can approximate the working set model with a fixed interval timer interrupt and a reference bit. for example assume that a equals references and that we can cause a timer interrupt every references. when we get a timer interrupt we copy and clear the reference bit values for page reference table ... ws f ws f figure . working set modef. . thrashing each page. thus if a page fault occurs we can examine the current reference bit and two in memory bits to determine whether a page was used within the last to references. if it was used at least one of these bits will be on. if it has not been used these bits will be off. those pages with at least one bit on will be considered to be in the working set. note that this arrangement is not entirely accurate because we cannot tell where within an interval of a reference occurred. we can reduce the uncertainty by increasing the number of history bits and the frequency of interrupts for example bits and interrupts every references . however the cost to service these more frequent interrupts will be correspondingly higher. . . page fault frequency the working set model is successful and knowledge of the working set can be useful for prepaging section . . but it seems a clumsy way to control thrashing. a strategy that uses the page fault frequency pff takes a more direct approach. the specific problem is how to prevent thrashing. thrashing has a high page fault rate. thus we want to control the page fault rate. when it is too high we know that the process needs more frames. conversely if the page fault rate is too low then the process may have too many frames. we can establish upper and lower bounds on the desired page fault rate figure . . if the actual page fault rate exceeds the upper limit we allocate the process another frame if the page fault rate falls below the lower limit we remove a frame from the process. thus we can directly measure and control the page fault rate to prevent thrashing. as with the working set strategy we may have to suspend a process. if the page fault rate increases and no free frames are available we must select some process and suspend it. the freed frames are then distributed to processes with high page fault rates. number of frames figure . page fault frequency. chapter virtual memory t rafcife ifewtrfehgiire sjgji f tiros as .refeifgiifieg m daja amt cocife skciioii r e lie fapft is oceujrs rk! ihis m jni at fe' fafls. flrig w i tj this .the . sta rt ofoneipeak andithestartiofithe ne xt peak iljustifa t js one warkine set to ai