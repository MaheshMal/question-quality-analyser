 as we noted in the preceding chapter a distributed system is a collection of loosely coupled computers interconnected by a communication network. these computers can share physically dispersed files by using a distributed file system dfs . in this chapter we use the term dfs to mean distributed file systems in general not the commercial transarc dfs product. the latter is referenced as transarc dfs. also nfs refers to nfs version unless otherwise noted. chapter distributed file systems to explain the structure of a dfs we need to define the terms service seroer and client. a service is a software entity running on one or more machines and providing a particular type of function to clients. a server is the service software running on a single machine. a client is a process that can invoke a service using a set of operations that form its client interface. sometimes a lower level interface is defined for the actual cross machine interaction it is the intermachine interface. using this terminology we say that a file system provides file services to clients. a client interface for a file service is formed by a set of primitive file operations such as create a file delete a file read from a file and write to a file. the primary hardware component that a file server controls is a set of local secondary storage devices usually magnetic disks on which files are stored and from which they are retrieved according to the clients' requests. a dfs is a file system whose clients servers and storage devices are dispersed among the machines of a distributed system. accordingly service activity has to be carried out across the network. instead of a single centralized data repository the system frequently has multiple and independent storage devices. as you will see in this text the concrete configuration and implementation of a dfs may vary from system to system. in some configurations servers run on dedicated machines in others a machine can be both a server and a client. a dfs can be implemented as part of a distributed operating system or alternatively by a software layer whose task is to manage the communication between conventional operating systems and file systems. the distinctive features of a dfs are the multiplicity and autonomy of clients and servers in the system. ideally a dfs should appear to its clients to be a conventional centralized file system. the multiplicity and dispersion of its servers and storage devices should be made invisible. that is the client interface of a dfs should not distinguish between local and remote files. it is up to the dfs to locate the files and to arrange for the transport of the data. a transparent dfs facilitates user mobility by bringing the user's environment that is home directory to wherever a user logs in. the most important performance measurement of a dfs is the amount of time needed to satisfy service requests. in conventional systems this time consists of disk access time and a small amount of cpu processing time. in a dfs however a remote access has the additional overhead attributed to the distributed structure. this overhead includes the time to deliver the request to a server as well as the time to get the response across the network back to the client. for each direction in addition to the transfer of the information there is the cpu overhead of running the communication protocol software. the performance of a dfs can be viewed as another dimension of the dfs's transparency. that is the performance of an ideal dfs would be comparable to that of a conventional file system. the fact that a dfs manages a set of dispersed storage devices is the dfs's key distinguishing feature. the overall storage space managed by a dfs is composed of different and remotely located smaller storage spaces. usually these constituent storage spaces correspond to sets of files. a component unit is the smallest set of files that can be stored on a single machine independently from other units. all files belonging to the same component unit must reside in the same location