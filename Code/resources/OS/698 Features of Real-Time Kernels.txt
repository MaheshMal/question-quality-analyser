 in this section we discuss the features necessary for designing an operating system that supports real time processes. before we begin though let's consider what is typically not needed for a real time system. we begin by examining several features provided in many of the operating systems discussed so far in this text including linux unix and the various versions of windows. these systems typically provide support for the following a variety of peripheral devices such as graphical displays cd and dvd drives protection and security mechanisms multiple users supporting these features often results in a sophisticated and large kernel. for example windows xp has over forty million lines of source code. in contrast a typical real time operating system usually has a very simple design often written in thousands rather than millions of lines of source code. we would not expect these simple systems to include the features listed above. but why don't real time systems provide these features which are crucial to standard desktop and server systems? there are several reasons but three are most prominent. first because most real time systems serve a single purpose they simply do not require many of the features found in a desktop pc. consider a digital wristwatch it obviously has no need to support a disk drive or dvd let alone virtual memory. furthermore a typical real time system does not include the notion of a user the system simply supports a small number of tasks which often await input from hardware devices sensors vision identification and so forth . second the features supported by standard desktop operating systems are impossible to provide without fast processors and large amounts of memory. both of these are unavailable in real time systems due to space constraints as explained earlier. in addition many real time systems lack sufficient space to support peripheral disk drives or graphical displays although some systems may support file systems using nonvolatile memory nvram . third supporting features common in standard . features of real time kernels physical memory ipagei table figure . address translation in real time systems. desktop computing environments would greatly increase the cost of real time systems which could make such systems economically impractical. additional considerations apply when considering virtual memory in a real time system. providing virtual memory features as described in chapter require the system include a memory management unit mmu for translating logical to physical addresses. however mmus typically increase the cost and power consumption of the system. in addition the time required to translate logical addresses to physical addresses especially in the case of a translation look aside buffer tlb miss may be prohibitive in a hard real time environment. in the following we examine several appraoches for translating addresses in real time systems. figure . illustrates three different strategies for managing address translation available to designers of real time operating systems. in this scenario the cpu generates logical address l that must be mapped to physical address p. the first approach is to bypass logical addresses and have the cpu generate physical addresses directly. this technique known as real addressing mode does not employ virtual memory techniques and is effectively stating that p equals l. one problem with real addressing mode is the absence of memory protection between processes. real addressing mode may also require that programmers specify the physical location where their programs are loaded into memory. however the benefit of this approach is that the system is quite fast as no time is spent on address translation. real addressing mode is quite common in embedded systems with hard real time constraints. in fact some real time operating systems running on microprocessors containing an mmu actually disable the mmu to gain the performance benefit of referencing physical addresses directly. a second strategy for translating addresses is to use an approach similar to the dynamic relocation register shown in figure . . in this scenario a relocation register r is set to the memory location where a program is loaded. the physical address p is generated by adding the contents of the relocation register r to l. some real time systems configure the mmu to perform this way. the obvious benefit of this strategy is that the mmu can easily translate logical addresses to physical addresses using p l r. however this system still suffers from a lack of memory protection between processes. chapter real time systems the last approach is for the real time system to provide full virtual memory functionality as described in chapter . in this instance address translation takes place via page tables and a translation look aside buffer or tlb. in addition to allowing a program to be loaded at any memory location this strategy also provides memory protection between processes. for systems without attached disk drives demand paging and swapping may not be possible. however systems may provide such features using nvram flash memory. the lynxos and oncore systems are examples of real time operating systems providing full support for virtual memory. . implementing real time operating systems keeping in mind the many possible variations we now identify the features necessary for implementing a real time operating system. this list is by no means absolute some systems provide more features than we list below while other systems provide fewer. preemptive priority based scheduling preemptive kernel minimized latency one notable feature we omit from this list is networking support. however deciding whether to support networking protocols such as tcp ip is simple if the real time system must be connected to a network the operating system must provide networking capabilities. for example a system that gathers real time data and transmits it to a server must obviously include networking features. alternatively a self contained embedded system requiring no interaction with other computer systems has no obvious networking requirement. in the remainder of this section we examine the basic requirements listed above and identify how they can be implemented in a real time operating system. . . priority based scheduling the most important feature of a real time operating system is to respond immediately to a real time process as soon as that process requires the cpu. as a result the scheduler for a real time operating system must support a priority based algorithm with preemption. recall that priority based scheduling algorithms assign each process a priority based on its importance more important tasks are assigned higher priorities than those deemed less important. if the scheduler also supports preemption a process currently running on the cpu will be preempted if a higher priority process becomes available to run. preemptive priority based scheduling algorithms are discussed in detail in chapter where we also present examples of the soft real time scheduling features of the solaris windows xp and linux operating systems. each of these systems assigns real time processes the highest scheduling priority. for . implementing real time operating systems example windows xp has different priority levels the highest levels priority values to are reserved for real time processes. solaris and linux have similar prioritization schemes. note however that providing a preemptive priority based scheduler only guarantees soft real time functionality. hard real time systems must further guarantee that real time tasks will be serviced in accord with their deadline requirements and making such guarantees may require additional scheduling features. in section . we cover scheduling algorithms appropriate for hard real time systems. . . preemptive kernels nonpreemptive kernels disallow preemption of a process running in kernel mode a kernel mode process will run until it exits kernel mode blocks or voluntarily yields control of the cpu. in contrast a preemptive kernel allows the preemption of a task running in kernel mode. designing preemptive kernels can be quite difficult and traditional user oriented applications such as spreadsheets word processors and web browsers typically do not require such quick response times. as a result some commercial desktop operating systems such as windows xp are nonpreemptive. however to meet the timing requirements of real time systems in particular hard real time systems preemptive kernels are mandatory. otherwise a real time task might have to wait an arbitrarily long period of time while another task was active in the kernel. there are various strategies for making a kernel preemptible. one approach is to insert preemption points in long duration system calls. a preemption point checks to see whether a high priority process needs to be run. if so a context switch takes place. then when the high priority process terminates the interrupted process continues with the system call. preemption points can be placed only at safe locations in the kernel that is only where kernel data structures are not being modified. a second strategy for making a kernel preemptible is through the use of synchronization mechanisms which we discussed in chapter . with this method the kernel can always be preemptible because any kernel data being updated are protected from modification by the high priority process. event e first occurs event latency to t. t real time system responds to e time figure . event latency. chapter real time systems . . minimizing latency ? consider the event driven nature of a real time system the system is typically waiting for an event in real time to occur. events may arise either in software as when a timer expires or in hardware as when a remote controlled vehicle detects that it is approaching an obstruction. when an event occurs the system must respond to and service it as quickly as possible. we refer to event latency as the amount of time that elapses from when an event occurs to when it is serviced figure . . usually different events have different latency requirements. for example the latency requirement for an antilock brake system might be three to five milliseconds meaning that from the time a wheel first detects that it is sliding the system controlling the antilock brakes has three to five milliseconds to respond to and control the situation. any response that takes longer might result in the automobile's veering out of control. in contrast an embedded system controlling radar in an airliner might tolerate a latency period of several seconds. two types of latencies affect the performance of real time systems . interrupt latency . dispatch latency interrupt latency refers to the period of time from the arrival of an interrupt at the cpu to the start of the routine that services the interrupt. when an interrupt occurs the operating system must first complete the instruction it is executing and determine the type of interrupt that occurred. it must then save the state of the current process before servicing the interrupt using the specific interrupt service routine isr . the total time required to perform these tasks is the interrupt latency figure . . obviously it is crucial for real time interrupt determine task t running interrupt type . context switch isr interrupt latency time figure . interrupt latency. . implementing real time operating systems operating systems to minimize interrupt latency to ensure that real time?tasks receive immediate attention. one important factor contributing to interrupt latency is the amount of time interrupts may be disabled while kernel data structures are being updated. real time operating systems require that interrupts to be disabled for very short periods of time. however for hard real time systems interrupt latency must not only be minimized it must in fact be bounded to guarantee the deterministic behavior required of hard real time kernels. the amount of time required for the scheduling dispatcher to stop one process and start another is known as dispatch latency. providing real time tasks with immediate access to the cpu mandates that real time operating systems minimize this latency. the most effective technique for keeping dispatch latency low is to provide preemptive kernels. in figure . we diagram the makeup of dispatch latency. the conflict phase of dispatch latency has two components . preemption of any process running in the kernel . release by low priority processes of resources needed by a high priority process as an example in solaris the dispatch latency with preemption disabled is over milliseconds. with preemption enabled it is reduced to less than a millisecond. one issue that can affect dispatch latency arises when a higher priority process needs to read or modify kernel data that are currently being accessed by a lower priority process or a chain of lower priority processes. as kernel event response to event response interval process made interrupt available processing dispatch latency real time process execution conflicts dispatch time figure . dispatch latency. chapter real time systems data are typically protected with a lock the higher priority process will have to wait for a lower priority one to finish with the resource. the situation becomes more complicated if the lower priority process is preempted in favor of another process with a higher priority. as an example assume we have three processes l m and h whose priorities follow the order l m h. assume that process h requires resource r which is currently being accessed by process l. ordinarily process h would wait for l to finish using resource r. however now suppose that process m becomes runnable thereby preempting process l. indirectly a process with a lower priority process m has affected how long process h must wait for l to relinquish resource r. this problem known as priority inversion can be solved by use of the priority inheritance protocol. according to this protocol all processes that are accessing resources needed by a higher priority process inherit the higher priority until they are finished with the resources in question. when they are finished their priorities revert to their original values. in the example above a priority inheritance protocol allows process l to temporarily inherit the priority of process h thereby preventing process m from preempting its execution. when process l has finished using resource r it relinquishes its inherited priority from h and assumes its original priority. as resource r is now available process h not m will run next