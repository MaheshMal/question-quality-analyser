 a process must be in memory to be executed. a process however can be swapped temporarily out of memory to a backing store and then brought back into memory for continued execution. for example assume a multiprogramming environment with a round robin cpu scheduling algorithm. when a quantum expires the memory manager will start to swap out the process that just finished and to swap another process into the memory space that has been freed figure . . in the meantime the cpu scheduler will allocate a time slice to some other process in memory. when each process finishes its quantum it will be swapped with another process. ideally the memory manager can swap processes fast enough that some processes will be in memory ready to execute when the cpu scheduler wants to reschedule the cpu. in addition the quantum must be large enough to allow reasonable amounts of computing to be done between swaps. a variant of this swapping policy is used for priority based scheduling algorithms. if a higher priority process arrives and wants service the memory manager can swap out the lower priority process and then load and execute the higher priority process. when the higher priority process finishes the lower priority process can be swapped back in and continued. this variant of swapping is sometimes called roll out roll in. backing store main memory figure . swapping of two processes using a disk as a backing store. . swapping normally a process that is swapped out will be swapped back into the same memory space it occupied previously. this restriction is dictated by the method of address binding. if binding is done at assembly or load time then the process cannot be easily moved to a different location. if execution time binding is being used however then a process can be swapped into a different memory space because the physical addresses are computed during execution time. swapping requires a backing store. the backing store is commonly a fast disk. it must be large enough to accommodate copies of all memory images for all users and it must provide direct access to these memory images. the system maintains a ready queue consisting of all processes whose memory images are on the backing store or in memory and are ready to run. wlienever the cpu scheduler decides to execute a process it calls the dispatcher. the dispatcher checks to see whether the next process in the queue is in memory. if it is not and if there is no free memory region the dispatcher swaps out a process currently in memory and swaps in the desired process. it then reloads registers and transfers control to the selected process. the context switch time in such a swapping system is fairly high. to get an idea of the context switch time let us assume that the user process is mb in size and the backing store is a standard hard disk with a transfer rate of mb per second. the actual transfer of the mb process to or from main memory takes kb kb per second second milliseconds. assuming that no head seeks are necessary and assuming an average latency of milliseconds the swap time is milliseconds. since we must both swap out and swap in the total swap time is about milliseconds. for efficient cpu utilization we want the execution time for each process to be long relative to the swap time. thus in a round robin cpu scheduling algorithm for example the tune quantum should be substantially larger than . seconds. notice that the major part of the swap time is transfer time. the total transfer time is directly proportional to the amount of memory swapped. if we have a computer system with mb of main memory and a resident operating system taking mb the maximum size of the user process is mb. however many user processes may be much smaller than this say mb. a mb process could be swapped out in milliseconds compared with the . seconds required for swapping mb. clearly it would be useful to know exactly how much memory a user process is using not simply how much it might be using. then we would need to swap only what is actually used reducing swap time. for this method to be effective the user must keep the system informed of any changes in memory requirements. thus a process with dynamic memory requirements will need to issue system calls request memory and r e l e a s e memory to inform the operating system of its changing memory needs. swapping is constrained by other factors as well. if we want to swap a process we must be sure that it is completely idle. of particular concern is any pending i o. a process may be waiting for an i o operation when chapter main memory we want to swap that process to free up memory. however if the i o is asynchronously accessing the user memory for i o buffers then the process cannot be swapped. assume that the i o operation is queued because the device is busy. if we were to swap out process pi and swap in process po the i o operation might then attempt to use memory that now belongs to process pi. there are two main solutions to this problem never swap a process with pending i o or execute i o operations only into operating system buffers. transfers between operating system buffers and process memory then occur only when the process is swapped in. the assumption mentioned earlier that swapping requires few if any head seeks needs further explanation. we postpone discussing this issue until chapter where secondary storage structure is covered. generally swap space is allocated as a chunk of disk separate from the file system so that its use is as fast as possible. currently standard swapping is used in few systems. it requires too much swapping time and provides too little execution time to be a reasonable memory management solution. modified versions of swapping however are found on many systems. a modification of swapping is used in many versions of unix. swapping is normally disabled but will start if many processes are running and are using a threshold amount of memory. swapping is again halted when the load on the system is reduced. memory management in unix is described fully in sections . and a. . early pcs which lacked the sophistication to implement more advanced memory management methods ran multiple large processes by using a modified version of swapping. a prime example is the microsoft windows . operating system which supports concurrent execution of processes in memory. if a new process is loaded and there is insufficient main memory an old process is swapped to disk. this operating system however does not provide full swapping because the user rather than the scheduler decides when it is time to preempt one process for another. any swapped out process remains swapped out and not executing until the user selects that process to run. subsequent versions of microsoft operating systems take advantage of the advanced mmu features now found in pcs. we explore such features in section . and in chapter where we cover virtual memory