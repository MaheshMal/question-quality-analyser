 for a system to be reliable we need a mechanism that allows a set of processes to agree on a common value. such an agreement may not take place for several reasons. first the communication medium may be faulty resulting in lost or garbled messages. second the processes themselves may be faulty resulting in unpredictable process behavior. the best we can hope for in this case is that processes fail in a clean way stopping their execution without deviating from their normal execution pattern. in the worst case processes may send garbled or incorrect messages to other processes or even collaborate with other failed processes in an attempt to destroy the integrity of the system. the byzantine generals problem provides an analogy for this situation. several divisions of the byzantine army each commanded by its own general surround an enemy camp. the byzantine generals must reach agreement on whether or not to attack the enemy at dawn. it is crucial that all generals agree since an attack by only some of the divisions would result in defeat. the various divisions are geographically dispersed and the generals can communicate with one another only via messengers who run from camp to camp. the generals may not be able to reach agreement for at least two major reasons . messengers may get caught by the enemy and thus may be unable to deliver their messages. this situation corresponds to unreliable communication in a computer system and is discussed further in section . . . . generals may be traitors trying to prevent the loyal generals from reaching an agreement. this situation corresponds to faulty processes in a computer system and is discussed further in section . . . . . unreliable communications let us first assume that if processes fail they do so in a clean way and that the communication medium is unreliable. suppose that process p at site si which has sent a message to process p at site s needs to know whether pj has received the message so that it can decide how to proceed with its computation. for example p may decide to compute a function foo if pj has received its message or to compute a function boo if pj has not received the message because of some hardware failure . to detect failures we can use a time out scheme similar to the one described in section . . . when p sends out a message it also specifies . reaching agreement a time interval during which it is willing to wait for an acknowledgment message from p . when p receives the message it immediately sends an acknowledgment to p . if p receives the acknowledgment message within the specified time interval it can safely conclude that p has received its message. if however a time out occurs then p needs to retransmit its message and wait for an acknowledgment. this procedure continues until p either gets the acknowledgment message back or is notified by the system that site en is down. in the first case it will compute s in the latter case it will compute f. note that if these are the only two viable alternatives p must wait until it has been notified that one of the situations has occurred. suppose now that p also needs to know that p has received its acknowledgment message so that it can decide how to proceed with its computation. for example pj may want to compute foo only if it is assured that p got its acknowledgment. in other words p and pj will compute foo if and only if both have agreed on it. it turns out that in the presence of failure it is not possible to accomplish this task. more precisely it is not possible in a distributed environment for processes p and pr to agree completely on their respective states. to prove this claim let us suppose that a minimal sequence of message transfers exists such that after the messages have been delivered both processes agree to compute foo. let in' be the last message sent by p to pj. since p does not know whether its message will arrive at pj since the message may be lost due to a failure p will execute foo regardless of the outcome of the message delivery. thus m' could be removed from the sequence without affecting the decision procedure. hence the original sequence was not minimal contradicting our assumption and showing that there is no sequence. the processes can never be sure that both will compute foo. . . faulty processes now let us assume that the communication medium is reliable but that processes can fail in unpredictable ways. consider a system of n processes of which no more than m are faulty. suppose that each process p has some private value of v . we wish to devise an algorithm that allows each nonfaulty process p to construct a vector x a.i a. a n such that the following conditions exist . if pj is a nonfaulty process then aj.j vj. . if p and pj are both nonfaulty processes then x xj. there are many sokitions to this problem and they share the following properties . a correct algorithm can be devised only if n x m . . the worst case delay for reaching agreement is proportionate to in message passing delays. . the number of messages required for reaching agreement is large. no single process is trustworthy so all processes must collect all information and make their own decisions. chapter distributed coordination rather than presenting a general solution which would be complicated we present an algorithm for the simple case where m and n . the algorithm requires two rounds of information exchange . each process sends its private value to the other three processes. . each process sends the information it has obtained in the first round to all other processes. a faulty process obviously may refuse to send messages. in this case a nonfaulty process can choose an arbitrary value and pretend that the value was sent by the faulty process. once these two rounds are completed a nonfaulty process p can construct its vector x a.i a. a. a. as follows . for j i if at least two of the three values reported for process pj in the two rounds of exchange agree then the majority value is used to set the value of a otherwise a default value say nil is used to set the value of a. 