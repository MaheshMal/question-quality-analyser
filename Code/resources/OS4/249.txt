Scheduling Terminology and Concepts
        Scheduling, very generally, is the activity of selecting the next request to be ser-
        viced by a server. Figure 7.1 is a schematic diagram of scheduling. The scheduler
        actively considers a list of pending requests for servicing and selects one of them.
        The server services the request selected by the scheduler. This request leaves the
        server either when it completes or when the scheduler preempts it and puts it
        back into the list of pending requests. In either situation, the scheduler selects
        the request that should be serviced next. From time to time, the scheduler admits
        one of the arrived requests for active consideration and enters it into the list
        of pending requests. Actions of the scheduler are shown by the dashed arrows
228



                                                                            Chapter       7  Scheduling    229
                                                      Request is preempted
                      Scheduler
             Request            Request is            Request is
             arrives            admitted              scheduled             Server
                                                                                             Request
                                                                                             is completed
                      Arrived               Pending
                      requests              requests
Figure  7.1  A schematic of scheduling.
in Figure 7.1. Events related to a request are its arrival, admission, scheduling,
preemption, and completion.
In an operating system, a request is the execution of a job or a process, and
the server is the CPU. A job or a process is said to arrive when it is submitted by a
user, and to be admitted when the scheduler starts considering it for scheduling.
An admitted job or process either waits in the list of pending requests, uses the
CPU, or performs I/O operations. Eventually, it completes and leaves the system.
The scheduler's action of admitting a request is important only in an operating
system with limited resources; for simplicity, in most of our discussions we assume
that a request is admitted automatically on arrival.
In Chapter 3 we discussed how use of priorities in the scheduler provides
good system performance while use of round-robin scheduling provides good user
service in the form of fast response. Modern operating systems use more complex
scheduling policies to achieve a suitable combination of system performance and
user service.
Table 7.1 lists the key terms and concepts related to scheduling. The service
time of a job or a process is the total of CPU time and I/O time required by it
to complete its execution, and the deadline, which is specified only in real-time
systems (see Section 3.7), is the time by which its servicing should be completed.
Both service time and deadline are an inherent property of a job or a process.
The completion time of a job or a process depends on its arrival and service times,
and on the kind of service it receives from the OS.
We group scheduling concepts into user-centric concepts and system-centric
concepts to characterize the OS's concern for either user service or system
performance.
User-Centric Scheduling Concepts            In an interactive environment, a user inter-
acts with a process during its operation--the user makes a subrequest to a process
and the process responds by performing actions or by computing results. Response
time is the time since submission of a subrequest to the time its processing is com-
pleted. It is an absolute measure of service provided to a subrequest. Turnaround
time is an analogous absolute measure of service provided to a job or process.



230  Part 2  Process Management
             Table 7.1           Scheduling Terms and Concepts
             Term or concept          Definition or description
             Request related
             Arrival time             Time when a user submits a job or process.
             Admission time           Time when the system starts considering a job or
                                      process for scheduling.
             Completion time          Time when a job or process is completed.
             Deadline                 Time by which a job or process must be completed to
                                      meet the response requirement of a real-time
                                      application.
             Service time             The total of CPU time and I/O time required by a
                                      job, process or subrequest to complete its operation.
             Preemption               Forced deallocation of CPU from a job or process.
             Priority                 A tie-breaking rule used to select a job or process
                                      when many jobs or processes await service.
             User service related: individual request
             Deadline overrun         The amount of time by which the completion time of
                                      a job or process exceeds its deadline. Deadline
                                      overruns can be both positive or negative.
             Fair share               A specified share of CPU time that should be devoted
                                      to execution of a process or a group of processes.
             Response ratio           The ratio
                                      time since arrival + service time of a job or process
                                                       service time of the job or process
             Response time (rt)       Time between the submission of a subrequest for
                                      processing to the time its result becomes available.
                                      This concept is applicable to interactive processes.
             Turnaround time (ta)     Time between the submission of a job or process and
                                      its completion by the system. This concept is
                                      meaningful for noninteractive jobs or processes only.
             Weighted turnaround (w)  Ratio of the turnaround time of a job or process to its
                                      own service time.
             User service related: average service
             Mean response time (rt)  Average of the response times of all subrequests
                                      serviced by the system.
             Mean turnaround          Average of the turnaround times of all jobs or
             time (ta)                processes serviced by the system.
             Performance related
             Schedule length          The time taken to complete a specific set of jobs or
                                      processes.
             Throughput               The average number of jobs, processes, or
                                      subrequests completed by a system in one unit
                                      of time.



                                                              Chapter 7                   Scheduling  231
Turnaround time differs from the service time of a job or process because it also
includes the time when the job or process is neither executing on the CPU nor
performing I/O operations. We are familiar with these two measures from the
discussions in Chapter 3.
   Several other measures of user service are defined. The weighted turnaround
relates the turnaround time of a process to its own service time. For example, a
weighted turnaround of 5 indicates that the turnaround received by a request is
5 times its own service time. Comparison of weighted turnarounds of different
jobs or processes indicates the comparative service received by them. Fair share
is the share of CPU time that should be alloted to a process or a group of pro-
cesses. Response ratio of a job or process is the ratio (time since arrival + service
time)/service time. It relates the delay in the servicing of a job or process to its own
service time; it can be used in a scheduling policy to avoid starvation of processes
(see Section 7.2.3). The deadline overrun is the difference between the completion
time and deadline of a job or process in a real-time application. A negative value
of deadline overrun indicates that the job or process was completed before its
deadline, whereas a positive value indicates that the deadline was missed. The
mean response time and mean turnaround time are measures of average service
provided to subrequests and processes or jobs, respectively.
System-Centric Scheduling Concepts  Throughput and schedule length are mea-
sures of system performance. Throughput indicates the average number of requests
or subrequests completed per unit of time (see Section 3.5). It provides a basis
for comparing performance of two or more scheduling policies, or for comparing
performance of the same scheduling policy over different periods of time. Sched-
ule length indicates the total amount of time taken by a server to complete a set
of requests.
   Throughput and schedule length are related. Consider servicing of five
requests r1, . . . , r5. Let mina and maxc be the earliest of the arrival times and
the latest of the completion times, respectively. The schedule length for these five
requests is (maxc - mina) and the throughput is 5/(maxc - mina). However, it is
typically not possible to compute schedule length and throughput in this manner
because an OS may also admit and service other requests in the interval from mina
to maxc, to achieve good system performance. Nevertheless, schedule length is an
important basis for comparing the performance of scheduling policies when the
scheduling overhead is not negligible. Throughput is related to the mean response
time and mean turnaround time in an obvious way.
7.1.1 Fundamental Techniques of Scheduling
Schedulers use three fundamental techniques in their design to provide good user
service or high performance of the system:
·  Priority-based scheduling: The process in operation should be the highest-
   priority process requiring use of the CPU. It is ensured by scheduling the
   highest-priority ready process at any time and preempting it when a pro-
   cess with a higher priority becomes ready. Recall from Section 3.5.1 that a



232  Part 2  Process Management
                multiprogramming OS assigns a high priority to I/O-bound processes; this
                assignment of priorities provides high throughput of the system.
             ·  Reordering of requests: Reordering implies servicing of requests in some
                order other than their arrival order. Reordering may be used by itself to
                improve user service, e.g., servicing short requests before long ones reduces
                the average turnaround time of requests. Reordering of requests is implicit in
                preemption, which may be used to enhance user service, as in a time-sharing
                system, or to enhance the system throughput, as in a multiprogramming
                system.
             ·  Variation of time slice: When time-slicing is used, from Eq. (3.2) of Section 3.6,
                 = /( +  ) where  is the CPU efficiency,  is the time slice and  is the
                OS overhead per scheduling decision. Better response times are obtained
                when smaller values of the time slice are used; however, it lowers the CPU
                efficiency because considerable process switching overhead is incurred. To
                balance CPU efficiency and response times, an OS could use different values
                of  for different requests--a small value for I/O-bound requests and a large
                value for CPU-bound requests--or it could vary the value of  for a process
                when its behavior changes from CPU-bound to I/O-bound, or from I/O-
                bound to CPU-bound.
                In Sections 7.2 and 7.3 we discuss how the techniques of priority-based
             scheduling and reordering of requests are used in classical nonpreemptive and
             preemptive scheduling policies. In Sections 7.4 and 7.5, we discuss how sched-
             ulers in modern OSs combine these three fundamental techniques to provide a
             combination of good performance and good user service.
             7.1.2 The Role of Priority
             Priority is a tie-breaking rule that is employed by a scheduler when many requests
             await attention of the server. The priority of a request can be a function of several
             parameters, each parameter reflecting either an inherent attribute of the request,
             or an aspect concerning its service. It is called a dynamic priority if some of its
             parameters change during the operation of the request; otherwise, it called a static
             priority.
                Some process reorderings could be obtained through priorities as well. For
             example, short processes would be serviced before long processes if priority is
             inversely proportional to the service time of a process, and processes that have
             received less CPU time would be processed first if priority is inversely proportional
             to the CPU time consumed by a process. However, complex priority functions may
             be needed to obtain some kinds of process reorderings such as those obtained
             through time-slicing; their use would increase the overhead of scheduling. In
             such situations, schedulers employ algorithms that determine the order in which
             requests should be serviced.
                If two or more requests have the same priority, which of them should be
             scheduled first? A popular scheme is to use round-robin scheduling among
             such requests. This way, processes with the same priority share the CPU among
