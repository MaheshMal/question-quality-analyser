Preemptive Scheduling Policies
                  In preemptive scheduling, the server can be switched to the processing of a new
                  request before completing the current request. The preempted request is put
                  back into the list of pending requests (see Figure 7.1). Its servicing is resumed
                  when it is scheduled again. Thus, a request might have to be scheduled many
                  times before it completed. This feature causes a larger scheduling overhead than
                  when nonpreemptive scheduling is used. We discussed preemptive scheduling in
                  multiprogramming and time-sharing operating systems earlier, in Chapter 3.



                                                                                   Chapter 7    Scheduling  237
            Completed process              Response ratios of processes
   Time     id         ta      w        P1    P2     P3      P4          P5  Scheduled process
   0        -          -       -        1.00                                 P1
   3        P1         3       1.00           1.33   1.00                    P2
   6        P2         4       1.33                  1.60    2.00            P4
   8        P4         4       2.00                  2.00             1.00   P3
   13       P3         10      2.00                                   2.67   P5
   16       P5         8       2.67                                          ­
                                           ta = 5.8 seconds
                                           w = 1.80
                P1
                P2
                P3
                P4
                P5
                    0                   5            10                  15  Time
Figure 7.4  Operation      of  highest  response ratio (HRN) policy.
   We discuss three preemptive scheduling policies in this section:
·  Round-robin scheduling with time-slicing (RR)
·  Least completed next (LCN) scheduling
·  Shortest time to go (STG) scheduling
   The RR scheduling policy shares the CPU among admitted requests by ser-
vicing them in turn. The other two policies take into account the CPU time
required by a request or the CPU time consumed by it while making their
scheduling decisions.
7.3.1 Round-Robin Scheduling with Time-Slicing (RR)
The RR policy aims at providing good response times to all requests. The time
slice, which is designated as , is the largest amount of CPU time a request may
use when scheduled. A request is preempted at the end of a time slice. To facilitate
this, the kernel arranges to raise a timer interrupt when the time slice elapses.
   The RR policy provides comparable service to all CPU-bound processes. This
feature is reflected in approximately equal values of their weighted turnarounds.
The actual value of the weighted turnaround of a process depends on the number
of processes in the system. Weighted turnarounds provided to processes that per-
form I/O operations would depend on the durations of their I/O operations.
The RR policy does not fare well on measures of system performance like
throughput because it does not give a favored treatment to short processes. The
following example illustrates the performance of RR scheduling.



238  Part 2        Process Management
·
     Example 7.4     Round-Robin (RR) Scheduling
                        A round-robin scheduler maintains a queue of processes in the ready state and
                     simply selects the first process in the queue. The running process is preempted
                     when the time slice elapses and it is put at the end of the queue. It is assumed
                     that a new process that was admitted into the system at the same instant a
                     process was preempted will be entered into the queue before the preempted
                     process.
                            Figure 7.5 summarizes operation of the RR scheduler with  = 1 second
                     for the five processes shown in Table 7.2. The scheduler makes scheduling
                     decisions every second. The time when a decision is made is shown in the
                     first row of the table in the top half of Figure 7.5. The next five rows show
                     positions of the five processes in the ready queue. A blank entry indicates that
                     the process is not in the system at the designated time. The last row shows the
                     process selected by the scheduler; it is the process occupying the first position
                     in the ready queue. Consider the situation at 2 seconds. The scheduling queue
                     contains P2 followed by P1. Hence P2 is scheduled. Process P3 arrives at
                     3 seconds, and is entered in the queue. P2 is also preempted at 3 seconds
                     and it is entered in the queue. Hence the queue has process P1 followed by P3
                     and P2, so P1 is scheduled.
     Time of scheduling     0   1      2   3   4   5   6     7   8   9   10  11  12  13  14  15      c   ta    w
     Position of        P1  1   1      2   1                                                         4   4   1.33
     Processes in       P2             1   3   2   1   3     2   1                                   9   7   2.33
     ready queue        P3                 2   1   3   2     1   4   3   2   1   2   1   2   1       16  13  2.60
     (1 implies         P4                     3   2   1     3   2   1                               10  6   3.00
     head of queue)     P5                                       3   2   1   2   1   2   1           15  7   2.33
     Process scheduled      P1  P1     P2  P1  P3  P2  P4    P3  P2  P4  P5  P3  P5  P3  P5  P3
                                    ta = 7.4 seconds, w = 2.32
                                c: completion time of a process
                                P1
                                P2
                                P3
                                P4
                                P5
                                    0                     5                  10                  15      Time
                     Figure    7.5  Scheduling using the round-robin policy with time-slicing (RR).



                                                                    Chapter 7         Scheduling       239
The turnaround times and weighted turnarounds of the processes are as
shown in the right part of the table. The c column shows completion times.
The turnaround times and weighted turnarounds are inferior to those given
by the nonpreemptive policies discussed in Section 7.2 because the CPU time
is shared among many processes because of time-slicing. It can be seen that
processes P2, P3, and P4, which arrive at around the same time, receive approxi-
mately equal weighted turnarounds. P4 receives the worst weighted turnaround
because through most of its life it is one of three processes present in the sys-
tem. P1 receives the best weighted turnaround because no other process exists
in the system during the early part of its execution. Thus weighted turnarounds
depend on the load in the system.
                                                                                   ·
As discussed in Chapter 3, if a system contains n processes, each subrequest by
a process consumes exactly  seconds, and the overhead per scheduling decision
is  , the response time (rt) for a subrequest is n × ( + ). However, the relation
between  and rt is more complex than this. First, some processes will be blocked
for I/O or waiting for user actions, so the response time will be governed by the
number of active processes rather than by n. Second, if a request needs more CPU
time than  seconds, it will have to be scheduled more than once before it can
produce a response. Hence at small values of , rt for a request may be higher for
smaller values of . The following example illustrates this aspect.
                                                                                                       ·
Variation of Response Time in RR Scheduling                                           Example     7.5
An OS contains 10 identical processes that were initiated at the same time.
Each process receives 15 identical subrequests, and each subrequest consumes
20 ms of CPU time. A subrequest is followed by an I/O operation that consumes
10 ms. The system consumes 2 ms in CPU scheduling. For   20 ms, the first
subrequest by the first process receives a response time of 22 ms and the first
subrequest by the last process receives a response time of 220 ms. Hence the
average response time is 121 ms. A subsequent subrequest by any process
receives a response time of 10 × (2 + 20) - 10 ms = 210 ms because the process
spends 10 ms in an I/O wait before receiving the next subrequest. For  = 10 ms,
a subrequest would be preempted after 10 ms. When scheduled again, it would
execute for 10 ms and produce results. Hence the response time for the first
process is 10 × (2 + 10) + (2 + 10) = 132 ms, and that for the last process is
10 × (2 + 10) + 10 × (2 + 10) = 240 ms. A subsequent subrequest receives
a response time of 10 × (2 + 10) + 10 × (2 + 10) - 10 = 230 ms. Figure 7.6
summarizes performance of the system for different values of . As expected,
the schedule length and the overhead are higher for smaller values of . The
graph in Figure 7.6 illustrates the variation of average response time to second
and subsequent subrequests for different values of . Note that the response
time is larger when  is 5 ms than when it is 10 ms.
                                                                                   ·



240  Part 2  Process Management
                          Time slice                                    5 ms           10 ms  15 ms     20 ms
                          Average rt for first subrequest (ms)              248.5      186    208.5     121
                          Average rt for subsequent subrequest (ms)         270        230    230       210
                          Number of scheduling decisions                    600        300    300       150
                          Schedule length (ms)                          4200           3600   3600      3300
                          Overhead (percent)                                   29      17     17        9
                                        300
                              Response
                              time
                              (msecs)   200
                                        100
                                                    5  10       15  20  25             Time slice (ms)
                  Figure 7.6  Performance of    RR  scheduling for  different  values  of .
                  7.3.2 Least Completed Next (LCN) Scheduling
                  The LCN policy schedules the process that has so far consumed the least amount
                  of CPU time. Thus, the nature of a process, whether CPU-bound or I/O-bound,
                  and its CPU time requirement do not influence its progress in the system.
                  Under the LCN policy, all processes will make approximately equal progress
                  in terms of the CPU time consumed by them, so this policy guarantees that
                  short processes will finish ahead of long processes. Ultimately, however, this pol-
                  icy has the familiar drawback of starving long processes of CPU attention. It
                  also neglects existing processes if new processes keep arriving in the system.
                  So even not-so-long processes tend to suffer starvation or large turnaround
                  times.
·
     Example 7.6  Least Completed Next (LCN) Scheduling
                  Implementation of the LCN scheduling policy for the five processes shown
                  in Table 7.2 is summarized in Figure 7.7. The middle rows in the table in the
                  upper half of the figure show the amount of CPU time already consumed
                  by a process. The scheduler analyzes this information and selects the process
                  that has consumed the least amount of CPU time. In case of a tie, it selects
                  the process that has not been serviced for the longest period of time. The
                  turnaround times and weighted turnarounds of the processes are shown in the
                  right half of the table.



                                                                                   Chapter 7     Scheduling  241
Time of scheduling      0   1   2   3   4   5   6   7   8    9   10   11  12  13   14  15     c  ta  w
             P1         0   1   2   2   2   2   2   2   2    2   2                         11    11  3.67
CPU time     P2                 0   1   1   1   2   2   2    2   2    2                    12    10  3.33
consumed by  P3                     0   1   1   1   2   2    2   2    2   2   3    4   5   16    13  2.60
processes    P4                         0   1   1   1                                         8  4   2.00
             P5                                         0    1   2    2   2   2            14    6   2.00
Process scheduled       P1  P1  P2  P3  P4  P2  P3  P4  P5   P5  P1   P2  P3  P5   P3  P3
                                ta = 8.8 seconds, w = 2.72
                            c: completion time of a process
P1
P2
P3
P4
P5
        0                   5                   10                    15     Time
Figure  7.7  Scheduling using the least completed next (LCN) policy.
It can be seen that servicing of P1, P2, and P3 is delayed because new pro-
cesses arrive and obtain CPU service before these processes can make further
progress. The LCN policy provides poorer turnaround times and weighted
turnarounds than those provided by the RR policy (See Example 7.4) and the
STG policy (to be discussed next) because it favors newly arriving processes
over existing processes in the system until the new processes catch up in terms
of CPU utilization; e.g., it favors P5 over P1, P2, and P3.
                                                                                           ·
7.3.3 Shortest Time to Go (STG) Scheduling
The shortest time to go policy schedules a process whose remaining CPU time
requirements are the smallest in the system. It is a preemptive version of the
shortest request next (SRN) policy of Section 7.2, so it favors short processes
over long ones and provides good throughput. Additionally, the STG policy
also favors a process that is nearing completion over short processes entering
the system. This feature helps to improve the turnaround times and weighted
turnarounds of processes. Since it is analogous to the SRN policy, long processes
might face starvation.
