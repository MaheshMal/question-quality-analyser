Time-Sharing Systems
In  an  interactive  computing        environment,       a  user  submits    a  computational
requirement--a subrequest--to a process and examines its response on the mon-
itor screen. A time-sharing operating system is designed to provide a quick
response to subrequests made by users. It achieves this goal by sharing the CPU
time among processes in such a way that each process to which a subrequest has
been made would get a turn on the CPU without much delay.
     The scheduling technique used by a time-sharing kernel is called round-robin
scheduling with time-slicing. It works as follows (see Figure 3.6): The kernel main-
tains a scheduling queue of processes that wish to use the CPU; it always schedules
the process at the head of the queue. When a scheduled process completes ser-
vicing of a subrequest, or starts an I/O operation, the kernel removes it from
the queue and schedules another process. Such a process would be added at the
end of the queue when it receives a new subrequest, or when its I/O operation
completes. This arrangement ensures that all processes would suffer comparable



66  Part 1  Overview
                 delays before getting to use the CPU. However, response times of processes would
                 degrade if a process consumes too much CPU time in servicing its subrequest.
                 The kernel uses the notion of a time slice to avoid this situation. We use the
                 notation  for the time slice.
                 Definition 3.5 Time Slice      The largest amount of CPU time any time-shared
                 process can consume when scheduled to execute on the CPU.
                      If the time slice elapses before the process completes servicing of a subrequest,
                 the kernel preempts the process, moves it to the end of the scheduling queue, and
                 schedules another process. The preempted process would be rescheduled when it
                 reaches the head of the queue once again. Thus, a process may have to be scheduled
                 several times before it completes servicing of a subrequest. The kernel employs a
                 timer interrupt to implement time-slicing (see Section 2.2.5 and Table 2.2).
                      The appropriate measure of user service in a time-sharing system is the time
                 taken to service a subrequest, i.e., the response time (rt). It can be estimated
                 in the following manner: Let the number of users using the system at any time
                 be n. Let the complete servicing of each user subrequest require exactly  CPU
                 seconds, and let  be the scheduling overhead; i.e., the CPU time consumed by
                 the kernel to perform scheduling. If we assume that an I/O operation completes
                 instantaneously and a user submits the next subrequest immediately after receiv-
                 ing a response to the previous subrequest, the response time (rt) and the CPU
                 efficiency () are given by
                                                rt = n × ( +  )                                       (3.1)
                                                =                                                     (3.2)
                                                   +
                 The actual response time may be different from the value of rt predicted by
                 Eq. (3.1), for two reasons. First, all users may not have made subrequests to their
                 processes. Hence rt would not be influenced by n, the total number of users in the
                 system; it would be actually influenced by the number of active users. Second,
                 user subrequests do not require exactly  CPU seconds to produce a response.
                 Hence the relationship of rt and  with  is more complex than shown in Eqs. (3.1)
                 and (3.2).
                      Example 3.2 illustrates round-robin scheduling with time-slicing, and how it
                 results in interleaved operation of processes.
·
    Example 3.2  Operation of Processes in a Time-Sharing System
                 Processes P1 and P2 follow a cyclic behavior pattern. Each cycle contains a
                 burst of CPU activity to service a subrequest and a burst of I/O activity to
                 report its result, followed by a wait until the next subrequest is submitted to it.
                 The CPU bursts of processes P1 and P2 are 15 and 30 ms, respectively, while
                 the I/O bursts are 100 and 60 ms, respectively.



                                                                      Chapter 3  Overview of Operating Systems  67
    Figure 3.7 shows operation of the processes in a time-sharing system using
a time slice of 10 ms. The table in the top half of Figure 3.7 shows the scheduling
list and scheduling decisions of the kernel, assuming scheduling overhead to
be negligible, while the timing chart shows the CPU and I/O activities of the
processes. Both processes have to be scheduled a few times before they can
complete the CPU bursts of their execution cycle and start I/O. Process P1 uses
the CPU from time 0 to 10 ms and P2 uses the CPU from 10 to 20 ms without
completing the CPU bursts of their execution cycles. P1 is scheduled once again
at 20 ms and starts an I/O operation at 25 ms. Now P2 gets two consecutive
time slices. However, these time slices are separated by the scheduling overhead
because the OS preempts process P2 at 35 ms and schedules it again, since no
other process in the system needs the CPU. P1's I/O operation completes at
125 ms. P2 starts an I/O operation at 45 ms, which completes at 105 ms. Thus,
the response times are 125 ms and 105 ms, respectively.
                                                                                       ·
3.6.1 Swapping of Programs
Throughput of subrequests is the appropriate measure of performance of a time-
sharing operating system. The time-sharing OS of Example 3.2 completes two
subrequests in 125 ms, hence its throughput is 8 subrequests per second over the
period 0 to 125 ms. However, the throughput would drop after 125 ms if users
do not make the next subrequests to these processes immediately. The CPU is
                      Scheduling              Scheduled
Time                  list                    program     Remarks
0                     P1, P2                  P1          P1 is preempted at 10 ms
10                    P2, P1                  P2          P2 is preempted at 20 ms
20                    P1, P2                  P1          P1 starts I/O at 25 ms
25                    P2                      P2          P2 is preempted at 35 ms
35                    P2                      P2          P2 starts I/O at 45 ms
45                    -                       -           CPU is idle
CPU activity  P1
              P2
I/O activity  P1
              P2
                  0           20         40           60  80          100        120
                                                                                 Time
Figure 3.7 Operation  of  processes  P1  and  P2  in  a time-sharing  system.
