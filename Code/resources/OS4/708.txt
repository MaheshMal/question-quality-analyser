Design Issues in Distributed Operating Systems
The user of a distributed system expects its operating system to provide the look
and feel of a conventional OS and also provide the benefits of a distributed
system summarized in Table 16.1. To meet these expectations, the OS must fully
exploit the capabilities of all nodes by distributing data, resources, users, and
their computations effectively among the nodes of the system. It gives rise to the
following design issues.
Transparency of Resources and Services  Transparency implies that names of
resources and services do not depend on their locations in the system. It enables
an application to access local and nonlocal resources identically. It also permits
an OS to change the location of a resource freely because a change in location
does not affect the name of the resource and hence does not affect the appli-
cations that use the resource. The OS can exploit transparency to perform data
migration to speed up applications, reduce network traffic, or optimize use of
disks. Transparency also facilitates computation migration because the compu-
tation can continue to access resources as it did before it was migrated. We discuss
transparency in detail in Chapter 20.
Distribution of Control Functions  A control function is a function performed by
the kernel to control resources and processes in the system, e.g., resource alloca-
tion, deadlock handling, and scheduling. Centralized control functions face two
problems in a distributed system: Because of network latency, it is not possible to
obtain consistent information about the current state of processes and resources
in all nodes of the system, so the centralized function may not be able to arrive
at correct decisions. A centralized function is also a potential performance bot-
tleneck and a single point of failure in the system. To handle these problems,
a distributed OS performs a control function through a distributed control algo-
rithm, whose actions are performed in several nodes of the system in a coordinated
manner. We discuss distributed algorithms for performing control functions such
as deadlock detection, scheduling, and mutual exclusion in Chapter 18.
System Performance        In addition to techniques of conventional OSs, a dis-
tributed OS uses two new techniques to provide good system performance--data
migration and computation migration. Data migration is employed to reduce
network latencies and improve response times of processes. Computation migra-
tion is employed to ensure that nearly equal amounts of computational load are
directed at all CPUs in the system. This technique is called load balancing.
A distributed system typically grows in size over time through addition of
nodes and users. As the size of a system grows, process response times may degrade



688  Part 5  Distributed Operating Systems
                   because of increased loading of resources and services of the OS, and increased
                   overhead of OS control functions. Such degradation obstructs growth of a system,
                   so the performance of a distributed system should be scalable; i.e., the delays and
                   response times should not degrade with growth in system size, and the throughput
                   should increase with growth in system size. An important scalability technique
                   is to use self-sufficient clusters of hosts (see Section 16.3), so that network traffic
                   does not grow as more clusters are added to the system. In Chapter 20, we discuss
                   how the technique of file caching used in distributed file systems helps satisfy this
                   requirement.
                   Reliability     Fault tolerance techniques provide availability of resources and con-
                   tinuity of system operation when faults occur. Link and node faults are tolerated
                   by providing redundancy of resources and communication links. If a fault occurs
                   in a network path to a resource or in the resource itself, an application can use
                   another network path to the resource or use another resource. This way, a resource
                   is unavailable only when unforeseen faults occur.
                          Consistency of data becomes an issue when data is distributed or replicated.
                   When several parts of distributed data are to be modified, a fault should not put
                   the system in a state in which some parts of the data have been updated but others
                   have not been. A distributed OS employs a technique called two-phase commit
                   protocol to ensure that it does not happen (see Section 19.4.3).
                          Parts of a computation may be performed in different nodes of a system. If
                   a node or link fault occurs during execution of such a computation, the system
                   should assess the damage caused by the fault and judiciously restore some of the
                   subcomputations to previous states recorded in backups. This approach is called
                   recovery. The system must also deal with uncertainties about the cause of a fault.
                   Example 16.2 illustrates these uncertainties.
·
     Example 16.2  Uncertainties about Faults
                   A   distributed       computation  consists    of  two  subcomputations      represented
                   by     processes  Pi  and  Pj ,  executing   in  nodes  N1  and  N2,   respectively     (see
                   Figure 16.15). Process Pi sends a request to Pj and waits for a response. How-
                   ever, a time-out occurs before it receives a reply. The time-out could have been
                   caused by any one of the following situations:
                      1.  Process Pj never received the request, so never started processing it.
                      2.  The  processing   is    taking  longer  than  expected;  i.e.,  process  Pj  is  still
                          processing the request.
                      3.  Process    Pj  started  processing   the  request  but   suffered  a  fault  before
                          completing it.
                      4.  Process Pj completed the processing of the request but its reply to process
                          Pi was lost.
                   ·
