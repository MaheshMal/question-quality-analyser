Preview of the Book
A computer system, the services it provides to its users and their programs, and its
interfaces with other systems all make up the computing environment. Operating
systems are designed to provide effective utilization of a computer system in its
computing environment, which is the appropriate combination of efficient use
of resources and good user service in the computing environment, and to ensure
noninterference in the activities of its users. Parts 1­4 of this book primarily dis-
cuss operating systems for conventional computing environments characterized
by use of a single computer system having a single CPU; only Chapter 10 discusses
operating systems for the multiprocessor computing environment. Operating sys-
tems for the distributed computing environment are discussed in the chapters of
Part 5.
     All through this book, we will use abstract views to present the design and
implementation of operating systems because, as discussed in Section 1.1, abstract
views help in managing complexity and presenting generic concepts or ideas.



16  Part 1  Overview
            1.4.1 Introduction to Operating Systems
            Part 1 of the book consists of Chapters 1­4, of which the present chapter is
            Chapter 1. We begin the study of operating systems in Chapter 2 with a discussion
            of how an operating system interacts with the computer and with user programs.
            Events and Interrupts      An OS interleaves execution of several user programs on
            the CPU. While a user program is in execution, some situations concerning its
            own activity, or concerning activities in other programs, may require attention
            of the OS. Hence, occurrence of an event, which is any situation that requires
            attention of the OS, causes control of the CPU to be passed to the operating
            system. The operating system uses the CPU to execute instructions that analyze
            the event and perform appropriate actions. When an event has been attended to,
            the OS schedules a user program for execution on the CPU. Hence operation of
            the OS is said to be event driven. For example, if an I/O operation ends, the OS
            informs the program that had requested the I/O operation and starts another I/O
            operation on the device, if one is pending; if a program requests a resource, the
            OS allocates the resource if it is available. In either case, it performs scheduling to
            select the program to be executed next. Figure 1.5 is an abstract view, also called
            a logical view, of the functioning of an operating system.
                      The end of an I/O operation or the making of a resource request by a program
            actually causes an interrupt in the computer system. The CPU is designed to
            recognize an interrupt and divert itself to the OS. This physical view, which is the
            foundation for a study of operating systems, is developed in Chapter 2.
            Effective Utilization of a Computer System              Computing environments evolved in
            response to advances in computer architecture and new requirements of computer
            users. Each computing environment had a different notion of effective utilization,
            so its OS used a different set of techniques to realize it. A modern comput-
            ing environment contains features of several classical computing environments,
            such as noninteractive, time-sharing, and distributed computing environments,
            so techniques employed in these environments are used in modern OSs as well.
            Chapter 3 discusses these techniques to form the background for a detailed study
            of operating systems.
                                                         Operating
                                                         system
                                               Event                Event
                                               Computer             User
                                               system               programs
                                               Computing environment
            Figure 1.5  An  operating  system  in its computing environment.



                                                                      Chapter 1       Introduction  17
Portability  and     Extensibility   of  Operating  Systems  Early operating systems
were developed for specific computer systems, so they were tightly integrated
with architectures of specific computer systems. Modern operating systems
such as Unix and Windows pose two new requirements--the operating sys-
tem has to be portable, that is, it should be possible to implement it on many
computer architectures, and it should be extensible so that it can meet new
requirements arising from changes in the nature of its computing environment.
Chapter 4 discusses the operating system design techniques for portability and
extensibility.
1.4.2 Managing User Computations
Chapters 5­10, which constitute Part 2 of the book, discuss various facets of the
program management function. Chapter 5 lays the foundation of this study by
discussing how the operating system handles execution of programs.
Processes and Threads         A process is an execution of a program. An OS uses
a process as a unit of computational work--it allocates resources to a process
and schedules it for servicing by the CPU. It performs process switching when it
decides to preempt a process and schedule another one for servicing by the CPU
(see Figure 1.3). Process switching involves saving information concerning the
preempted process and accessing information concerning the newly scheduled
process; it consumes some CPU time and constitutes overhead of the operat-
ing system. The notion of a thread is introduced to reduce the OS overhead.
Switching between threads requires much less information to be stored and
accessed compared with switching between processes. However, processes and
threads are similar in other respects, so we use the term process as a generic term
for both a process and a thread, except while discussing the implementation of
threads.
Process Synchronization       Processes that have a common goal must coordinate
their activities so that they can perform their actions in a desired order. This
requirement is called process synchronization. Figure 1.6 illustrates two kinds of
process synchronization. Figure 1.6(a) shows processes named credit and debit
that access the balance in a bank account. Their results may be incorrect if both
processes update the balance at the same time, so they must perform their updates
strictly one after another. Figure 1.6(b) shows a process named generate that
             Credit           Debit
                                         Generate            Analyze
                     Balance                        Sample
             (a)                         (b)
Figure  1.6  Two kinds of process synchronization.



18  Part 1  Overview
            produces some data and puts it into a variable named sample, and the process
            named analyze that performs analysis on the data contained in variable sam-
            ple. Here, process analyze should not perform analysis until process generate has
            deposited the next lot of data in sample, and process generate should not produce
            the next lot of data until process analyze has analyzed the previous data. Program-
            ming languages and operating systems provide several facilities that processes may
            use for performing synchronization. Chapter 6 describes these facilities, their use
            by processess and their implementation in an OS.
            Message Passing  Processes may also interact through message passing. When
            a process sends some information in a message to another process, the operating
            system stores the message in its own data structures until the destination process
            makes a request to receive a message. Unlike the situation in Figure 1.6(b), syn-
            chronization of sender and destination processes is performed by the operating
            system--it makes the destination process wait if no message has been sent to it
            by the time it makes a request to receive a message. Details of message passing
            are described in Chapter 9.
            Scheduling  The nature of a computing environment decides whether effective
            utilization of a computer system implies efficient use of its resources, high user
            convenience, or a suitable combination of both. An OS realizes effective utiliza-
            tion through a scheduling policy that shares the CPU among several processes.
            This way, many processes make progress at the same time, which contributes to
            quick service for all users, and hence to high user convenience. The manner in
            which the CPU is shared among processes governs the use of resources allocated
            to processes, so it governs efficient use of the computer system. In Chapter 7, we
            discuss the classical scheduling policies, which aimed either at efficient use of a
            computer system, or at high user convenience, and scheduling policies used in
            modern operating systems, which aim at suitable combinations of efficient use
            and user convenience.
            Deadlocks   User processes share a computer system's resources. If a resource
            requested by some process Pi is currently allocated to process Pj, Pi has to wait
            until Pj releases the resource. Such waits sometimes cause a deadlock, which
            is a situation in which processes wait for other processes' actions indefinitely.
            Figure 1.7 illustrates such a situation. The arrow drawn from process Pi to Pj
            indicates that process Pi is waiting because it requested a resource that is cur-
            rently allocated to process Pj. Processes Pj and Pk similarly wait for resources
            that are currently allocated to processes Pk and Pi, respectively. Hence the three
            processes are in a deadlock. A deadlock adversely affects performance of a sys-
            tem because processes involved in the deadlock cannot make any progress and
            resources allocated to them are wasted. We discuss deadlock handling techniques
            used in operating systems in Chapter 8.
            Multiprocessor  Operating    Systems     A  multiprocessor  computer  system         can
            provide high performance because its CPUs can service several processes simulta-
            neously. It can also speed up operation of a computer application if its processes
            are scheduled simultaneously on several CPUs. To realize these advantages, the



                                                                                  Chapter 1  Introduction  19
                                        Pk
                Pk requires a resource                   Pj requires a  resource
                allocated to Pi                          allocated      to Pk
                Pi                                       Pj
                                 Pi requires a resource
                                        allocated to Pj
Figure 1.7  A  deadlock involving three processes.
operating system has to use special scheduling and synchronization techniques
to ensure that processes can operate efficiently and harmoniously on the CPUs.
We discuss these techniques in Chapter 10.
1.4.3 Management of Memory
Memory management involves efficient allocation, release and reuse of memory
to meet requests of processes. In the classical model of memory allocation, a single
contiguous area of memory is allocated to a process. This model does not support
reuse of a memory area that is not large enough to accommodate a new process,
so the kernel has to use the technique of compaction to combine several free areas
of memory into one large free area of memory; it incurs substantial overhead. The
noncontiguous memory allocation model allows many disjoint areas of memory
to be allocated to a process, which enables direct reuse of several small areas of
memory. We describe memory reuse techniques and the model of noncontiguous
memory allocation in Chapter 11. The kernel uses special techniques to meet its
own memory requirements efficiently. These techniques are also discussed in this
chapter.
Virtual Memory  Modern operating systems provide virtual memory, which is a
storage capability that is larger than the actual memory of a computer system.
The OS achieves it by storing the code and data of a process on a disk, and
loading only some portions of the code and data in memory. This way, a process
can operate even if its size exceeds the size of memory.
The operating system employs the noncontiguous memory allocation model
to implement virtual memory. It maintains a table of memory allocation infor-
mation to indicate which portions of the code and data of a process are present in
memory, and what their memory addresses are. During operation of the process,
the CPU passes each instruction address or data address used by it to a spe-
cial hardware unit called the memory management unit (MMU), which consults
the memory allocation information for the process and computes the address in
memory where the instruction or data actually resides. If the required instruction
or data does not exist in memory, the MMU causes a "missing from memory"
interrupt. The operating system now loads the portion that contains the required
instruction or data in memory--for which it might have to remove some other



20  Part 1  Overview
                                                    Memory             Memory allocation
                                                    Operating          information of Pi
                                                    system             Operand address
                      "Missing                                         in instruction
                      from memory"                                     being executed
                      interrupt
                                 Memory
                        management                             Loading/removal                 Code and data
                                 unit                                  of portions of          of processes
                                                                       code and data
                                    Memory address
                                       of operand                      Memory areas allocated  to process Pi
            Figure 1.8  A schematic of virtual      memory operation.
                                                                       User process
                                                    File system
                                                    Input output control system
                                                               (IOCS)
                                                    Computer hardware
            Figure 1.9  An overview of file system and input output control system (IOCS).
            portion from memory--and resumes operation of the process. Figure 1.8 is a
            schematic diagram of virtual memory when a process Pi is in operation.
                      A "missing from memory" interrupt slows down progress of a process, so
            the operating system has to make two key decisions to ensure a low rate of these
            interrupts: how many and which portions of the code and data of a process should
            it keep in memory. The techniques used in making these decisions are described
            in Chapter 12.
            1.4.4 Management of Files and I/O Devices
            A file system has to meet several expectations of its users--provide fast access
            to a file, protect the file against access by unauthorized persons, and provide
            reliable operation in the presence of faults such as faulty I/O media or power
            outages--and also ensure efficient use of I/O devices. A file system uses a layered
            organization to separate the various issues involved in fulfilling these expecta-
            tions; Figure 1.9 shows an abstract view. The upper layer, which is the file system
            itself, permits a user to share his files with some other users, implements file
            protection and provides reliability. To implement an operation on a file, the file



                                                      Chapter 1                         Introduction  21
system invokes the lower layer, which contains the input output control system
(IOCS). This layer ensures fast access to files by a process, and efficient use of I/O
devices.
File System     The file system provides each user with a logical view in which the
user has a home directory at an appropriate place in the directory structure of
the file system. The user can create directories, or folders, as they are called in
the Windows operating system, in his home directory, and other directories or
folders in these directories, and so on. A user can authorize some collaborators
to access a file by informing the file system of the names of collaborators and the
name of the file. The file system uses this information to implement file protection.
To ensure reliability, the file system prevents damage to the data in a file, and to
its own data such as a directory, which is called the metadata, due to faults like
faulty I/O media or power outages. All these features of file systems are discussed
in Chapter 13.
Input Output Control System (IOCS)  The IOCS implements a file operation by
transferring data between a process and a file that is recorded on an I/O device.
It ensures efficient implementation of file operations through three means--by
reducing the time required to implement a data transfer between a process and an
I/O device, by reducing the number of times data has to be transferred between a
process and an I/O device, and by maximizing the number of I/O operations that
an I/O device can complete in a given period of time. Its techniques are discussed
in Chapter 14.
Security and Protection  Security and protection threats, and the arrangement
used to implement security and protection, were described earlier in Section 1.3.3.
The OS encrypts the password data through an encryption function known only
to itself. Encryption strengthens the security arrangement because an intruder
cannot obtain passwords of users except through an exhaustive search, which
would involve trying out every possible string as a password. Various security
and protection threats, the technique of encryption, and various methods used
to implement protection are described in Chapter 15.
1.4.5 Distributed Operating Systems
A distributed computer system consists of several computer systems, each with its
own memory, connected through networking hardware and software. Each com-
puter system in it is called a node. Use of a distributed computer system provides
three key advantages: speeding up of a computer application by scheduling its
processes in different nodes of the system simultaneously, high reliability through
redundancy of computer systems and their resources, and resource sharing across
node boundaries. To realize these advantages, a distributed OS must tackle the
following fundamental issues:
·  Networking causes delays in the transfer of data between nodes of a dis-
   tributed system. Such delays may lead to an inconsistent view of data located
   in different nodes, and make it difficult to know the chronological order in
   which events occurred in the system.
