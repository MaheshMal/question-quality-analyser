Networking
             The term networking includes both network hardware and network software.
             Thus, it includes networking technology and design of computer networks, as also
             software aspects of implementing communication between a pair of processes.
             The basic issues in networking are summarized in Table 16.6. Network type,
             network topology, and networking technology concern the design of networks.
             All other issues concern message communication between processes--finding
             the IP address of the node where a destination process is located, deciding which
             route a message would follow to that node, and ensuring that the message is
             delivered efficiently and reliably. We discussed the domain name system (DNS)
             that determines the IP address of a host in Section 16.4.1. All other issues in
             networking are discussed in this section.
             16.6.1 Types of Networks
             A wide area network (WAN) connects resources and users that are geographically
             distant. When expensive mainframe computers were in use, it made good sense to
             make them accessible to a large number of users from different organizations and
             different locations. A WAN made this possible. The other motivation for WANs
             was to enable communication and data sharing between users.



                                                             Chapter 16   Distributed Operating  Systems  673
Table 16.6        Issues  in  Networking
Issue                         Description
Network type                  The type of a network is determined by the
                              geographical distribution of users and resources in the
                              system. Two main types of networks are wide area
                              networks (WANs) and local area networks (LANs).
Network topology              Network topology is the arrangement of nodes and
                              communication links in a network. It influences the
                              speed and reliability of communication, and the cost of
                              network hardware.
Networking technology         Networking technology is concerned with transmission
                              of data over a network. It influences network
                              bandwidth and latency.
Naming of processes           Using the domain name system (DNS), the pair (<host_
                              name>, <process_id>) for a destination process is
                              translated into the pair (IP address, <process_id>).
Connection strategy           A connection strategy decides how to set up data paths
                              between communicating processes. It influences
                              throughput of communication links and efficiency of
                              communication between processes.
Routing strategy              A routing strategy decides the route along which a
                              message would travel through the system. It influences
                              communication delays suffered by a message.
Network protocols             A network protocol is a set of rules and conventions
                              that ensure effective communication over a network.
                              A hierarchy of network protocols is used to obtain a
                              separation of various concerns involved in data
                              transmission and reliability.
Network bandwidth             The bandwidth of a network is the rate at which data is
and latency                   transferred over the network. Latency is the elapsed
                              time before data is delivered at the destination site.
When inexpensive personal computers became available, many organiza-
tions installed a large number of PCs within offices. Data used by PC users and
resources like good-quality laser printers became critical resources, so local area
networks (LANs) were set up to connect users and resources located within the
same office or same building. Since all resources and users in a LAN belonged
to the same organization, there was little motivation for sharing the data and
resources with outsiders. Hence few LANs were connected to WANs, though
the technology for making such connections existed. Advent of the Internet
changed the scenario and most LANs and WANs are today connected to the
Internet.
Figure 16.7 illustrates WANs and LANs. The LAN consists of PCs, printers,
and a file server. It is connected to a WAN through a gateway, which is a computer
that is connected to two (or more) networks and transfers messages between them.



674  Part 5  Distributed Operating Systems
                                                                             Workstations
                                                                             Local area
                                                         Host                network (LAN)
                           Wide     area             CP
                           network  (WAN)                           Gateway  File              Printer
                                                                             server
                                    CP                          CP
                                               Host                 Host
             Figure  16.7 Types     of networks.
                                          ...
                                    Bus                             Star     Ring
                                               Fully connected            Partially connected
             Figure  16.8  Network topologies.
             Special-purpose processors called communication processors (CPs) are used in the
             WAN to facilitate communication of messages between distant hosts. LANs use
             expensive high-speed cables like Category 5 or fiber-optic cables to provide high
             data transfer rates. WANs often use public lines for data transfer because of cost
             considerations, so it is generally not possible to support high transfer rates.
             16.6.2 Network Topology
             Figure 16.8 illustrates five network topologies. These topologies differ in the cost
             of network hardware, speed of communication, and reliability. The bus topology



                                                   Chapter 16  Distributed Operating     Systems  675
is similar to the bus in a PC. All hosts are connected directly to the bus, so the cost
of network hardware is low. Only one pair of hosts can communicate over the
bus at any time. High transfer rates are achieved except when contention exists
for the bus. The bus topology is used in Ethernet-based LANs.
In the star topology, each host is connected only to the host in the central site
of the system. This topology is useful when the distributed system contains one
server, and nodes contain processes that use this server. Reliability of a star net-
work depends on reliability of the central host. Communication delays between
a host and the central host, or between two hosts, depend on contention at the
central host. Fast Ethernet uses a star topology.
In a ring network, each host has two neighbors. When a host wishes to
communicate with another host, a message is passed along the ring until it reaches
the destination host. Consequently, the communication load on a host is high
even when none of its processes is communicating. In a unidirectional ring, a link
carries messages in only one direction whereas in a bidirectional ring a link can
carry messages in both directions. Naturally unidirectional and bidirectional rings
have different reliability characteristics--a bidirectional ring network is immune
to single host or link faults, whereas a unidirectional ring network is not.
In a fully connected network, a link exists between every pair of hosts. Con-
sequently, communication between a pair of hosts is immune to crashes of other
hosts, or faults in up to (n - 2) links, where n is the number of hosts in the net-
work. One or more hosts may become isolated if the number of faults exceeds
n - 2. This situation is called network partitioning. A partially connected network
contains fewer links than a fully connected network. It has a lower cost than a
fully connected network; however, it may get partitioned with fewer host or link
crashes than a fully connected network.
16.6.3 Networking Technologies
We discuss three networking technologies. The Ethernet and token ring tech-
nologies are used for local area networks and the Asynchronous Transfer Mode
(ATM) technology is used for ISDN networks.
Ethernet  Ethernet is a bus-like network (simple or branching bus) using a circuit
that consists of cables linked by repeaters. Several entities, called stations, are
connected to the same cable. Data is transmitted in units called frames. Each
frame contains addresses of its source and destination, and a data field. Each
station listens on the bus at all times. It copies a frame in a buffer if the frame
is meant for it; otherwise, it ignores the frame. The original Ethernet operated
at a transmission rate of 10 Mbits per second. Fast Ethernet, which operates at
100 Mbits per second, Gigabit Ethernet, and 10 Gigabit Ethernet are prevalent
variants of Ethernet. A bridge is used to connect Ethernet LANs. It is a computer
that receives frames on one Ethernet and, depending on the destination addresses,
reproduces them on another Ethernet to which it is connected.
Since the basic Ethernet topology is that of a bus, only one conversation
can be in progress at any time. The "carrier sense multiple access with collision



676  Part 5  Distributed Operating Systems
             detection" (CSMA/CD) technology ensures it as follows: A station that wishes to
             send a message listens to the traffic on the cable to check whether a signal is being
             transmitted. This check is called carrier sensing. The station starts transmitting
             its frame if it does not detect a signal. However, if many stations find no signal
             on the cable and transmit at the same time, their frames would interfere with
             one another, causing abnormal voltage on the cable. This situation is called a
             collision. A station that detects a collision emits a special 32-bit jam signal. On
             receiving the jam signal, any transmitting station that had not so far detected a
             collision becomes aware of a collision. All the transmitting stations now back off
             by abandoning their transmissions and waiting for a random period of time before
             retransmitting their frames. This procedure of recovering from a collision does
             not guarantee that the frames will not collide again; however, it helps in ensuring
             that eventually all frames will be transmitted and received without collisions. The
             frame size must exceed a minimum that facilitates collision detection. This size is
             512 bits for the 10 Mbps and 100 Mbps Ethernets, where Mbps is an abbrevation
             of 220 bits per second, and 4096 bits for the Gigabit Ethernet.
             Token Ring    A token ring is a network with a ring topology that uses the notion
             of a token to decide which station may transmit a message at any time. The token
             is a special message circulating over the network. It has a status bit, which can be
             either free or busy. The status bit value busy indicates that a message is currently
             being transmitted over the network, whereas the value free indicates that the
             network is currently idle. Any station that wishes to transmit a message waits
             until it sees the token with the status bit free. It now changes the status to busy
             and starts transmitting its message. Thus a message follows a busy token, so only
             one message can be in transit at any time. A message can be of any length. It need
             not be split into frames of a standard size.
             Every station that sees a message checks whether the message is intended
             for it; only the destination station copies the message. When the station that
             transmitted a message sees the busy token over the network, it resets its status bit
             to free. This action releases the network for another message transmission. When
             early token release is supported, the destination station resets the status bit of
             the token to free. Operation of the token ring comes to a halt if the token is lost
             because of communication errors. One of the stations is responsible for recovering
             from this situation--it listens continuously to the traffic on the network to check
             for the presence of a token, and creates a new token if the token has been lost.
             Asynchronous  Transfer         Mode  (ATM)  Technology  ATM      is  a  virtual-circuit­
             oriented packet-switching technology (see Sections 16.6.4 and 16.6.5). The virtual
             circuit is called a virtual path in ATM terminology, and a packet is called a cell.
             ATM implements a virtual path between sites by reserving specific bandwidth in
             physical links situated in a network path between the sites, that is, by reserving a
             specific portion of the capacity of each physical link for the virtual path. When
             a physical link is common to many virtual paths, it multiplexes the traffic of the
             various virtual paths on a statistical basis such that each virtual path receives
             the specified portion of the bandwidth of the physical link. This way, cells to be



                                                         Chapter 16  Distributed Operating Systems  677
transmitted on a virtual path do not face delays due to traffic on other virtual
paths.
The principle of reserving bandwidth is carried one step further by hosts in
an ATM network. A virtual path may be set up between two hosts, say, hosts X
and Y. When a process Pi in host X wishes to communicate with a process Pj
in host Y, the hosts may set up a virtual channel between Pi and Pj by reserving
some bandwidth of the virtual path between X and Y. This two-tier arrangement
ensures that message traffic between a pair of processes does not incur delays due
to message traffic between other pairs of processes.
The ATM technology aims to provide real-time transport capabilities for
multimedia applications incorporating diverse traffics such as voice, video, and
high-speed data. ATM uses a cell size of 53 bytes. This size is a compromise
between a small cell size that is desired in voice communication to ensure small
delays and a largish cell size desired in data communication to reduce the overhead
of forming packets for a message and assembling them back to form a message.
Each cell contains a header of 5 bytes and a data field of 48 bytes. The header
contains two items of information: a virtual path id (VPI) and a virtual channel id
(VCI).
Figure 16.9 is a schematic diagram illustrating functioning of an ATM switch.
The switch contains a routing table, which has an entry for each virtual path
defined in the switch. The entry contains two fields--the VPI field and the port
field. In Figure 16.9, the virtual path identifier of the incoming cell is n, and the
nth entry in the routing table contains m and p. The switch copies m in the VPI
field of the cell and sends out the modified cell on port p. This simple arrangement
ensures that the ids assigned to virtual paths need not be unique in the system;
they only need to be unique in the switch. The switching actions are performed in
the hardware of the switch; they provide extremely fast switching, of the order of
low double digits of microseconds, which makes it possible to provide LAN-like
transmission speeds over wide area networks.
While creating a new virtual path, an application specifies the desired band-
width. The OS sets up a virtual path by reserving the bandwidth in individual
links, choosing a unique virtual path identifier in each switch and updating its
routing table. While managing the traffic in virtual channels of the same vir-
tual path, hosts use statistical multiplexing to provide appropriate bandwidth to
                                VPI         Port
VPI     VCI                                           p  VPI         VCI
n                           #n  m           p            m
Header       Data                                        Header           Data
                                Routing
                                     table
                                ATM switch
Figure 16.9 An ATM switch.



678  Part 5  Distributed Operating Systems
                                                       Applications
                                                Voice       Video             Data
                                                       Adaptation layer
                                                       ATM layer
                                                       Physical layer
             Figure  16.10   ATM protocol reference model.
                                                            m1                           pc1(m1)
                         m3  m2  m1                             m2
                     Pi                     Pj  Pi                        Pj        Pi   pc3(m1)           Pj
                                                            m3                           pc2(m1)
                         Circuit switching             Message switching                 Packet switching
             (a)                                (b)                                 (c)
             Figure  16.11   Connection strategies: circuit, message, and     packet switching.
             individual applications. Thus different applications can simultaneously transmit
             messages at different speeds over their virtual paths.
             An ATM network has a mesh-star architecture. ATM switches are connected
             to one another in a mesh form. Hosts are connected to the ATM switches as
             in a star network. This strategy provides a path between every pair of nodes.
             Figure 16.10 shows the protocol layers in the ATM protocol reference model.
             The physical layer performs transfer of cells across the network. The ATM layer
             performs transmission of messages between ATM entities. It performs multiplex-
             ing and demultiplexing of virtual channels into virtual paths, cell scheduling, and
             cell routing. The ATM adaptation layer provides different kinds of services to dif-
             ferent kinds of traffic such as voice, video, and data communication. It provides
             separate protocols for each kind of traffic.
             16.6.4 Connection Strategies
             A connection is a data path between communicating processes. A connection strat-
             egy, also called a switching technique, determines when a connection should be set
             up between a pair of processes, and for how long it should be maintained. Choice
             of the switching technique influences efficiency of communication between a pair
             of processes and throughput of communication links. Figure 16.11 illustrates
             three connection strategies. We use the notation mi for a message and pcj(mi) for
             the jth packet of message mi, where a packet has the meaning defined later in this
             section.



                                                             Chapter 16  Distributed Operating  Systems  679
Circuit  Switching      A  circuit  is  a  connection  that  is  used    exclusively  by  a
pair of communicating processes and carries all messages between them [see
Figure 16.11(a)]. A circuit is set up when processes decide to communicate, i.e.,
before the first message is transmitted, and is destroyed sometime after the last
message has been transmitted. Circuit set up actions involve deciding the actual
network path that messages will follow and reserving communication resources
accordingly. Each circuit is given a unique id, and processes specify the circuit id
while sending and receiving messages.
The advantage of circuit switching is that messages do not face delays once a
circuit has been set up. However, a circuit ties up a set of communication resources
and incurs set up overhead and delays, so use of circuit switching is justified only
if the overall message density in the system is low but medium-to-heavy traffic is
expected between a pair of processes.
Message Switching          A connection is established for every message exchanged
between a pair of processes. Thus messages between the same pair of processes
may travel over different paths in the system [see Figure 16.11(b)]. Message switch-
ing incurs repetitive overhead and may cause delays due to the set up time of the
connection, so its use is justified if light message traffic exists between a pair of
processes. It does not tie up communication resources, so other processes can use
the same connection, or some links in the connection, for their communication.
Traffic in the network should be heavy enough to exploit this possibility.
Packet Switching    In packet switching, a message is split into parts of a standard
size, called packets. A connection is set up for each packet individually, so packets
of a message may travel along different paths [see Figure 16.11(c)] and arrive out
of sequence at a destination site. Use of packet switching incurs two kinds of
overhead: A packet has to carry some identification information in its header--
id of the message to which it belongs, sequence number within the message, and
ids of the sender and destination processes--and packets have to be assembled
into messages in the destination site. However, use of fixed-size packets reduces
the cost of retransmission when an error arises. Also, links are not monopolized
by specific pairs of processes, hence all pairs of communicating processes receive
fair and unbiased service. These features make packet switching attractive for
interactive processes.
Because of the cost of setting up connections, connectionless protocols are
often used in practice for sending messages and packets. In such a protocol,
the originating node simply selects one of its neighboring nodes and sends the
message to it. If that node is not the destination node, it saves the message in
its memory and decides which of the neighbors to send it to, and so on until
the message reaches the destination node. This method is called the store-and-
forward method of transmitting a message. A packet is transmitted similarly.
Connectionless transmission can adapt better to traffic densities in communica-
tion links than message or packet switching, because a node can make the choice
of the link when it is ready to send out a message or packet. It is typically imple-
mented by exchanging traffic information among nodes and maintaining a table
in each node that indicates which neighbor to send to in order to reach a specific



680  Part 5  Distributed Operating Systems
             destination node. However, each node should have a large memory for buffering
             messages and packets when its outgoing links are congested.
             16.6.5 Routing
             The routing function is invoked whenever a connection is to be set up. It decides
             which network path would be used by the connection. Choice of the routing
             strategy influences ability to adapt to changing traffic patterns in the system.
             Figure 16.12 illustrates three routing strategies.
             Fixed Routing           A path is permanently specified for communication between a
             pair of nodes [see Figure 16.12(a)]. When processes located in these nodes wish
             to communicate, a connection is set up over this path. Fixed routing is simple
             and efficient to implement--each node merely contains a table showing paths to
             all other nodes in the system; however, it lacks flexibility to deal with fluctuations
             in traffic densities and node or link faults. Hence its use can result in delays or
             low throughputs.
             Virtual Circuit         A path is selected at the start of a session between a pair of pro-
             cesses. It is used for all messages sent during the session [see Figure 16.12(b)].
             Information concerning traffic densities and communication delays along differ-
             ent links in the system is used to decide the best path for a session. Hence this
             strategy can adapt to changing traffic patterns and node or link faults, and it
             ensures good network throughput and response times.
             Dynamic Routing         A path is selected whenever a message or a packet is to be
             sent, so different messages between a pair of processes and different packets of
             a message may use different paths [see Figure 16.12(c)]. This feature enables the
             routing strategy to respond more effectively to changes in traffic patterns and
             faults in nodes or links, and achieve better throughput and response times than
             when virtual circuits are used. In the Arpanet, which was the progenitor of the
             Internet, information about traffic density and communication delay along every
             link was constantly exchanged between nodes. This information was used to
             determine the current best path to a given destination node.
                  Pk                 Pl                Pk                    Pl                  Pk  m2               Pl
                                                           m3  m2  m1                                         m1
                  Pi                 Pj                Pi                    Pj                  Pi                   Pj
                  N1                 N2                N1                    N2                  N1  m3               N2
                      Fixed routing                        Virtual circuit                           Dynamic routing
             (a)                                  (b)                                       (c)
             Figure   16.12  Routing strategies:  fixed    routing, virtual  circuit,  and  dynamic routing.



                                                              Chapter 16  Distributed Operating  Systems  681
16.6.6 Network Protocols
A network protocol is a set of rules and conventions used to implement communi-
cation over a network. Several concerns need to be addressed while implementing
communication, such as ensuring confidentiality of data, achieving communica-
tion efficiency, and handling data transmission errors. Therefore, a hierarchy of
network protocols is used in practice to provide a separation of concerns. Each
protocol addresses one or more concerns and provides an interface to the proto-
cols above and below it in the hierarchy. The protocol layers are like the layers of
abstraction in a model (see Section 1.1). They provide the same benefits--an entity
using a protocol in a higher layer need not be aware of details at a lower layer.
Accordingly, lower-level protocols deal with data-transmission-related aspects
such as detection of data transmission errors, middle-level protocols deal with
formation of packets and routing, and higher-level protocols deal with semantic
issues that concern applications, e.g., atomicity of actions and confidentiality of
data.
ISO Procotol      The International Organization for Standardization (ISO) devel-
oped an Open Systems Interconnection reference model (OSI model) for com-
munication between entities in an open system. This model consists of seven
protocol layers described in Table 16.7. It is variously called the ISO protocol, the
ISO protocol stack, or the OSI model.
Figure 16.13 illustrates operation of the OSI model when a message is
exchanged by two application processes. The message originates in an appli-
cation, which presents it to the application layer. The application layer adds
some control information to it in the form of a header field. The message
now passes through the presentation and session layers, which add their own
headers. The presentation layer performs change of data representation and
Table 16.7         Layers  of  the ISO Protocol Stack
Layer                          Function
1. Physical layer              Provides electrical mechanisms for bit transmission
                               over a physical link.
2. Data link layer             Organizes received bits into frames. Performs error
                               detection on frames. Performs flow control.
3. Network layer               Performs switching and routing.
4. Transport layer             Forms outgoing packets. Assembles incoming packets.
                               Performs error detection and retransmission and flow
                               control.
5. Session layer               Establishes and terminates sessions. Provides for restart
                               and recovery in applications.
6. Presentation layer          Implements data semantics by performing change of
                               representation, compression, and encryption/
                               decryption where necessary.
7. Application layer           Provides network interface for applications.



682  Part 5  Distributed Operating Systems
                          Application
                                   process
                          Application layer
                          Presentation layer
                          Session layer
                          Transport layer
                          Network layer
                          Data link layer
                          Physical layer
                                                     Sender                       Receiver
             Figure 16.13 Operation of the      ISO  protocol  stack.
             encryption/decryption. The session layer establishes a connection between the
             sender and destination processes. The transport layer splits the message into
             packets and hands over the packets to the network layer. The network layer
             determines the link on which each packet is to be sent and hands over a link
             id and a packet to the data link layer. The data link layer views the packet
             as a string of bits, adds error detection and correction information to it, and
             hands it over to the physical layer for actual transmission. When the message
             is received, the data link layer performs error detection and forms frames, the
             transport layer forms messages, and the presentation layer puts the data in the rep-
             resentation desired by the application. The protocol layers are discussed in the
             following.
             The physical layer is responsible for the mechanical, electrical, functional, and
             procedural aspects of transmitting bit streams over the network. It is implemented
             in the hardware of a networking device. RS-232C and EIA-232D are the common
             physical layer standards.
             The data link layer provides error detection, error correction, and flow control
             facilities. It splits the bit stream to be sent into fixed-size blocks called frames,
             and adds a CRC to each frame (see Section 14.3). It provides flow control by
             sending frames at a rate that the receiver can handle. HDLC (high-level data
             link control) is a common protocol of this layer. Bridges and switches operate in
             this layer.
             The          network  layer    is  responsible    for     providing  connections  and  routes
             between two sites in a system; it also collects information for routing. Popu-
             lar protocols of this layer are the X.25 protocol, which is a connection-oriented
             protocol using virtual circuits, and the Internet protocol (IP), which is a con-
             nectionless protocol. Thus, routing is the primary function of this layer, and
             connection is an optional one. Routers operate in this layer. The network layer is
             mostly redundant in LANs and in systems with point-to-point connections.
             The transport layer provides error-free transmission of messages between
             sites. It splits a message into packets, and hands them over to the network
             layer. It handles communication errors like nondelivery of packets due to node
             or link faults. This feature resembles the reliability feature of IPC protocols,
             hence it is implemented analogously through time-outs and retransmissions



                                                                 Chapter 16      Distributed Operating  Systems  683
(see Section 16.4). The transport layer also performs flow control so that data is
transferred at a rate that the receiver can handle. The effective rate depends on
the buffer space available in the receiver and the rate at which it can copy data
out of the buffer. ISO has five classes of transport layer protocols, named TP0
through TP4. Other common transport layer protocols are the Transport Con-
trol Protocol (TCP), which is a connection-oriented reliable protocol, and User
Datagram Protocol (UDP), which is a connectionless unreliable protocol.
The session layer provides means to control the dialog between two enti-
ties that use a connection-oriented protocol. It provides authentication, different
types of dialogs (one-way, two-way alternate, or two-way simultaneous) and
checkpoint­recovery facilities. It provides dialog control to ensure that mes-
sages exchanged using nonblocking send primitives arrive in the correct order
(see Section 16.4). It also provides a quarantine service whereby messages are
buffered at a receiver site until explicitly released by a sender. This facility is use-
ful in performing atomic actions in a file (see Section 13.11.2) and in implementing
atomic transactions (see Section 19.4).
The presentation layer supports services that change the representation of
a message to address hardware differences between the sender and destination
sites, to preserve confidentiality of data through encryption, and to reduce data
volumes through compression.
The application layer supports application-specific services like file transfer,
e-mail, and remote log in. Some popular protocols of this layer are FTP (File
Transfer Protocol), X.400 (e-mail), and rlogin (remote log-in).
TCP/IP  The Transmission Control Protocol / Internet Protocol (TCP/IP) is a pop-
ular protocol for communication over the Internet. It has fewer layers than
the ISO protocol, so it is both more efficient and more complex to implement.
Figure 16.14 shows details of its layers. The lowest layer is occupied by a data
link protocol. The Internet Protocol (IP) is a network layer protocol in the ISO
protocol stack; it can run on top of any data link protocol. The IP performs data
transmission over the Internet using the 32-bit IP address of a destination host.
It is a connectionless unreliable protocol; it does not guarantee that packets of
a message will be delivered without error, only once, and in the correct order.
These properties are provided by the protocols occupying higher levels in the
hierarchy.
               ISO layers 5­7  File Transfer Protocol (FTP), e-mail, remote
                               log-in, or an application-specific protocol
                               Transmission Control              User Datagram
               ISO layer 4     Protocol (TCP)                    Protocol (UDP)
               ISO layer 3               Internet Protocol (IP)
               ISO layer 2               Data Link Protocol
Figure  16.14  The Transmission Control Protocol/Internet Protocol (TCP/IP) stack.



684  Part 5  Distributed Operating Systems
             Protocols      in  the         next  higher  layers  provide  communication  between
             processes--each host assigns unique 16-bit port numbers to processes, and a
             sender process uses a destination process address that is a pair (IP address, port
             number). Use of port numbers permits many processes within a host to send and
             receive messages concurrently. Some well-known services such as FTP, telnet,
             SMTP, and HTTP have been assigned standard port numbers by the Internet
             Assigned Numbers Authority (IANA); other port numbers are assigned by the
             OS in a host.
             As shown in Figure 16.14, two protocols can be used in the layer above the
             IP, which corresponds to the transport layer, i.e., layer 4, in the ISO protocol
             stack. The Transmission Control Protocol (TCP) is a connection-oriented reliable
             protocol, It employs a virtual circuit between two processes and provides reliabil-
             ity by retransmitting a message that is not received in an expected time interval
             (see Section 16.4 for a discussion of acknowledgments and time-outs used to
             ensure reliable delivery of messages). The overhead of ensuring reliability is high
             if the speeds of a sender and a receiver mismatch, or if the network is overloaded;
             hence, the TCP performs flow control to ensure that a sender does not send pack-
             ets faster than the rate at which a receiver can accept them, and congestion control
             to ensure that traffic is regulated so that a network is not overloaded.
             The User Datagram Protocol (UDP) is a connectionless, unreliable protocol
             that neither guarantees delivery of a packet nor ensures that packets of a message
             will be delivered in the correct order. It incurs low overhead compared to the
             TCP because it does not have to set up and maintain a virtual circuit or ensure
             reliable delivery. The UDP is employed in multimedia applications and in video
             conferencing because the occasional loss of packets is not a correctness issue in
             these applications--it only leads to poor picture quality. These applications use
             their own flow and congestion control mechanisms such as reducing the resolu-
             tion of pictures--and, consequently, lowering the picture quality--if a sender, a
             receiver, or the network is overloaded.
             The top layer in the TCP/IP stack is occupied by an application layer protocol
             like the file transfer protocol, an e-mail protocol such as the SMTP, or a remote
             log-in protocol. This layer corresponds to layers 5­7 in the ISO protocol. When
             the UDP is used in the lower layer, the top layer can be occupied by an application-
             specific protocol implemented in an application process itself.
             16.6.7 Network Bandwidth and Latency
             When data is to be exchanged between two nodes, network hardware and network
             protocols participate in data transfer over a link, and communication processors
             (CPs) store and forward the data until it reaches the destination node. Two aspects
             of network performance are the rate at which data can be delivered and how soon
             data can reach the destination node.
             Network bandwidth is the rate at which data is transferred over a network. It is
             subject to various factors such as capacities of network links, error rates and delays
             at routers, bridges, and gateways. Peak bandwidth is the theoretical maximum rate
             at which data can be transferred between two nodes. Effective bandwidth may be
